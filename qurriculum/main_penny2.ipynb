{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as pnp\n",
    "from pennylane.optimize import NesterovMomentumOptimizer\n",
    "from shapely.geometry import Polygon, Point\n",
    "from matplotlib import pyplot as plt\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nqubits = 4         # Num qubits, min 4, always 2**num_layers qubits\n",
    "num_iters = 15      # Number of training iterations\n",
    "optimizer = \"Adam\"  # \"Adam\", \"Nesterov\"\n",
    "loss_type = \"cross-entropy\" # \"projectors\", \"cross-entropy\"\n",
    "with_bias = False    # Add a bias to the output of the quantum circuit\n",
    "balanced_classes = False     # True: Same number of datapoints for each class. False: We cover homologously the j1,j2 space \n",
    "random = True\n",
    "\n",
    "num_cpus = 80\n",
    "\n",
    "# Data hyper-parameters\n",
    "num_data = 100      # How many ground states do we want?\n",
    "num_train = 75      # Ground states that will be used for training\n",
    "batch_size = 20     # batch training size\n",
    "\n",
    "# Tweak hyper-parameters\n",
    "max_weight_init = 0.01  # weight_init goes from 0 to this number. Max = 2*np.pi. Other options = 0.01\n",
    "stepsize = 0.02         # stepsize of the gradient descent.\n",
    "\n",
    "# Constant definitions\n",
    "layers = int(np.log2(nqubits))\n",
    "nweights = 30*(layers-1) + 15\n",
    "rng = np.random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def X(i):\n",
    "    return qml.PauliX(i)\n",
    "\n",
    "def Z(i):\n",
    "    return qml.PauliZ(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Gound states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ground_state(j1, j2):\n",
    "    \n",
    "    hamiltonian = 0\n",
    "    for i in range(nqubits):\n",
    "        hamiltonian += Z(i)\n",
    "        hamiltonian -= j1 * X(i) @ X((i+1)%nqubits)\n",
    "        hamiltonian -= j2 * X((i-1)%nqubits) @ Z(i) @ X((i+1)%nqubits)\n",
    "    \n",
    "    _, eigvecs = np.linalg.eigh(qml.matrix(hamiltonian))\n",
    "    \n",
    "    return eigvecs[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir las coordenadas de los puntos de cada regi칩n\n",
    "region01_coords = np.array([(-2, 1), (2, 1), (4, 3), (4, 4), (-4, 4), (-4, 3)])    # Class 0\n",
    "region02_coords = np.array([(-3, -4), (0, -1), (3, -4)])                           # Class 0\n",
    "region1_coords = np.array([(0, -1), (3, -4), (4, -4), (4, 3)])                     # Class 1\n",
    "region2_coords = np.array([(0, -1), (-3, -4), (-4, -4), (-4, 3)])                  # Class 2\n",
    "region3_coords = np.array([(-2, 1), (2, 1), (0, -1)])                              # Class 3\n",
    "\n",
    "def labeling(x, y):\n",
    "\n",
    "    # Crear objetos Polygon para cada regi칩n\n",
    "    region01_poly = Polygon(region01_coords)\n",
    "    region02_poly = Polygon(region02_coords)\n",
    "    region1_poly = Polygon(region1_coords)\n",
    "    region2_poly = Polygon(region2_coords)\n",
    "    region3_poly = Polygon(region3_coords)\n",
    "    \n",
    "    \n",
    "    punto = Point(x, y)\n",
    "    if region01_poly.contains(punto):\n",
    "        return 0\n",
    "    elif region02_poly.contains(punto):\n",
    "        return 0\n",
    "    elif region1_poly.contains(punto):\n",
    "        return 1\n",
    "    elif region2_poly.contains(punto):\n",
    "        return 2\n",
    "    elif region3_poly.contains(punto):\n",
    "        return 3\n",
    "    else:\n",
    "        return None # Si el punto no est치 en ninguna regi칩n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not random:\n",
    "    rng = np.random.RandomState(0)\n",
    "\n",
    "if balanced_classes:\n",
    "    \n",
    "    npoints_class = num_data//4\n",
    "    num_data = 4*npoints_class\n",
    "    j_list = []\n",
    "    num_0, num_1, num_2, num_3 = 0, 0, 0, 0\n",
    "\n",
    "    while num_0 != npoints_class or num_1 != npoints_class or num_2 != npoints_class or num_3 != npoints_class:\n",
    "        j = rng.uniform(-4, 4, 2)\n",
    "        l = labeling(j[0], j[1])\n",
    "\n",
    "        if l==0 and num_0 < npoints_class:\n",
    "            num_0 += 1\n",
    "            j_list.append(j)\n",
    "        elif l==1 and num_1 < npoints_class:\n",
    "            num_1 += 1\n",
    "            j_list.append(j)\n",
    "        elif l==2 and num_2 < npoints_class:\n",
    "            num_2 += 1\n",
    "            j_list.append(j)\n",
    "        elif l==3 and num_3 < npoints_class:\n",
    "            num_3 += 1\n",
    "            j_list.append(j)\n",
    "\n",
    "    j_list = np.array(j_list)\n",
    "    \n",
    "else:\n",
    "    j_list = rng.uniform(-4, 4, (num_data,2))\n",
    "\n",
    "\n",
    "gs_list = []\n",
    "labels_list = []\n",
    "for i in range(num_data):\n",
    "    gs_list.append(ground_state(j_list[i,0], j_list[i,1]))\n",
    "    labels_list.append(labeling(j_list[i,0], j_list[i,1]))\n",
    "\n",
    "gs_list = np.array(gs_list)\n",
    "labels_list = np.array(labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 16)\n"
     ]
    }
   ],
   "source": [
    "print(gs_list.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convolutional_layer(q1, q2, weights):\n",
    "    qml.U3(wires=q1, theta=weights[0], phi=weights[1], delta=weights[2])\n",
    "    qml.U3(wires=q1, theta=weights[3], phi=weights[4], delta=weights[5])\n",
    "    qml.CNOT(wires=[q2, q1])\n",
    "    qml.RZ(wires=q1, phi=weights[6])\n",
    "    qml.RY(wires=q2, phi=weights[7])\n",
    "    qml.CNOT(wires=[q1, q2])\n",
    "    qml.RY(wires=q2, phi=weights[8])\n",
    "    qml.CNOT(wires=[q2, q1])\n",
    "    qml.U3(wires=q1, theta=weights[9], phi=weights[10], delta=weights[11])\n",
    "    qml.U3(wires=q1, theta=weights[12], phi=weights[13], delta=weights[14])\n",
    "\n",
    "def pooling_layer(q1, q2, weights):\n",
    "    qml.U3(wires=q1, theta=weights[0], phi=weights[1], delta=weights[2])\n",
    "    qml.U3(wires=q1, theta=weights[3], phi=weights[4], delta=weights[5])\n",
    "    qml.CNOT(wires=[q2, q1])\n",
    "    qml.RZ(wires=q1, phi=weights[6])\n",
    "    qml.RY(wires=q2, phi=weights[7])\n",
    "    qml.CNOT(wires=[q1, q2])\n",
    "    qml.RY(wires=q2, phi=weights[8])\n",
    "    qml.CNOT(wires=[q2, q1])\n",
    "    qml.U3(wires=q1, theta=weights[9], phi=weights[10], delta=weights[11])\n",
    "    qml.U3(wires=q1, theta=weights[12], phi=weights[13], delta=weights[14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_circuit(weights, state_ini):\n",
    "    \n",
    "    qubits = list(range(nqubits))\n",
    "    \n",
    "    qml.QubitStateVector(state_ini, wires=qubits)\n",
    "\n",
    "    for j in range(layers-1):\n",
    "        \n",
    "        len_qubits = len(qubits)\n",
    "        \n",
    "        for i in range(len_qubits//2):\n",
    "            convolutional_layer(qubits[2*i], qubits[(2*i+1)%len_qubits], weights[15*2*j:15*(2*j+1)])\n",
    "        \n",
    "        for i in range(len_qubits//2):\n",
    "            convolutional_layer(qubits[2*i+1], qubits[(2*i+2)%len_qubits], weights[15*2*j:15*(2*j+1)])\n",
    "            \n",
    "        for i in range(len_qubits//2):\n",
    "            pooling_layer(qubits[2*i], qubits[(2*i+1)%len_qubits], weights[15*(2*j+1):15*(2*j+2)])\n",
    "\n",
    "        qub = []\n",
    "        for i in range(len_qubits):\n",
    "            if i%2 == 1:\n",
    "                qub.append(qubits[i])\n",
    "                \n",
    "        qubits = qub\n",
    "    \n",
    "    convolutional_layer(qubits[0], qubits[1], weights[15*(2*layers-2):15*(2*layers-1)])\n",
    "    \n",
    "    return qml.expval(Z(qubits[0])), qml.expval(Z(qubits[1])), qml.expval(Z(qubits[0]) @ Z(qubits[1]))\n",
    "\n",
    "# dev_draw = qml.device(\"qiskit.aer\", wires=nqubits)\n",
    "dev = qml.device(\"default.qubit\", wires=nqubits)\n",
    "\n",
    "# cnn_draw = qml.QNode(cnn_circuit, dev_draw)\n",
    "cnn_circuit = qml.QNode(cnn_circuit, dev, interface=\"auto\", diff_method=\"best\")\n",
    "\n",
    "\n",
    "def cnn(weights, state_ini):\n",
    "    z0, z1, zz01 = cnn_circuit(weights, state_ini)\n",
    "\n",
    "    proj_00 = (1+zz01+z0+z1)/4\n",
    "    proj_01 = (1-zz01-z0+z1)/4\n",
    "    proj_10 = (1-zz01+z0-z1)/4\n",
    "    proj_11 = (1+zz01-z0-z1)/4\n",
    "\n",
    "    return pnp.array([proj_00, proj_01, proj_10, proj_11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variational_classifier(weights, bias, state_ini):\n",
    "    return cnn(weights, state_ini) + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cnn_circuit() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m weights \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mpi, nweights)\n\u001b[1;32m      2\u001b[0m drawer \u001b[38;5;241m=\u001b[39m qml\u001b[38;5;241m.\u001b[39mdraw(cnn_circuit)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdrawer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgs_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# z0, z1, zz01 = cnn_draw(gs_list[0], weights)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# print(z0, z1, zz01)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# dev_draw._circuit.draw(output=\"mpl\")\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pennylane/drawer/draw.py:247\u001b[0m, in \u001b[0;36m_draw_qnode.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    246\u001b[0m     qnode\u001b[38;5;241m.\u001b[39mexpansion_strategy \u001b[38;5;241m=\u001b[39m expansion_strategy \u001b[38;5;129;01mor\u001b[39;00m original_expansion_strategy\n\u001b[0;32m--> 247\u001b[0m     tapes \u001b[38;5;241m=\u001b[39m \u001b[43mqnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    249\u001b[0m     qnode\u001b[38;5;241m.\u001b[39mexpansion_strategy \u001b[38;5;241m=\u001b[39m original_expansion_strategy\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pennylane/qnode.py:827\u001b[0m, in \u001b[0;36mQNode.construct\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m old_interface \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    825\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterface \u001b[38;5;241m=\u001b[39m qml\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mget_interface(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mvalues()))\n\u001b[0;32m--> 827\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tape \u001b[38;5;241m=\u001b[39m \u001b[43mmake_qscript\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshots\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_qfunc_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtape\u001b[38;5;241m.\u001b[39m_qfunc_output\n\u001b[1;32m    830\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtape\u001b[38;5;241m.\u001b[39mget_parameters(trainable_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pennylane/tape/qscript.py:1482\u001b[0m, in \u001b[0;36mmake_qscript.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1480\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1481\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m AnnotatedQueue() \u001b[38;5;28;01mas\u001b[39;00m q:\n\u001b[0;32m-> 1482\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1484\u001b[0m     qscript \u001b[38;5;241m=\u001b[39m QuantumScript\u001b[38;5;241m.\u001b[39mfrom_queue(q, shots)\n\u001b[1;32m   1485\u001b[0m     qscript\u001b[38;5;241m.\u001b[39m_qfunc_output \u001b[38;5;241m=\u001b[39m result\n",
      "\u001b[0;31mTypeError\u001b[0m: cnn_circuit() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "weights = np.random.uniform(0, 2*np.pi, nweights)\n",
    "drawer = qml.draw(cnn_circuit)\n",
    "print(drawer(weights, gs_list[0]))\n",
    "\n",
    "# z0, z1, zz01 = cnn_draw(gs_list[0], weights)\n",
    "# print(z0, z1, zz01)\n",
    "# dev_draw._circuit.draw(output=\"mpl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log2_arraybox(abox):\n",
    "    return pnp._np.numpy_boxes.ArrayBox(value = np.log2(abox._value), trace = abox._trace, node = abox._node)\n",
    "\n",
    "\n",
    "def exp_arraybox(abox):\n",
    "    return pnp._np.numpy_boxes.ArrayBox(value = np.exp(abox._value), trace = abox._trace, node = abox._node)\n",
    "\n",
    "\n",
    "def single_loss(weights, bias, ground_state, label):\n",
    "    \n",
    "    proj = variational_classifier(weights, bias, ground_state)\n",
    "\n",
    "    if loss_type == \"projectors\":\n",
    "            cost = proj[label]\n",
    "\n",
    "    elif loss_type == \"cross-entropy\":\n",
    "        \n",
    "            if isinstance(proj[label], pnp._np.numpy_boxes.ArrayBox):\n",
    "                cost = -log2_arraybox(proj[label])\n",
    "            else:\n",
    "                cost = -np.log2(proj[label])\n",
    "    \n",
    "    return cost\n",
    "\n",
    "\n",
    "def loss(weights, bias, ground_states, labels):\n",
    "    #-------------------------\n",
    "#     cost = 0\n",
    "    \n",
    "#     for j in range(len(labels)):\n",
    "#         cost += single_loss(weights, bias, ground_states[j], labels[j])\n",
    "    \n",
    "    #-------------------------\n",
    "    args = [[weights, bias, ground_states[j], labels[j]] for j in range(len(labels))]\n",
    "    \n",
    "    with Pool(num_cpus) as pool:\n",
    "        cost_arr = pool.starmap(single_loss, args)\n",
    "    \n",
    "    cost = sum(cost_arr)\n",
    "    #-------------------------\n",
    "    \n",
    "#     a = single_loss(weights, bias, ground_states, labels)\n",
    "#     print(a)\n",
    "    \n",
    "    return cost/len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.08413055462751\n"
     ]
    }
   ],
   "source": [
    "weights_init = pnp.random.uniform(0, max_weight_init, nweights, requires_grad=True)\n",
    "bias_init = pnp.array([0.0]*4, requires_grad=True)\n",
    "\n",
    "print(loss(weights_init, bias_init, gs_list, labels_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_acc(weights, bias, ground_states, labels):\n",
    "    accuracy_data = 0\n",
    "    predictions = []\n",
    "\n",
    "    for j in range(len(labels)):\n",
    "        projectors = variational_classifier(weights, bias, ground_states[j])\n",
    "        \n",
    "        if loss_type == \"projectors\":\n",
    "            pred = np.argmin(projectors)\n",
    "        elif loss_type == \"cross-entropy\":\n",
    "            pred = np.argmax(projectors)\n",
    "\n",
    "        accuracy_data += 1 if pred == labels[j] else 0\n",
    "        predictions.append(pred)\n",
    "            \n",
    "    return predictions, accuracy_data*100/len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't pickle local object 'VJPNode.initialize_root.<locals>.<lambda>'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 49\u001b[0m\n\u001b[1;32m     46\u001b[0m labels_train_batch \u001b[38;5;241m=\u001b[39m labels_train[batch_index]\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Update the weights by one optimizer step\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m w, b, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgs_train_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels_train_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m weights\u001b[38;5;241m.\u001b[39mappend(w)\n\u001b[1;32m     51\u001b[0m bias\u001b[38;5;241m.\u001b[39mappend(b)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pennylane/optimize/gradient_descent.py:88\u001b[0m, in \u001b[0;36mGradientDescentOptimizer.step\u001b[0;34m(self, objective_fn, grad_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, objective_fn, \u001b[38;5;241m*\u001b[39margs, grad_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     71\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Update trainable arguments with one step of the optimizer.\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;03m        If single arg is provided, list [array] is replaced by array.\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m     g, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m     new_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_grad(g, args)\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;66;03m# unwrap from list if one argument, cleaner return\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pennylane/optimize/gradient_descent.py:117\u001b[0m, in \u001b[0;36mGradientDescentOptimizer.compute_grad\u001b[0;34m(objective_fn, args, kwargs, grad_fn)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Compute gradient of the objective function at the given point and return it along with\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03mthe objective function forward pass (if available).\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;124;03m    will not be evaluted and instead ``None`` will be returned.\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    116\u001b[0m g \u001b[38;5;241m=\u001b[39m get_gradient(objective_fn) \u001b[38;5;28;01mif\u001b[39;00m grad_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m grad_fn\n\u001b[0;32m--> 117\u001b[0m grad \u001b[38;5;241m=\u001b[39m \u001b[43mg\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m forward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(g, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    120\u001b[0m num_trainable_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_grad\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pennylane/_grad.py:120\u001b[0m, in \u001b[0;36mgrad.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fun(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ()\n\u001b[0;32m--> 120\u001b[0m grad_value, ans \u001b[38;5;241m=\u001b[39m \u001b[43mgrad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward \u001b[38;5;241m=\u001b[39m ans\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m grad_value\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/autograd/wrap_util.py:20\u001b[0m, in \u001b[0;36munary_to_nary.<locals>.nary_operator.<locals>.nary_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     19\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(args[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m argnum)\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43munary_operator\u001b[49m\u001b[43m(\u001b[49m\u001b[43munary_f\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnary_op_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnary_op_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pennylane/_grad.py:138\u001b[0m, in \u001b[0;36mgrad._grad_with_forward\u001b[0;34m(fun, x)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;129m@unary_to_nary\u001b[39m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_grad_with_forward\u001b[39m(fun, x):\n\u001b[1;32m    135\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"This function is a replica of ``autograd.grad``, with the only\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m    difference being that it returns both the gradient *and* the forward pass\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;124;03m    value.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 138\u001b[0m     vjp, ans \u001b[38;5;241m=\u001b[39m \u001b[43m_make_vjp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m vspace(ans)\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    141\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    142\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGrad only applies to real scalar-output functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    143\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTry jacobian, elementwise_grad or holomorphic_grad.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    144\u001b[0m         )\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/autograd/core.py:10\u001b[0m, in \u001b[0;36mmake_vjp\u001b[0;34m(fun, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_vjp\u001b[39m(fun, x):\n\u001b[1;32m      9\u001b[0m     start_node \u001b[38;5;241m=\u001b[39m VJPNode\u001b[38;5;241m.\u001b[39mnew_root()\n\u001b[0;32m---> 10\u001b[0m     end_value, end_node \u001b[38;5;241m=\u001b[39m  \u001b[43mtrace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_node\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end_node \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvjp\u001b[39m(g): \u001b[38;5;28;01mreturn\u001b[39;00m vspace(x)\u001b[38;5;241m.\u001b[39mzeros()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/autograd/tracer.py:10\u001b[0m, in \u001b[0;36mtrace\u001b[0;34m(start_node, fun, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace_stack\u001b[38;5;241m.\u001b[39mnew_trace() \u001b[38;5;28;01mas\u001b[39;00m t:\n\u001b[1;32m      9\u001b[0m     start_box \u001b[38;5;241m=\u001b[39m new_box(x, t, start_node)\n\u001b[0;32m---> 10\u001b[0m     end_box \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_box\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m isbox(end_box) \u001b[38;5;129;01mand\u001b[39;00m end_box\u001b[38;5;241m.\u001b[39m_trace \u001b[38;5;241m==\u001b[39m start_box\u001b[38;5;241m.\u001b[39m_trace:\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m end_box\u001b[38;5;241m.\u001b[39m_value, end_box\u001b[38;5;241m.\u001b[39m_node\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/autograd/wrap_util.py:15\u001b[0m, in \u001b[0;36munary_to_nary.<locals>.nary_operator.<locals>.nary_f.<locals>.unary_f\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     subargs \u001b[38;5;241m=\u001b[39m subvals(args, \u001b[38;5;28mzip\u001b[39m(argnum, x))\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msubargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[35], line 37\u001b[0m, in \u001b[0;36mloss\u001b[0;34m(weights, bias, ground_states, labels)\u001b[0m\n\u001b[1;32m     34\u001b[0m     args \u001b[38;5;241m=\u001b[39m [[weights, bias, ground_states[j], labels[j]] \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(labels))]\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Pool(num_cpus) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[0;32m---> 37\u001b[0m         cost_arr \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstarmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43msingle_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m     cost \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(cost_arr)\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;66;03m#-------------------------\u001b[39;00m\n\u001b[1;32m     41\u001b[0m     \n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m#     a = single_loss(weights, bias, ground_states, labels)\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m#     print(a)\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/pool.py:372\u001b[0m, in \u001b[0;36mPool.starmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstarmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    367\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;124;03m    Like `map()` method but the elements of the `iterable` are expected to\u001b[39;00m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;124;03m    be iterables as well and will be unpacked as arguments. Hence\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;124;03m    `func` and (a, b) becomes func(a, b).\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 372\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstarmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/pool.py:771\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n\u001b[1;32m    770\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 771\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/pool.py:537\u001b[0m, in \u001b[0;36mPool._handle_tasks\u001b[0;34m(taskqueue, put, outqueue, pool, cache)\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 537\u001b[0m     \u001b[43mput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    539\u001b[0m     job, idx \u001b[38;5;241m=\u001b[39m task[:\u001b[38;5;241m2\u001b[39m]\n",
      "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/connection.py:206\u001b[0m, in \u001b[0;36m_ConnectionBase.send\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_writable()\n\u001b[0;32m--> 206\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_bytes(\u001b[43m_ForkingPickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/reduction.py:51\u001b[0m, in \u001b[0;36mForkingPickler.dumps\u001b[0;34m(cls, obj, protocol)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdumps\u001b[39m(\u001b[38;5;28mcls\u001b[39m, obj, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     50\u001b[0m     buf \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO()\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m buf\u001b[38;5;241m.\u001b[39mgetbuffer()\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can't pickle local object 'VJPNode.initialize_root.<locals>.<lambda>'"
     ]
    }
   ],
   "source": [
    "if not random:\n",
    "    rng = np.random.RandomState(0)\n",
    "\n",
    "# Splitting the data into training and validation\n",
    "index = rng.permutation(range(num_data))\n",
    "\n",
    "gs_train = gs_list[index[:num_train]]\n",
    "labels_train = labels_list[index[:num_train]]\n",
    "gs_val = gs_list[index[num_train:]]\n",
    "labels_val = labels_list[index[num_train:]]\n",
    "\n",
    "# We need these later for plotting\n",
    "j_train = j_list[index[:num_train]]\n",
    "j_val = j_list[index[num_train:]]\n",
    "\n",
    "# weights and bias initialization\n",
    "weights_init = pnp.random.uniform(0, max_weight_init, nweights, requires_grad=True)\n",
    "\n",
    "if with_bias:\n",
    "    bias_init = pnp.array([0.0]*4, requires_grad=True)\n",
    "else:\n",
    "    bias_init = np.array([0.0]*4)\n",
    "\n",
    "# train the variational classifier\n",
    "if optimizer == \"Nesterov\":\n",
    "    opt = NesterovMomentumOptimizer(stepsize)\n",
    "elif optimizer == \"Adam\":\n",
    "    opt = qml.AdamOptimizer(stepsize)\n",
    "    \n",
    "    \n",
    "weights = []\n",
    "bias = []\n",
    "losses = []\n",
    "pred_train_arr = []\n",
    "pred_val_arr = []\n",
    "acc_train_arr = []\n",
    "acc_val_arr = []\n",
    "\n",
    "w = weights_init\n",
    "b = bias_init\n",
    "\n",
    "for it in range(num_iters):\n",
    "\n",
    "    batch_index = np.random.randint(0, num_train, (batch_size,))\n",
    "    gs_train_batch = gs_train[batch_index]\n",
    "    labels_train_batch = labels_train[batch_index]\n",
    "    \n",
    "    # Update the weights by one optimizer step\n",
    "    w, b, _, _ = opt.step(loss, w, b, gs_train_batch, labels_train_batch)\n",
    "    weights.append(w)\n",
    "    bias.append(b)\n",
    "    \n",
    "    # Compute predictions and accuracy on train and validation set\n",
    "    pred_train, acc_train = pred_acc(w, b, gs_train, labels_train)\n",
    "    pred_val, acc_val = pred_acc(w, b, gs_val, labels_val) if len(labels_val)>0 else [0, 0]\n",
    "\n",
    "    # Save prediction for later plotting\n",
    "    pred_train_arr.append(pred_train)\n",
    "    pred_val_arr.append(pred_val)\n",
    "    acc_train_arr.append(acc_train)\n",
    "    acc_val_arr.append(acc_val)\n",
    "\n",
    "    l = loss(w, b, gs_list, labels_list)\n",
    "    losses.append(l)\n",
    "\n",
    "    print(\n",
    "        \"Iter: {:5d} | Loss: {:0.7f} | Acc train: {:0.7f} | Acc validation: {:0.7f}\"\n",
    "        \"\".format(it+1, l, acc_train, acc_val)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plus_iter = 0\n",
    "\n",
    "for i in range(plus_iter):\n",
    "    \n",
    "    it+=1\n",
    "\n",
    "    # Update the weights by one optimizer step\n",
    "    batch_index = np.random.randint(0, num_train, (batch_size,))\n",
    "    gs_train_batch = gs_train[batch_index]\n",
    "    labels_train_batch = labels_train[batch_index]\n",
    "    \n",
    "    w, b, _, _ = opt.step(loss, w, b, gs_train_batch, labels_train_batch)\n",
    "    weights.append(w)\n",
    "    bias.append(b)\n",
    "    \n",
    "    # Compute predictions and accuracy on train and validation set\n",
    "    pred_train, acc_train = pred_acc(w, b, gs_train, labels_train)\n",
    "    pred_val, acc_val = pred_acc(w, b, gs_val, labels_val) if len(labels_val)>0 else [0, 0]\n",
    "\n",
    "    # Save prediction for later plotting\n",
    "    pred_train_arr.append(pred_train)\n",
    "    pred_val_arr.append(pred_val)\n",
    "    acc_train_arr.append(acc_train)\n",
    "    acc_val_arr.append(acc_val)\n",
    "\n",
    "    l = loss(w, b, gs_list, labels_list)\n",
    "    losses.append(l)\n",
    "\n",
    "    print(\n",
    "        \"Iter: {:5d} | Loss: {:0.7f} | Acc train: {:0.7f} | Acc validation: {:0.7f}\"\n",
    "        \"\".format(it+1, l, acc_train, acc_val)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "iterations = range(1, len(acc_train_arr)+1)\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "color1 = 'darkred'\n",
    "ax1.set_xlabel('Iterations')\n",
    "ax1.set_ylabel('Accuracy %', color=color1)\n",
    "ax1.plot(iterations, acc_train_arr, label=\"Training\", color=color1)\n",
    "ax1.plot(iterations, acc_val_arr, '-.', label=\"Validation\", color=color1)\n",
    "ax1.tick_params(axis='y', labelcolor=color1)\n",
    "ax1.set_ylim(0,100)\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color2 = 'darkblue'\n",
    "ax2.set_ylabel('Loss', color=color2)  # we already handled the x-label with ax1\n",
    "ax2.plot(iterations, losses, label=\"Loss\", color=color2)\n",
    "ax2.tick_params(axis='y', labelcolor=color2)\n",
    "# ax2.set_ylim(bottom=0)\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "# plt.legend()\n",
    "plt.title(\"Accuracy and Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_iter = it+1 #it+1\n",
    "\n",
    "# define regions coordinates\n",
    "x01, y01 = region01_coords[:,0], region01_coords[:,1]\n",
    "x02, y02 = region02_coords[:,0], region02_coords[:,1]\n",
    "x1, y1 = region1_coords[:,0], region1_coords[:,1]\n",
    "x2, y2 = region2_coords[:,0], region2_coords[:,1]\n",
    "x3, y3 = region3_coords[:,0], region3_coords[:,1]\n",
    "\n",
    "# plt.figure(figsize=(8, 8))\n",
    "\n",
    "# put the regions into the plot\n",
    "plt.fill(x01, y01, facecolor='lightskyblue')    # class 0\n",
    "plt.fill(x02, y02, facecolor='lightskyblue')    # class 0\n",
    "plt.fill(x1, y1, facecolor='sandybrown')        # class 1\n",
    "plt.fill(x2, y2, facecolor='salmon')            # class 2\n",
    "plt.fill(x3, y3, facecolor='lightgreen')        # class 3\n",
    "\n",
    "pred_train_plot = np.array(pred_train_arr[plot_iter-1])\n",
    "pred_val_plot = np.array(pred_val_arr[plot_iter-1])\n",
    "\n",
    "colors = [\"b\", \"orange\", \"r\", \"g\"]\n",
    "\n",
    "# plot datapoints\n",
    "for i in range(4):\n",
    "    plt.scatter(\n",
    "        j_train[:, 0][pred_train_plot==i],\n",
    "        j_train[:, 1][pred_train_plot==i],\n",
    "        c=colors[i],\n",
    "        marker=\"o\",\n",
    "        edgecolors=\"k\",\n",
    "        label=f\"class {i+1} train\",\n",
    "    )\n",
    "    plt.scatter(\n",
    "        j_val[:, 0][pred_val_plot==i],\n",
    "        j_val[:, 1][pred_val_plot==i],\n",
    "        c=colors[i],\n",
    "        marker=\"^\",\n",
    "        edgecolors=\"k\",\n",
    "        label=f\"class {i+1} validation\",\n",
    "    )\n",
    "\n",
    "\n",
    "# plt.legend()\n",
    "plt.axis('square')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from importlib import reload\n",
    "# plt=reload(plt)\n",
    "\n",
    "plt.plot(range(1, len(acc_train_arr)+1), acc_train_arr, label=\"Training\")\n",
    "plt.plot(range(1, len(acc_train_arr)+1), acc_val_arr, '-.', label=\"Validation\")\n",
    "\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Percentage\")\n",
    "\n",
    "plt.ylim(0, 100)\n",
    "plt.title(\"Accuracy\")\n",
    "\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(range(1, len(acc_train_arr)+1), losses)\n",
    "\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
