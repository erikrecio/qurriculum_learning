{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import random as rand\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from pennylane.optimize import NesterovMomentumOptimizer\n",
    "from shapely.geometry import Polygon, Point\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "nqubits = 4         # num qubits, min 4, always 2**num_layers qubits\n",
    "num_iters = 60      # Training iterations \n",
    "random = False\n",
    "\n",
    "# Data hyper-parameters\n",
    "num_data = 15       # How many ground states do we want for training?\n",
    "perc_train = 0.75   # Percentage of num_data that will be used for training. Max = 1.\n",
    "batch_size = 5      # batch training size\n",
    "\n",
    "# Tweak hyper-parameters\n",
    "max_weight_init = 0.01  # weight_init goes from 0 to this number. Max = 2*np.pi\n",
    "stepsize = 0.01         # stepsize of the gradient descent.\n",
    "\n",
    "layers = int(np.log2(nqubits))\n",
    "nweights = 30*(layers-1) + 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def X(i):\n",
    "    return qml.PauliX(i)\n",
    "\n",
    "def Z(i):\n",
    "    return qml.PauliZ(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gound states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ground_state(j1, j2):\n",
    "    \n",
    "    hamiltonian = 0\n",
    "    for i in range(nqubits):\n",
    "        hamiltonian += Z(i)\n",
    "        hamiltonian -= j1 * X(i) @ X((i+1)%nqubits)\n",
    "        hamiltonian -= j2 * X((i-1)%nqubits) @ Z(i) @ X((i+1)%nqubits)\n",
    "    \n",
    "    _, eigvecs = np.linalg.eigh(qml.matrix(hamiltonian))\n",
    "    \n",
    "    return eigvecs[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labeling(x, y):\n",
    "    # Definir las coordenadas de los puntos de cada región\n",
    "    region1_coords = [(-2, 1), (2, 1), (0, -1)]\n",
    "    region2_coords = [(0, -1), (3, -4), (4, -4), (4, 3)]\n",
    "    region3_coords = [(0, -1), (-3, -4), (-4, -4), (-4, 3)]\n",
    "    region4_coords = [(-2, 1), (2, 1), (4, 3), (4, 4), (-4, 4), (-4, 3)]\n",
    "    region5_coords = [(-3, -4), (0, -1), (3, -4)]\n",
    "    \n",
    "    # Crear objetos Polygon para cada región\n",
    "    region1_poly = Polygon(region1_coords)\n",
    "    region2_poly = Polygon(region2_coords)\n",
    "    region3_poly = Polygon(region3_coords)\n",
    "    region4_poly = Polygon(region4_coords)\n",
    "    region5_poly = Polygon(region5_coords)\n",
    "    \n",
    "    punto = Point(x, y)\n",
    "    if region1_poly.contains(punto):\n",
    "        return 3\n",
    "    elif region2_poly.contains(punto):\n",
    "        return 1\n",
    "    elif region3_poly.contains(punto):\n",
    "        return 2\n",
    "    elif region4_poly.contains(punto):\n",
    "        return 0\n",
    "    elif region5_poly.contains(punto):\n",
    "        return 0\n",
    "    else:\n",
    "        return None # Si el punto no está en ninguna región"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not random:\n",
    "    rng = rand.RandomState(0)\n",
    "\n",
    "gs_list = []\n",
    "labels_list = []\n",
    "j_list = rng.uniform(-4, 4, (num_data,2))\n",
    "\n",
    "for i in range(num_data):\n",
    "    gs_list.append(ground_state(j_list[i,0], j_list[i,1]))\n",
    "    labels_list.append(labeling(j_list[i,0], j_list[i,1]))\n",
    "\n",
    "gs_list = np.array(gs_list, requires_grad=False)\n",
    "labels_list = np.array(labels_list, requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 16)\n"
     ]
    }
   ],
   "source": [
    "print(gs_list.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_layer(q1, q2, weights):\n",
    "    qml.U3(wires=q1, theta=weights[0], phi=weights[1], delta=weights[2])\n",
    "    qml.U3(wires=q1, theta=weights[3], phi=weights[4], delta=weights[5])\n",
    "    qml.CNOT(wires=[q2, q1])\n",
    "    qml.RZ(wires=q1, phi=weights[6])\n",
    "    qml.RY(wires=q2, phi=weights[7])\n",
    "    qml.CNOT(wires=[q1, q2])\n",
    "    qml.RY(wires=q2, phi=weights[8])\n",
    "    qml.CNOT(wires=[q2, q1])\n",
    "    qml.U3(wires=q1, theta=weights[9], phi=weights[10], delta=weights[11])\n",
    "    qml.U3(wires=q1, theta=weights[12], phi=weights[13], delta=weights[14])\n",
    "\n",
    "def pooling_layer(q1, q2, weights):\n",
    "    qml.U3(wires=q1, theta=weights[0], phi=weights[1], delta=weights[2])\n",
    "    qml.U3(wires=q1, theta=weights[3], phi=weights[4], delta=weights[5])\n",
    "    qml.CNOT(wires=[q2, q1])\n",
    "    qml.RZ(wires=q1, phi=weights[6])\n",
    "    qml.RY(wires=q2, phi=weights[7])\n",
    "    qml.CNOT(wires=[q1, q2])\n",
    "    qml.RY(wires=q2, phi=weights[8])\n",
    "    qml.CNOT(wires=[q2, q1])\n",
    "    qml.U3(wires=q1, theta=weights[9], phi=weights[10], delta=weights[11])\n",
    "    qml.U3(wires=q1, theta=weights[12], phi=weights[13], delta=weights[14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_circuit(weights, state_ini):\n",
    "\n",
    "    qubits = list(range(nqubits))\n",
    "    \n",
    "    qml.QubitStateVector(state_ini, wires=qubits)\n",
    "\n",
    "    for j in range(layers-1):\n",
    "        \n",
    "        len_qubits = len(qubits)\n",
    "        \n",
    "        for i in range(len_qubits//2):\n",
    "            convolutional_layer(qubits[2*i], qubits[(2*i+1)%len_qubits], weights[15*2*j:15*(2*j+1)])\n",
    "        \n",
    "        for i in range(len_qubits//2):\n",
    "            convolutional_layer(qubits[2*i+1], qubits[(2*i+2)%len_qubits], weights[15*2*j:15*(2*j+1)])\n",
    "            \n",
    "        for i in range(len_qubits//2):\n",
    "            pooling_layer(qubits[2*i], qubits[(2*i+1)%len_qubits], weights[15*(2*j+1):15*(2*j+2)])\n",
    "\n",
    "        qub = []\n",
    "        for i in range(len_qubits):\n",
    "            if i%2 == 1:\n",
    "                qub.append(qubits[i])\n",
    "                \n",
    "        qubits = qub\n",
    "    \n",
    "    convolutional_layer(qubits[0], qubits[1], weights[15*(2*layers-2):15*(2*layers-1)])\n",
    "    \n",
    "    return qml.expval(Z(qubits[0])), qml.expval(Z(qubits[1])), qml.expval(Z(qubits[0]) @ Z(qubits[1]))\n",
    "\n",
    "# dev_draw = qml.device(\"qiskit.aer\", wires=nqubits)\n",
    "dev = qml.device(\"default.qubit\", wires=nqubits)\n",
    "\n",
    "# cnn_draw = qml.QNode(cnn, dev_draw)\n",
    "cnn_circuit = qml.QNode(cnn_circuit, dev, interface=\"autograd\")\n",
    "\n",
    "\n",
    "def cnn(weights, state_ini):\n",
    "    z0, z1, zz01 = cnn_circuit(weights, state_ini)\n",
    "\n",
    "    proj_00 = (1+zz01+z0+z1)/4\n",
    "    proj_01 = (1-zz01-z0+z1)/4\n",
    "    proj_10 = (1-zz01+z0-z1)/4\n",
    "    proj_11 = (1+zz01-z0-z1)/4\n",
    "\n",
    "    return np.array([proj_00, proj_01, proj_10, proj_11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variational_classifier(weights, bias, state_ini):\n",
    "    return cnn(weights, state_ini) + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: ─╭|Ψ⟩──U3(4.01,1.23,5.31)──U3(1.15,1.18,4.90)─╭X──RZ(1.18)─╭●───────────╭X──U3(0.45,4.01,5.92)\n",
      "1: ─├|Ψ⟩─────────────────────────────────────────╰●──RY(0.47)─╰X──RY(1.43)─╰●──U3(4.01,1.23,5.31)\n",
      "2: ─├|Ψ⟩──U3(4.01,1.23,5.31)──U3(1.15,1.18,4.90)─╭X──RZ(1.18)─╭●───────────╭X──U3(0.45,4.01,5.92)\n",
      "3: ─╰|Ψ⟩─────────────────────────────────────────╰●──RY(0.47)─╰X──RY(1.43)─╰●──U3(4.01,1.23,5.31)\n",
      "\n",
      "───U3(3.44,2.88,4.71)──────────────────────────────────────────────────────────────────────╭●\n",
      "───U3(1.15,1.18,4.90)─╭X──RZ(1.18)─╭●───────────╭X──U3(0.45,4.01,5.92)──U3(3.44,2.88,4.71)─│─\n",
      "───U3(3.44,2.88,4.71)─╰●──RY(0.47)─╰X──RY(1.43)─╰●─────────────────────────────────────────│─\n",
      "───U3(1.15,1.18,4.90)──────────────────────────────────────────────────────────────────────╰X\n",
      "\n",
      "───RY(0.47)─╭X──RY(1.43)─╭●──U3(2.09,5.54,1.56)──U3(4.70,2.52,0.91)─╭X──RZ(3.19)─╭●───────────╭X\n",
      "────────────│────────────│──────────────────────────────────────────╰●──RY(5.26)─╰X──RY(4.83)─╰●\n",
      "────────────│────────────│───U3(2.09,5.54,1.56)──U3(4.70,2.52,0.91)─╭X──RZ(3.19)─╭●───────────╭X\n",
      "───RZ(1.18)─╰●───────────╰X──U3(0.45,4.01,5.92)──U3(3.44,2.88,4.71)─╰●──RY(5.26)─╰X──RY(4.83)─╰●\n",
      "\n",
      "───U3(2.80,5.26,0.30)──U3(2.63,2.32,4.30)─────────────────────────────────────────────────\n",
      "───U3(4.07,6.17,0.90)──U3(5.35,4.56,2.99)─╭X──RZ(4.62)─╭●───────────╭X──U3(3.10,6.06,0.26)\n",
      "───U3(2.80,5.26,0.30)──U3(2.63,2.32,4.30)─│────────────│────────────│─────────────────────\n",
      "──────────────────────────────────────────╰●──RY(0.38)─╰X──RY(5.71)─╰●────────────────────\n",
      "\n",
      "──────────────────────┤            \n",
      "───U3(6.22,2.98,3.43)─┤  <Z> ╭<Z@Z>\n",
      "──────────────────────┤      │     \n",
      "──────────────────────┤  <Z> ╰<Z@Z>\n"
     ]
    }
   ],
   "source": [
    "weights = rand.uniform(0, 2*np.pi, nweights)\n",
    "drawer = qml.draw(cnn_circuit)\n",
    "print(drawer(weights, gs_list[0]))\n",
    "\n",
    "# z0, z1, zz01 = cnn_draw(gs_list[0], weights)\n",
    "# print(z0, z1, zz01)\n",
    "# dev_draw._circuit.draw(output=\"mpl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(weights, bias, ground_states, labels):\n",
    "    cost = 0\n",
    "    \n",
    "    for j in range(len(labels)):\n",
    "\n",
    "        proj_00, proj_01, proj_10, proj_11 = variational_classifier(weights, bias, ground_states[j])\n",
    "        \n",
    "        if labels[j] == 0:\n",
    "            cost += proj_00\n",
    "        elif labels[j] == 1:\n",
    "            cost += proj_01\n",
    "        elif labels[j] == 2:\n",
    "            cost += proj_10\n",
    "        else:\n",
    "            cost += proj_11\n",
    "\n",
    "        # adding extra terms to equalize incorrect classes might help in the optimization, \n",
    "        # although it is not required\n",
    "        \"\"\"\n",
    "        if labels[j] == 0:\n",
    "            cost += proj_00 + ((proj_01-proj_10)**2 + (proj_01-proj_11)**2 + (proj_10-proj_11)**2)/3\n",
    "        elif labels[j] == 1:\n",
    "            cost += proj_01 + ((proj_00-proj_10)**2 + (proj_00-proj_11)**2 + (proj_10-proj_11)**2)/3\n",
    "        elif labels[j] == 2:\n",
    "            cost += proj_10 + ((proj_00-proj_01)**2 + (proj_00-proj_11)**2 + (proj_01-proj_11)**2)/3\n",
    "        else:\n",
    "            cost += proj_11 + ((proj_00-proj_01)**2 + (proj_00-proj_10)**2 + (proj_01-proj_10)**2)/3\n",
    "        \"\"\"\n",
    "\n",
    "    return cost/len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_acc(weights, bias, ground_states, labels):\n",
    "    accuracy_data = 0\n",
    "    predictions = []\n",
    "\n",
    "    for j in range(len(labels)):\n",
    "        projectors = variational_classifier(weights, bias, ground_states[j])\n",
    "        pred = np.argmin(projectors)\n",
    "\n",
    "        accuracy_data += 1 if pred == labels[j] else 0\n",
    "        predictions.append(pred)\n",
    "            \n",
    "    return predictions, accuracy_data*100/len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:     1 | Loss: 0.3526673 | Acc train: 9.0909091 | Acc validation: 0.0000000\n",
      "Iter:     2 | Loss: 0.3462436 | Acc train: 9.0909091 | Acc validation: 0.0000000\n",
      "Iter:     3 | Loss: 0.3355559 | Acc train: 9.0909091 | Acc validation: 0.0000000\n",
      "Iter:     4 | Loss: 0.3227274 | Acc train: 9.0909091 | Acc validation: 0.0000000\n",
      "Iter:     5 | Loss: 0.3067356 | Acc train: 9.0909091 | Acc validation: 0.0000000\n",
      "Iter:     6 | Loss: 0.2878650 | Acc train: 0.0000000 | Acc validation: 0.0000000\n",
      "Iter:     7 | Loss: 0.2680066 | Acc train: 0.0000000 | Acc validation: 0.0000000\n",
      "Iter:     8 | Loss: 0.2465625 | Acc train: 0.0000000 | Acc validation: 0.0000000\n",
      "Iter:     9 | Loss: 0.2235251 | Acc train: 9.0909091 | Acc validation: 0.0000000\n",
      "Iter:    10 | Loss: 0.1986237 | Acc train: 9.0909091 | Acc validation: 0.0000000\n",
      "Iter:    11 | Loss: 0.1722219 | Acc train: 9.0909091 | Acc validation: 25.0000000\n",
      "Iter:    12 | Loss: 0.1425949 | Acc train: 18.1818182 | Acc validation: 25.0000000\n",
      "Iter:    13 | Loss: 0.1095512 | Acc train: 18.1818182 | Acc validation: 25.0000000\n",
      "Iter:    14 | Loss: 0.0727761 | Acc train: 27.2727273 | Acc validation: 50.0000000\n",
      "Iter:    15 | Loss: 0.0326513 | Acc train: 36.3636364 | Acc validation: 50.0000000\n",
      "Iter:    16 | Loss: -0.0116671 | Acc train: 45.4545455 | Acc validation: 50.0000000\n",
      "Iter:    17 | Loss: -0.0581004 | Acc train: 45.4545455 | Acc validation: 50.0000000\n",
      "Iter:    18 | Loss: -0.1040597 | Acc train: 45.4545455 | Acc validation: 50.0000000\n",
      "Iter:    19 | Loss: -0.1505844 | Acc train: 45.4545455 | Acc validation: 50.0000000\n",
      "Iter:    20 | Loss: -0.1960888 | Acc train: 45.4545455 | Acc validation: 50.0000000\n",
      "Iter:    21 | Loss: -0.2394140 | Acc train: 45.4545455 | Acc validation: 50.0000000\n",
      "Iter:    22 | Loss: -0.2807494 | Acc train: 45.4545455 | Acc validation: 50.0000000\n",
      "Iter:    23 | Loss: -0.3170638 | Acc train: 45.4545455 | Acc validation: 50.0000000\n",
      "Iter:    24 | Loss: -0.3486280 | Acc train: 45.4545455 | Acc validation: 50.0000000\n",
      "Iter:    25 | Loss: -0.3758663 | Acc train: 45.4545455 | Acc validation: 50.0000000\n",
      "Iter:    26 | Loss: -0.4006165 | Acc train: 45.4545455 | Acc validation: 50.0000000\n",
      "Iter:    27 | Loss: -0.4231494 | Acc train: 45.4545455 | Acc validation: 50.0000000\n",
      "Iter:    28 | Loss: -0.4466027 | Acc train: 45.4545455 | Acc validation: 50.0000000\n",
      "Iter:    29 | Loss: -0.4730103 | Acc train: 45.4545455 | Acc validation: 50.0000000\n",
      "Iter:    30 | Loss: -0.5011970 | Acc train: 45.4545455 | Acc validation: 50.0000000\n",
      "Iter:    31 | Loss: -0.5296314 | Acc train: 45.4545455 | Acc validation: 50.0000000\n",
      "Iter:    32 | Loss: -0.5604485 | Acc train: 45.4545455 | Acc validation: 50.0000000\n",
      "Iter:    33 | Loss: -0.5896991 | Acc train: 45.4545455 | Acc validation: 50.0000000\n",
      "Iter:    34 | Loss: -0.6226490 | Acc train: 45.4545455 | Acc validation: 50.0000000\n",
      "Iter:    35 | Loss: -0.6569516 | Acc train: 45.4545455 | Acc validation: 50.0000000\n",
      "Iter:    36 | Loss: -0.6911237 | Acc train: 45.4545455 | Acc validation: 50.0000000\n",
      "Iter:    37 | Loss: -0.7212904 | Acc train: 45.4545455 | Acc validation: 50.0000000\n",
      "Iter:    38 | Loss: -0.7505426 | Acc train: 45.4545455 | Acc validation: 50.0000000\n",
      "Iter:    39 | Loss: -0.7810348 | Acc train: 45.4545455 | Acc validation: 50.0000000\n",
      "Iter:    40 | Loss: -0.8125228 | Acc train: 45.4545455 | Acc validation: 50.0000000\n",
      "Iter:    41 | Loss: -0.8440041 | Acc train: 45.4545455 | Acc validation: 50.0000000\n",
      "Iter:    42 | Loss: -0.8757120 | Acc train: 45.4545455 | Acc validation: 50.0000000\n",
      "Iter:    43 | Loss: -0.9065217 | Acc train: 45.4545455 | Acc validation: 50.0000000\n",
      "Iter:    44 | Loss: -0.9371585 | Acc train: 45.4545455 | Acc validation: 50.0000000\n",
      "Iter:    45 | Loss: -0.9676829 | Acc train: 45.4545455 | Acc validation: 50.0000000\n",
      "Iter:    46 | Loss: -0.9986296 | Acc train: 45.4545455 | Acc validation: 50.0000000\n",
      "Iter:    47 | Loss: -1.0291909 | Acc train: 45.4545455 | Acc validation: 50.0000000\n",
      "Iter:    48 | Loss: -1.0594073 | Acc train: 45.4545455 | Acc validation: 50.0000000\n",
      "Iter:    49 | Loss: -1.0895535 | Acc train: 45.4545455 | Acc validation: 50.0000000\n",
      "Iter:    50 | Loss: -1.1198792 | Acc train: 45.4545455 | Acc validation: 50.0000000\n",
      "Iter:    51 | Loss: -1.1492865 | Acc train: 45.4545455 | Acc validation: 50.0000000\n",
      "Iter:    52 | Loss: -1.1786155 | Acc train: 45.4545455 | Acc validation: 50.0000000\n",
      "Iter:    53 | Loss: -1.2080742 | Acc train: 45.4545455 | Acc validation: 50.0000000\n",
      "Iter:    54 | Loss: -1.2384852 | Acc train: 45.4545455 | Acc validation: 50.0000000\n",
      "Iter:    55 | Loss: -1.2691914 | Acc train: 45.4545455 | Acc validation: 50.0000000\n",
      "Iter:    56 | Loss: -1.2993587 | Acc train: 45.4545455 | Acc validation: 50.0000000\n",
      "Iter:    57 | Loss: -1.3300662 | Acc train: 45.4545455 | Acc validation: 50.0000000\n",
      "Iter:    58 | Loss: -1.3619172 | Acc train: 45.4545455 | Acc validation: 50.0000000\n",
      "Iter:    59 | Loss: -1.3939535 | Acc train: 45.4545455 | Acc validation: 50.0000000\n",
      "Iter:    60 | Loss: -1.4261803 | Acc train: 45.4545455 | Acc validation: 50.0000000\n"
     ]
    }
   ],
   "source": [
    "if not random:\n",
    "    rng = rand.RandomState(0)\n",
    "\n",
    "# Splitting the data into training and validation\n",
    "num_train = int(perc_train * num_data)\n",
    "index = rng.permutation(range(num_data))\n",
    "gs_train = gs_list[index[:num_train]]\n",
    "labels_train = labels_list[index[:num_train]]\n",
    "gs_val = gs_list[index[num_train:]]\n",
    "labels_val = labels_list[index[num_train:]]\n",
    "\n",
    "# We need these later for plotting\n",
    "j_train = j_list[index[:num_train]]\n",
    "j_val = j_list[index[num_train:]]\n",
    "\n",
    "# weights and bias initialization\n",
    "weights_init = np.random.uniform(0, max_weight_init, nweights, requires_grad=True)\n",
    "bias_init = np.array([0.0]*4, requires_grad=True)\n",
    "\n",
    "# train the variational classifier\n",
    "opt = NesterovMomentumOptimizer(stepsize)\n",
    "weights = []\n",
    "bias = []\n",
    "w = weights_init\n",
    "b = bias_init\n",
    "for it in range(num_iters): #60\n",
    "\n",
    "    # Update the weights by one optimizer step\n",
    "    batch_index = np.random.randint(0, num_train, (batch_size,))\n",
    "    gs_train_batch = gs_train[batch_index]\n",
    "    labels_train_batch = labels_train[batch_index]\n",
    "    \n",
    "    w, b, _, _ = opt.step(loss, w, b, gs_train_batch, labels_train_batch)\n",
    "    weights.append(w)\n",
    "    bias.append(b)\n",
    "    \n",
    "    # Compute predictions and accuracy on train and validation set\n",
    "    pred_train, acc_train = pred_acc(w, b, gs_train, labels_train)\n",
    "    pred_val, acc_val = pred_acc(w, b, gs_val, labels_val)\n",
    "\n",
    "    print(\n",
    "        \"Iter: {:5d} | Loss: {:0.7f} | Acc train: {:0.7f} | Acc validation: {:0.7f}\"\n",
    "        \"\".format(it + 1, loss(w, b, gs_list, labels_list), acc_train, acc_val)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_iter = 100 #it+1\n",
    "\n",
    "plt.figure()\n",
    "cm = plt.cm.RdBu\n",
    "\n",
    "# make data for decision regions\n",
    "xx, yy = np.meshgrid(np.linspace(-1.1, 1.1, 20), np.linspace(-1.1, 1.1, 20))\n",
    "X_grid = [np.array([x, y]) for x, y in zip(xx.flatten(), yy.flatten())]\n",
    "\n",
    "# preprocess grid points like data inputs above\n",
    "padding = 0.3 * np.ones((len(X_grid), 1))\n",
    "X_grid = np.c_[np.c_[X_grid, padding], np.zeros((len(X_grid), 1))]  # pad each input\n",
    "normalization = np.sqrt(np.sum(X_grid ** 2, -1))\n",
    "X_grid = (X_grid.T / normalization).T  # normalize each input\n",
    "features_grid = np.array(\n",
    "    [get_angles(x) for x in X_grid]\n",
    ")  # angles for state preparation are new features\n",
    "predictions_grid = [variational_classifier(weights[plot_iter-1], bias[plot_iter-1], f) for f in features_grid]\n",
    "Z = np.reshape(predictions_grid, xx.shape)\n",
    "\n",
    "# plot decision regions\n",
    "cnt = plt.contourf(\n",
    "    xx, yy, Z, levels=np.arange(-1, 1.1, 0.1), cmap=cm, alpha=0.8, extend=\"both\"\n",
    ")\n",
    "plt.contour(\n",
    "    xx, yy, Z, levels=[0.0], colors=(\"black\",), linestyles=(\"--\",), linewidths=(0.8,)\n",
    ")\n",
    "plt.colorbar(cnt, ticks=[-1, 0, 1])\n",
    "\n",
    "# plot data\n",
    "plt.scatter(\n",
    "    X_train[:, 0][Y_train == 1],\n",
    "    X_train[:, 1][Y_train == 1],\n",
    "    c=\"b\",\n",
    "    marker=\"o\",\n",
    "    edgecolors=\"k\",\n",
    "    label=\"class 1 train\",\n",
    ")\n",
    "plt.scatter(\n",
    "    X_val[:, 0][Y_val == 1],\n",
    "    X_val[:, 1][Y_val == 1],\n",
    "    c=\"b\",\n",
    "    marker=\"^\",\n",
    "    edgecolors=\"k\",\n",
    "    label=\"class 1 validation\",\n",
    ")\n",
    "plt.scatter(\n",
    "    X_train[:, 0][Y_train == -1],\n",
    "    X_train[:, 1][Y_train == -1],\n",
    "    c=\"r\",\n",
    "    marker=\"o\",\n",
    "    edgecolors=\"k\",\n",
    "    label=\"class -1 train\",\n",
    ")\n",
    "plt.scatter(\n",
    "    X_val[:, 0][Y_val == -1],\n",
    "    X_val[:, 1][Y_val == -1],\n",
    "    c=\"r\",\n",
    "    marker=\"^\",\n",
    "    edgecolors=\"k\",\n",
    "    label=\"class -1 validation\",\n",
    ")\n",
    "\n",
    "plt.legend()\n",
    "plt.axis('square')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
