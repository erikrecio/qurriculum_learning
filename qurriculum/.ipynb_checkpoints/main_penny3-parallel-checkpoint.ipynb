{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jax.random\n",
    "import jax.numpy as jnp\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as pnp\n",
    "from pennylane.optimize import NesterovMomentumOptimizer\n",
    "from shapely.geometry import Polygon, Point\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "plt.ioff()\n",
    "\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pytz\n",
    "import ast\n",
    "from pypdf import PdfMerger\n",
    "\n",
    "import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Running parameters\n",
    "num_iters = 1    # Number of training iterations\n",
    "num_runs = 1\n",
    "with_cv = False\n",
    "with_val = False\n",
    "\n",
    "# Circuit and optimization parameters\n",
    "nqubits = 4         # Num qubits, min 4, always 2**num_layers qubits\n",
    "with_bias = False    # Add a bias to the output of the quantum circuit\n",
    "random = True\n",
    "optimizer = \"Adam\"  # \"Adam\", \"Nesterov\", \"GradientDescent\"\n",
    "loss_type = \"cross-entropy\" # \"projectors\", \"cross-entropy\"\n",
    "\n",
    "# Data hyper-parameters\n",
    "batch_size = 100     # batch training size\n",
    "train_size = 100      # Total ground states that will be used for training\n",
    "val_size = 1000      # Total gound states with training + validation\n",
    "cv_ratios = [0.3, 0.2, 0.2, 0.2, 0.1]\n",
    "\n",
    "# How the training data is generated\n",
    "uniform_train = True    # True - Uniform, False - Balanced\n",
    "epsilon_train = True   # True - epsilon, False - no epsilon\n",
    "uniform_val = True\n",
    "epsilon_val = False\n",
    "\n",
    "# Multiprocess hyperparameters. recommended: (num_data, num_cpus) -> (20, 10), (100, 20-30), (200, 40-50) (1000, 50-70)\n",
    "num_cpus_batch = 0 # 20\n",
    "num_cpus_train = 0 # 20\n",
    "num_cpus_val = 0 # 60\n",
    "\n",
    "# Tweak training hyper-parameters\n",
    "max_weight_init = 2*np.pi  # weight_init goes from 0 to this number. Max = 2*np.pi. Other options = 0.01\n",
    "stepsize = 0.01         # stepsize of the gradient descent.\n",
    "\n",
    "# Constant definitions\n",
    "layers = int(np.log2(nqubits))\n",
    "nweights = 30*(layers-1) + 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def X(i):\n",
    "    return qml.PauliX(i)\n",
    "\n",
    "def Z(i):\n",
    "    return qml.PauliZ(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Gound states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ground_state(j1, j2):\n",
    "    \n",
    "    hamiltonian = 0\n",
    "    for i in range(nqubits):\n",
    "        hamiltonian += Z(i)\n",
    "        hamiltonian -= j1 * X(i) @ X((i+1)%nqubits)\n",
    "        hamiltonian -= j2 * X((i-1)%nqubits) @ Z(i) @ X((i+1)%nqubits)\n",
    "    \n",
    "    _, eigvecs = np.linalg.eigh(qml.matrix(hamiltonian))\n",
    "    \n",
    "    return eigvecs[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define coordinates of the points of each region# Definir las coordenadas de los puntos de cada regi√≥n\n",
    "region01_coords = np.array([(-2, 1), (2, 1), (4, 3), (4, 4), (-4, 4), (-4, 3)])    # Class 0\n",
    "region02_coords = np.array([(-3, -4), (0, -1), (3, -4)])                           # Class 0\n",
    "region1_coords = np.array([(0, -1), (3, -4), (4, -4), (4, 3)])                     # Class 1\n",
    "region2_coords = np.array([(0, -1), (-3, -4), (-4, -4), (-4, 3)])                  # Class 2\n",
    "region3_coords = np.array([(-2, 1), (2, 1), (0, -1)])                              # Class 3\n",
    "\n",
    "e = 0.1\n",
    "# Define coordinates of the points of each region far from the borders\n",
    "region01e_coords = np.array([(-2+(np.sqrt(2)-1)*e, 1+e), (2-(np.sqrt(2)-1)*e, 1+e), (4, 3+np.sqrt(2)*e), (4, 4), (-4, 4), (-4, 3+np.sqrt(2)*e)])    # Class 0 with epsilon\n",
    "region02e_coords = np.array([(-3+np.sqrt(2)*e, -4), (0, -1-np.sqrt(2)*e), (3-np.sqrt(2)*e, -4)])                                                    # Class 0 with epsilon\n",
    "region1e_coords = np.array([(0+np.sqrt(2)*e, -1), (3+np.sqrt(2)*e, -4), (4, -4), (4, 3-np.sqrt(2)*e)])                                              # Class 1 with epsilon\n",
    "region2e_coords = np.array([(0-np.sqrt(2)*e, -1), (-3-np.sqrt(2)*e, -4), (-4, -4), (-4, 3-np.sqrt(2)*e)])                                           # Class 2 with epsilon\n",
    "region3e_coords = np.array([(-2+e/np.tan(np.pi/8), 1-e), (2-e/np.tan(np.pi/8), 1-e), (0, -1+np.sqrt(2)*e)])                                         # Class 3 with epsilon\n",
    "\n",
    "\n",
    "def labeling(x, y):\n",
    "\n",
    "    # Create Polygons for each region\n",
    "    region01_poly = Polygon(region01_coords)\n",
    "    region02_poly = Polygon(region02_coords)\n",
    "    region1_poly = Polygon(region1_coords)\n",
    "    region2_poly = Polygon(region2_coords)\n",
    "    region3_poly = Polygon(region3_coords)\n",
    "    \n",
    "    p = Point(x, y)\n",
    "    if region01_poly.contains(p):\n",
    "        return 0\n",
    "    elif region02_poly.contains(p):\n",
    "        return 0\n",
    "    elif region1_poly.contains(p):\n",
    "        return 1\n",
    "    elif region2_poly.contains(p):\n",
    "        return 2\n",
    "    elif region3_poly.contains(p):\n",
    "        return 3\n",
    "    else:\n",
    "        return None # if the point is not in any region\n",
    "    \n",
    "\n",
    "def labeling_epsilon(x, y):\n",
    "    \n",
    "    # Create Polygons for each region\n",
    "    region01e_poly = Polygon(region01e_coords)\n",
    "    region02e_poly = Polygon(region02e_coords)\n",
    "    region1e_poly = Polygon(region1e_coords)\n",
    "    region2e_poly = Polygon(region2e_coords)\n",
    "    region3e_poly = Polygon(region3e_coords)\n",
    "    \n",
    "    \n",
    "    p = Point(x, y)\n",
    "    if region01e_poly.contains(p):\n",
    "        return 0\n",
    "    elif region02e_poly.contains(p):\n",
    "        return 0\n",
    "    elif region1e_poly.contains(p):\n",
    "        return 1\n",
    "    elif region2e_poly.contains(p):\n",
    "        return 2\n",
    "    elif region3e_poly.contains(p):\n",
    "        return 3\n",
    "    else:\n",
    "        return None # if the point is not in any region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate ground states\n",
    "def generate_gs(num_points, uniform, epsilon, num_cpus):\n",
    "\n",
    "    if random:\n",
    "        rng = np.random\n",
    "    else:\n",
    "        rng = np.random.RandomState(0)\n",
    "        \n",
    "\n",
    "    if uniform:\n",
    "        if epsilon:\n",
    "            j_list = []\n",
    "            num = 0\n",
    "            while num < num_points:\n",
    "                j = rng.uniform(-4, 4, 2)\n",
    "                l = labeling_epsilon(j[0], j[1])\n",
    "\n",
    "                if l in [0,1,2,3]:\n",
    "                    num += 1\n",
    "                    j_list.append(j)\n",
    "\n",
    "            j_list = np.array(j_list)\n",
    "            \n",
    "        else:\n",
    "            j_list = rng.uniform(-4, 4, (num_points,2))\n",
    "    \n",
    "    \n",
    "    else: # Then it's balanced\n",
    "        npoints_class = num_points//4\n",
    "        num_points = 4*npoints_class\n",
    "        \n",
    "        npoints_02 = npoints_class//2\n",
    "        npoints_01 = npoints_class - npoints_02\n",
    "        \n",
    "        j_list = []\n",
    "        num_0, num_1, num_2, num_3 = 0, 0, 0, 0\n",
    "        num_01, num_02 = 0, 0\n",
    "        \n",
    "        while num_0 != npoints_class or num_1 != npoints_class or num_2 != npoints_class or num_3 != npoints_class:\n",
    "            j = rng.uniform(-4, 4, 2)\n",
    "            l = labeling_epsilon(j[0], j[1]) if epsilon else labeling(j[0], j[1])\n",
    "\n",
    "            if l==0 and num_0 < npoints_class:\n",
    "                \n",
    "                p = Point(j[0], j[1])\n",
    "                if Polygon(region01_coords).contains(p) and num_01 < npoints_01:\n",
    "                    num_01 += 1\n",
    "                    num_0 += 1\n",
    "                    j_list.append(j)\n",
    "                elif Polygon(region02_coords).contains(p) and num_02 < npoints_02:\n",
    "                    num_02 += 1\n",
    "                    num_0 += 1\n",
    "                    j_list.append(j)\n",
    "                \n",
    "            elif l==1 and num_1 < npoints_class:\n",
    "                num_1 += 1\n",
    "                j_list.append(j)\n",
    "            elif l==2 and num_2 < npoints_class:\n",
    "                num_2 += 1\n",
    "                j_list.append(j)\n",
    "            elif l==3 and num_3 < npoints_class:\n",
    "                num_3 += 1\n",
    "                j_list.append(j)\n",
    "\n",
    "        j_list = np.array(j_list)\n",
    "    \n",
    "    \n",
    "    if num_cpus == 0:\n",
    "        gs_list = []\n",
    "        labels_list = []\n",
    "\n",
    "        for i in range(num_points):\n",
    "            gs_list.append(ground_state(j_list[i,0], j_list[i,1]))\n",
    "            labels_list.append(labeling(j_list[i,0], j_list[i,1]))\n",
    "            \n",
    "    else:\n",
    "        args = [[j_list[i,0], j_list[i,1]] for i in range(num_points)]\n",
    "        \n",
    "        with mp.Pool(num_cpus) as pool:\n",
    "            gs_list = pool.starmap(ground_state, args)\n",
    "        \n",
    "        with mp.Pool(num_cpus) as pool:\n",
    "            labels_list = pool.starmap(labeling, args)\n",
    "            \n",
    "        \n",
    "    gs_list = np.array(gs_list)\n",
    "    labels_list = np.array(labels_list)\n",
    "\n",
    "    return gs_list, labels_list, j_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2)\n",
      "[ 2.12611569 -3.37639534  2.45000649  0.09979407  3.96435009 -1.07803785\n",
      " -2.59183817  3.28342971 -2.80694549  1.59064832  1.53908378  1.88766239\n",
      " -3.39527576 -2.12367675  1.41335459  1.38396754  1.62973072  0.54196749\n",
      " -2.79599334 -2.67731975 -0.29237662  2.7802531  -0.57809252  2.13435367\n",
      " -2.16713796 -3.21287231 -3.47191386 -0.92209651 -3.34452764  2.96391999\n",
      "  2.33096511 -0.39059666 -2.3028582  -0.37293537 -0.10968401 -3.37685385\n",
      " -0.49235625  2.25173347 -1.1850162  -0.20594142  2.42209747  0.43669682\n",
      "  3.84877667  3.94578742 -2.27634508 -1.05295999  2.80995193 -2.5363149\n",
      "  1.14819627 -0.17520086 -2.88125005 -0.3573416   1.95082736 -2.7206305\n",
      " -2.3312757   2.0142146   1.06568167 -2.52420489 -2.9006123   1.13783175\n",
      "  1.91623813  0.29927629  0.09204716  1.95373268  2.2874722   3.66529771\n",
      "  0.90457167 -3.95141965 -2.54569406  0.10459099 -0.13983748 -1.93353052\n",
      " -3.0997225   0.51913604  2.39201067  2.37517378 -1.70429535 -3.17466186\n",
      "  3.23359118  3.0180807  -2.82880352  0.62652825  1.48306442 -0.49236125\n",
      " -3.48024734 -2.37290468  0.79857581 -2.47186801 -3.47340199  0.60248565\n",
      "  3.67852035  0.70627082 -1.8670184   0.97768121 -2.34414     2.79413132\n",
      "  3.8526248  -3.66910314  1.00692236  0.85381494]\n",
      "[ 1.62640041 -3.04884503  1.7553421  -3.42398304 -0.85287495  2.11207324\n",
      "  1.92739634 -3.41962442  0.9409457  -2.80702425 -3.58918699  2.15257872\n",
      "  0.94184441  2.74046768 -2.24527337  1.82931674 -0.21114455 -1.05171242\n",
      " -1.03375045 -0.82614986  3.94864318  3.05742083 -0.05940952 -3.99665456\n",
      " -0.91034329  0.81431574  0.68735425 -1.09505433  1.09472914 -2.0482953\n",
      " -2.79090766 -0.96917393 -1.66728487  0.14006232 -1.6931327  -2.25198145\n",
      "  3.29501617  1.53914046 -3.57739367  1.40575977 -3.6033223   3.59703788\n",
      " -1.82122381 -2.78369671  0.04101205  1.44988603  3.49592997 -1.8238905\n",
      " -3.61286357 -0.24215259  2.78332905 -1.52893612 -0.90591815 -1.81806112\n",
      " -3.62884058  3.95788142 -2.96899881 -3.9861147   0.40560757  0.69010186\n",
      " -0.93379551 -3.71341923 -2.41395445 -3.8803028   3.29367358  3.30749688\n",
      "  3.80193479  0.30583103  1.33684632 -1.4638888   3.49744282 -0.4146232\n",
      " -1.29731063 -2.30778915  3.0598439  -1.54201743  3.16355454 -1.4177699\n",
      "  0.2151629   3.14002888  1.25557807 -3.12541602 -2.97436302  3.65632164\n",
      " -3.79722036  0.64432817  2.59279739 -2.0559205  -3.30904788 -2.85610723\n",
      "  0.20612258  3.39914133  1.87287998  1.1981124   3.30396017 -2.41330365\n",
      " -1.27862527  0.35030382 -3.14893495  0.85979688]\n"
     ]
    }
   ],
   "source": [
    "if random:\n",
    "    rng = np.random\n",
    "else:\n",
    "    rng = np.random.RandomState(0)\n",
    "\n",
    "if uniform_train:\n",
    "    if epsilon_train:\n",
    "        j_list = []\n",
    "        num = 0\n",
    "        while num < train_size:\n",
    "            j = rng.uniform(-4, 4, 2)\n",
    "            l = labeling_epsilon(j[0], j[1])\n",
    "\n",
    "            if l in [0,1,2,3]:\n",
    "                num += 1\n",
    "                j_list.append(j)\n",
    "\n",
    "        j_list = np.array(j_list)\n",
    "\n",
    "    else:\n",
    "        j_list = rng.uniform(-4, 4, (train_size,2))\n",
    "\n",
    "\n",
    "else: # Then it's balanced\n",
    "    npoints_class = train_size//4\n",
    "    train_size = 4*npoints_class\n",
    "\n",
    "    npoints_02 = npoints_class//2\n",
    "    npoints_01 = npoints_class - npoints_02\n",
    "\n",
    "    j_list = []\n",
    "    num_0, num_1, num_2, num_3 = 0, 0, 0, 0\n",
    "    num_01, num_02 = 0, 0\n",
    "\n",
    "    while num_0 != npoints_class or num_1 != npoints_class or num_2 != npoints_class or num_3 != npoints_class:\n",
    "        j = rng.uniform(-4, 4, 2)\n",
    "        l = labeling_epsilon(j[0], j[1]) if epsilon else labeling(j[0], j[1])\n",
    "\n",
    "        if l==0 and num_0 < npoints_class:\n",
    "\n",
    "            p = Point(j[0], j[1])\n",
    "            if Polygon(region01_coords).contains(p) and num_01 < npoints_01:\n",
    "                num_01 += 1\n",
    "                num_0 += 1\n",
    "                j_list.append(j)\n",
    "            elif Polygon(region02_coords).contains(p) and num_02 < npoints_02:\n",
    "                num_02 += 1\n",
    "                num_0 += 1\n",
    "                j_list.append(j)\n",
    "\n",
    "        elif l==1 and num_1 < npoints_class:\n",
    "            num_1 += 1\n",
    "            j_list.append(j)\n",
    "        elif l==2 and num_2 < npoints_class:\n",
    "            num_2 += 1\n",
    "            j_list.append(j)\n",
    "        elif l==3 and num_3 < npoints_class:\n",
    "            num_3 += 1\n",
    "            j_list.append(j)\n",
    "\n",
    "    j_list = np.array(j_list)\n",
    "    \n",
    "\n",
    "print(j_list.shape)\n",
    "print(j_list[:,0])\n",
    "print(j_list[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convolutional_layer(q1, q2, weights):\n",
    "    qml.U3(wires=q1, theta=weights[0], phi=weights[1], delta=weights[2])\n",
    "    qml.U3(wires=q1, theta=weights[3], phi=weights[4], delta=weights[5])\n",
    "    qml.CNOT(wires=[q2, q1])\n",
    "    qml.RZ(wires=q1, phi=weights[6])\n",
    "    qml.RY(wires=q2, phi=weights[7])\n",
    "    qml.CNOT(wires=[q1, q2])\n",
    "    qml.RY(wires=q2, phi=weights[8])\n",
    "    qml.CNOT(wires=[q2, q1])\n",
    "    qml.U3(wires=q1, theta=weights[9], phi=weights[10], delta=weights[11])\n",
    "    qml.U3(wires=q1, theta=weights[12], phi=weights[13], delta=weights[14])\n",
    "\n",
    "def pooling_layer(q1, q2, weights):\n",
    "    qml.U3(wires=q1, theta=weights[0], phi=weights[1], delta=weights[2])\n",
    "    qml.U3(wires=q1, theta=weights[3], phi=weights[4], delta=weights[5])\n",
    "    qml.CNOT(wires=[q2, q1])\n",
    "    qml.RZ(wires=q1, phi=weights[6])\n",
    "    qml.RY(wires=q2, phi=weights[7])\n",
    "    qml.CNOT(wires=[q1, q2])\n",
    "    qml.RY(wires=q2, phi=weights[8])\n",
    "    qml.CNOT(wires=[q2, q1])\n",
    "    qml.U3(wires=q1, theta=weights[9], phi=weights[10], delta=weights[11])\n",
    "    qml.U3(wires=q1, theta=weights[12], phi=weights[13], delta=weights[14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_circuit(weights, state_ini):\n",
    "    \n",
    "    qubits = list(range(nqubits))\n",
    "    \n",
    "    qml.QubitStateVector(state_ini, wires=qubits)\n",
    "\n",
    "    for j in range(layers-1):\n",
    "        \n",
    "        len_qubits = len(qubits)\n",
    "        \n",
    "        for i in range(len_qubits//2):\n",
    "            convolutional_layer(qubits[2*i], qubits[(2*i+1)%len_qubits], weights[15*2*j:15*(2*j+1)])\n",
    "        \n",
    "        for i in range(len_qubits//2):\n",
    "            convolutional_layer(qubits[2*i+1], qubits[(2*i+2)%len_qubits], weights[15*2*j:15*(2*j+1)])\n",
    "            \n",
    "        for i in range(len_qubits//2):\n",
    "            pooling_layer(qubits[2*i], qubits[(2*i+1)%len_qubits], weights[15*(2*j+1):15*(2*j+2)])\n",
    "\n",
    "        qub = []\n",
    "        for i in range(len_qubits):\n",
    "            if i%2 == 1:\n",
    "                qub.append(qubits[i])\n",
    "                \n",
    "        qubits = qub\n",
    "    \n",
    "    convolutional_layer(qubits[0], qubits[1], weights[15*(2*layers-2):15*(2*layers-1)])\n",
    "    \n",
    "    return qml.expval(Z(qubits[0])), qml.expval(Z(qubits[1])), qml.expval(Z(qubits[0]) @ Z(qubits[1]))\n",
    "\n",
    "# dev_draw = qml.device(\"qiskit.aer\", wires=nqubits)\n",
    "dev = qml.device(\"default.qubit\", wires=nqubits)\n",
    "\n",
    "# cnn_draw = qml.QNode(cnn_circuit, dev_draw)\n",
    "cnn_circuit = qml.QNode(cnn_circuit, dev, interface=\"jax\", diff_method=\"best\")\n",
    "\n",
    "\n",
    "def cnn(weights, state_ini):\n",
    "    z0, z1, zz01 = cnn_circuit(weights, state_ini)\n",
    "\n",
    "    proj_00 = (1+zz01+z0+z1)/4\n",
    "    proj_01 = (1-zz01-z0+z1)/4\n",
    "    proj_10 = (1-zz01+z0-z1)/4\n",
    "    proj_11 = (1+zz01-z0-z1)/4\n",
    "\n",
    "    return jnp.array([proj_00, proj_01, proj_10, proj_11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def variational_classifier(weights, bias, state_ini):\n",
    "    return cnn(weights, state_ini) + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# draw circuit\n",
    "\n",
    "# weights = np.random.uniform(0, 2*np.pi, nweights)\n",
    "# drawer = qml.draw(cnn_circuit)\n",
    "# print(drawer(weights, gs_list[0]))\n",
    "\n",
    "# z0, z1, zz01 = cnn_draw(gs_list[0], weights)\n",
    "# print(z0, z1, zz01)\n",
    "# dev_draw._circuit.draw(output=\"mpl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def single_loss(weights, bias, ground_state, label):\n",
    "    \n",
    "    proj = variational_classifier(weights, bias, ground_state)\n",
    "\n",
    "    if loss_type == \"projectors\":\n",
    "            cost = proj[label]\n",
    "\n",
    "    elif loss_type == \"cross-entropy\":\n",
    "        \n",
    "            # if isinstance(proj[label], pnp._np.numpy_boxes.ArrayBox):\n",
    "            #     cost = -log2_arraybox(proj[label])\n",
    "            # else:\n",
    "            #     cost = -np.log2(proj[label])\n",
    "                \n",
    "        cost = -jnp.log2(proj[label])\n",
    "    \n",
    "    return cost\n",
    "\n",
    "@jax.jit\n",
    "def loss(weights, bias, ground_states, labels, num_cpus):\n",
    "    \n",
    "    # cost=0\n",
    "    # for j in range(len(labels)):\n",
    "    #     cost += single_loss(weights, bias, ground_states[j], labels[j])\n",
    "        \n",
    "    costs = jax.vmap(single_loss, in_axes=[None, None, 0, 0])(weights, bias, ground_states, labels)\n",
    "    cost = costs.sum()\n",
    "    \n",
    "    return cost/len(labels)\n",
    "\n",
    "@jax.jit\n",
    "def grad_loss(weight, bias, ground_states, labels, _):\n",
    "    w, b = jax.grad(loss, argnums=[0,1])(weight, bias, ground_states, labels, None)\n",
    "    return w, b, None, None, None # maybe same array shape as input? jnp.zeros?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def single_pred(weights, bias, ground_state):\n",
    "    \n",
    "    projectors = variational_classifier(weights, bias, ground_state)\n",
    "    \n",
    "    if loss_type == \"projectors\":\n",
    "        pred = np.argmin(projectors)\n",
    "    elif loss_type == \"cross-entropy\":\n",
    "        pred = np.argmax(projectors)\n",
    "\n",
    "    return pred\n",
    "\n",
    "@partial(jax.jit, static_argnums=3)\n",
    "def pred(weights, bias, ground_states, num_cpus):\n",
    "    \n",
    "    if num_cpus == 0:\n",
    "        predictions = []\n",
    "        \n",
    "        for j in range(len(ground_states)):\n",
    "            predictions.append(single_pred(weights, bias, ground_states[j]))\n",
    "        \n",
    "        predictions = np.array(predictions)\n",
    "        \n",
    "    else:\n",
    "        predictions = jax.vmap(single_pred, in_axes=[None, None, 0])(weights, bias, ground_states)\n",
    "            \n",
    "    return predictions\n",
    "\n",
    "@jax.jit\n",
    "def acc(predictions, labels):\n",
    "    return sum(predictions==labels)*100/len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_multi_image(filename):\n",
    "    pp = PdfPages(filename)\n",
    "    fig_nums = plt.get_fignums()\n",
    "    figs = [plt.figure(n) for n in fig_nums]\n",
    "    for fig in figs:\n",
    "        fig.savefig(pp, format='pdf')\n",
    "    pp.close()\n",
    "\n",
    "def close_all_figures():\n",
    "    fig_nums = plt.get_fignums()\n",
    "    for n in fig_nums:\n",
    "        plt.figure(n)\n",
    "        plt.close()\n",
    "\n",
    "        \n",
    "def save_plots(time_now,\n",
    "               folder_name,\n",
    "               file_name,\n",
    "               plot_run,\n",
    "               it_max,\n",
    "               acc_train,\n",
    "               acc_val,\n",
    "               losses,\n",
    "               pred_train,\n",
    "               pred_val,\n",
    "               j_train,\n",
    "               j_val\n",
    "              ):\n",
    "\n",
    "\n",
    "    fig, axis = plt.subplots(1,3)\n",
    "    fig.set_figheight(6.5)\n",
    "    fig.set_figwidth(20)\n",
    "    fig.tight_layout(pad=2, w_pad=3.5)\n",
    "\n",
    "    # ---------------------------------------------------------------------- #\n",
    "    # -------------------- Loss and accuracy figure ------------------------ #\n",
    "    # ---------------------------------------------------------------------- #\n",
    "\n",
    "    iterations = range(1, num_iters+1)\n",
    "\n",
    "    color1 = 'darkred'\n",
    "    axis[0].set_xlabel('Iterations')\n",
    "    axis[0].set_ylabel('Accuracy %', color=color1)\n",
    "    axis[0].plot(iterations, acc_train, label=\"Training\", color=color1)\n",
    "    axis[0].plot(iterations, acc_val, '-.', label=\"Validation\", color=color1)\n",
    "    axis[0].tick_params(axis='y', labelcolor=color1)\n",
    "    axis[0].set_ylim(0,100)\n",
    "\n",
    "    ax2 = axis[0].twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "    color2 = 'darkblue'\n",
    "    ax2.set_ylabel('Loss', color=color2)  # we already handled the x-label with axis[0]\n",
    "    ax2.plot(iterations, losses, label=\"Loss\", color=color2)\n",
    "    ax2.tick_params(axis='y', labelcolor=color2)\n",
    "    # ax2.set_ylim(bottom=0)\n",
    "\n",
    "    # fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "    # plt.legend()\n",
    "    axis[0].set_title(f\"Accuracy and Loss - Run {plot_run}\")\n",
    "\n",
    "\n",
    "    # ---------------------------------------------------------------------- #\n",
    "    # ---------------------------- Max iter -------------------------------- #\n",
    "    # ---------------------------------------------------------------------- #\n",
    "\n",
    "    plot_iter = it_max\n",
    "\n",
    "    # define regions coordinates\n",
    "    x01, y01 = region01_coords[:,0], region01_coords[:,1]\n",
    "    x02, y02 = region02_coords[:,0], region02_coords[:,1]\n",
    "    x1, y1 = region1_coords[:,0], region1_coords[:,1]\n",
    "    x2, y2 = region2_coords[:,0], region2_coords[:,1]\n",
    "    x3, y3 = region3_coords[:,0], region3_coords[:,1]\n",
    "\n",
    "    # put the regions into the plot\n",
    "    axis[1].fill(x01, y01, facecolor='lightskyblue')    # class 0\n",
    "    axis[1].fill(x02, y02, facecolor='lightskyblue')    # class 0\n",
    "    axis[1].fill(x1, y1, facecolor='sandybrown')        # class 1\n",
    "    axis[1].fill(x2, y2, facecolor='salmon')            # class 2\n",
    "    axis[1].fill(x3, y3, facecolor='lightgreen')        # class 3\n",
    "\n",
    "    pred_train_plot = np.array(pred_train[plot_iter])\n",
    "    pred_val_plot = np.array(pred_val[plot_iter])\n",
    "\n",
    "    colors = [\"b\", \"orange\", \"r\", \"g\"]\n",
    "\n",
    "    # plot datapoints\n",
    "    for i in range(4):\n",
    "        axis[1].scatter(\n",
    "            j_train[:, 0][pred_train_plot==i],\n",
    "            j_train[:, 1][pred_train_plot==i],\n",
    "            c=colors[i],\n",
    "            marker=\"o\",\n",
    "            edgecolors=\"k\",\n",
    "            label=f\"class {i+1} train\",\n",
    "        )\n",
    "        if with_val:\n",
    "            axis[1].scatter(\n",
    "                j_val[:, 0][pred_val_plot==i],\n",
    "                j_val[:, 1][pred_val_plot==i],\n",
    "                c=colors[i],\n",
    "                marker=\"^\",\n",
    "                edgecolors=\"k\",\n",
    "                label=f\"class {i+1} validation\",\n",
    "            )\n",
    "\n",
    "\n",
    "    # plt.legend()\n",
    "    axis[1].set_title(f\"Max iteration ({acc_train[plot_iter]:.0f}%/{acc_val[plot_iter]:.0f}%)\")\n",
    "\n",
    "\n",
    "    # ---------------------------------------------------------------------- #\n",
    "    # ---------------------------- Last iter ------------------------------- #\n",
    "    # ---------------------------------------------------------------------- #\n",
    "\n",
    "\n",
    "    plot_iter = num_iters-1\n",
    "\n",
    "    # define regions coordinates\n",
    "    x01, y01 = region01_coords[:,0], region01_coords[:,1]\n",
    "    x02, y02 = region02_coords[:,0], region02_coords[:,1]\n",
    "    x1, y1 = region1_coords[:,0], region1_coords[:,1]\n",
    "    x2, y2 = region2_coords[:,0], region2_coords[:,1]\n",
    "    x3, y3 = region3_coords[:,0], region3_coords[:,1]\n",
    "\n",
    "    # put the regions into the plot\n",
    "    axis[2].fill(x01, y01, facecolor='lightskyblue')    # class 0\n",
    "    axis[2].fill(x02, y02, facecolor='lightskyblue')    # class 0\n",
    "    axis[2].fill(x1, y1, facecolor='sandybrown')        # class 1\n",
    "    axis[2].fill(x2, y2, facecolor='salmon')            # class 2\n",
    "    axis[2].fill(x3, y3, facecolor='lightgreen')        # class 3\n",
    "\n",
    "    pred_train_plot = np.array(pred_train[plot_iter])\n",
    "    pred_val_plot = np.array(pred_val[plot_iter])\n",
    "\n",
    "    colors = [\"b\", \"orange\", \"r\", \"g\"]\n",
    "\n",
    "    # plot datapoints\n",
    "    for i in range(4):\n",
    "        axis[2].scatter(\n",
    "            j_train[:, 0][pred_train_plot==i],\n",
    "            j_train[:, 1][pred_train_plot==i],\n",
    "            c=colors[i],\n",
    "            marker=\"o\",\n",
    "            edgecolors=\"k\",\n",
    "            label=f\"class {i+1} train\",\n",
    "        )\n",
    "        if with_val:\n",
    "            axis[2].scatter(\n",
    "                j_val[:, 0][pred_val_plot==i],\n",
    "                j_val[:, 1][pred_val_plot==i],\n",
    "                c=colors[i],\n",
    "                marker=\"^\",\n",
    "                edgecolors=\"k\",\n",
    "                label=f\"class {i+1} validation\",\n",
    "            )\n",
    "\n",
    "\n",
    "    # plt.legend()\n",
    "    axis[2].set_title(f\"Last iteration ({acc_train[plot_iter]:.0f}%/{acc_val[plot_iter]:.0f}%)\")\n",
    "\n",
    "    # ---------------------------------------------------------------------- #\n",
    "    # --------------------------- Save plots ------------------------------- #\n",
    "    # ---------------------------------------------------------------------- #\n",
    "\n",
    "    plots_pdf_name = f\"{folder_name}/{time_now} - Plots - {file_name}.pdf\"\n",
    "    \n",
    "    \n",
    "    # If the file doesn't exist we save it. If it does, we merge it.\n",
    "    if not os.path.isfile(plots_pdf_name):\n",
    "        save_multi_image(plots_pdf_name)\n",
    "    \n",
    "    else:\n",
    "        save_multi_image(plots_pdf_name + \"2\")\n",
    "        # Merge the new plot with the rest and delete the last file\n",
    "        merger = PdfMerger()\n",
    "        merger.append(plots_pdf_name)\n",
    "        merger.append(plots_pdf_name + \"2\")\n",
    "        merger.write(plots_pdf_name)\n",
    "        merger.close()\n",
    "        os.remove(plots_pdf_name + \"2\")\n",
    "    \n",
    "    close_all_figures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_hyperparameters(time_now, folder_name, file_name):\n",
    "    \n",
    "    # --------------- Hyperparameters -----------------#\n",
    "    hyperparameters = {}\n",
    "    hyperparameters[\"num_iters\"] = [num_iters]\n",
    "    hyperparameters[\"num_runs\"] = [num_runs]\n",
    "    hyperparameters[\"with_cv\"] = [with_cv]\n",
    "    hyperparameters[\"with_val\"] = [with_val]\n",
    "    hyperparameters[\"nqubits\"] = [nqubits]\n",
    "    hyperparameters[\"with_bias\"] = [with_bias]\n",
    "    hyperparameters[\"random\"] = [random]\n",
    "    hyperparameters[\"optimizer\"] = [optimizer]\n",
    "    hyperparameters[\"loss_type\"] = [loss_type]\n",
    "    hyperparameters[\"batch_size\"] = [batch_size]\n",
    "    hyperparameters[\"train_size\"] = [train_size]\n",
    "    hyperparameters[\"val_size\"] = [val_size]\n",
    "    hyperparameters[\"cv_ratios\"] = [cv_ratios]\n",
    "    hyperparameters[\"uniform_train\"] = [uniform_train]\n",
    "    hyperparameters[\"epsilon_train\"] = [epsilon_train]\n",
    "    hyperparameters[\"uniform_val\"] = [uniform_val]\n",
    "    hyperparameters[\"epsilon_val\"] = [epsilon_val]\n",
    "    hyperparameters[\"num_cpus_batch\"] = [num_cpus_batch]\n",
    "    hyperparameters[\"num_cpus_train\"] = [num_cpus_train]\n",
    "    hyperparameters[\"num_cpus_val\"] = [num_cpus_val]\n",
    "    hyperparameters[\"max_weight_init\"] = [max_weight_init]\n",
    "    hyperparameters[\"stepsize\"] = [stepsize]\n",
    "\n",
    "    hyperparameters = pd.DataFrame(hyperparameters)\n",
    "\n",
    "    hyperparameters_file_name = f\"{folder_name}/{time_now} - Hyperparameters{file_name}.csv\"\n",
    "    hyperparameters.to_csv(hyperparameters_file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(time_now,\n",
    "                folder_name,\n",
    "                run,\n",
    "                weights,\n",
    "                bias,\n",
    "                losses,\n",
    "                j_train,\n",
    "                j_val,\n",
    "                pred_train,\n",
    "                pred_val,\n",
    "                acc_train,\n",
    "                acc_val,\n",
    "                run_time,\n",
    "                cv\n",
    "               ):\n",
    "    \n",
    "    if cv:\n",
    "        file_name = f\"CV\"# - {train_size} Train - {val_size} Val\"\n",
    "    else:\n",
    "        file_name = f\"NCV\"# - {train_size} Train - {val_size} Val\"\n",
    "        \n",
    "    # -------------------- Total Data -------------------- #\n",
    "    data = {}\n",
    "    data[\"run\"] = run\n",
    "    \n",
    "    it_max = np.argmax(np.array(acc_train))\n",
    "    acc_train_max = acc_train[it_max]\n",
    "    acc_train_last = acc_train[num_iters-1]\n",
    "    acc_val_max = acc_val[it_max]\n",
    "    acc_val_last = acc_val[num_iters-1]\n",
    "    \n",
    "    data[\"it_max\"] = it_max\n",
    "    data[\"acc_train_max\"] = acc_train_max\n",
    "    data[\"acc_train_last\"] = acc_train_last\n",
    "    data[\"acc_val_max\"] = acc_val_max\n",
    "    data[\"acc_val_last\"] = acc_val_last\n",
    "    data[\"run_time\"] = run_time\n",
    "    \n",
    "    data[\"weights\"] = [weights]\n",
    "    data[\"bias\"] = [bias]\n",
    "    data[\"losses\"] = [losses]\n",
    "    data[\"j_train\"] = [j_train]\n",
    "    data[\"j_val\"] = [j_val]\n",
    "    data[\"pred_train\"] = [pred_train]\n",
    "    data[\"pred_val\"] = [pred_val]\n",
    "    data[\"acc_train\"] = [acc_train]\n",
    "    data[\"acc_val\"] = [acc_val]\n",
    "    \n",
    "\n",
    "    data = pd.DataFrame(data)\n",
    "    \n",
    "    data_file_name = f\"{folder_name}/{time_now} - Data - {file_name}.csv\"\n",
    "    data.to_csv(data_file_name, mode='a', index=False, header=not os.path.exists(data_file_name))\n",
    "    \n",
    "    \n",
    "    # ------------------- Results ------------------- #\n",
    "    \n",
    "    read_data = pd.read_csv(data_file_name,\n",
    "                     usecols=[\"it_max\",\n",
    "                              \"acc_train_max\",\n",
    "                              \"acc_val_max\",\n",
    "                              \"acc_train\",\n",
    "                              \"acc_val\"],\n",
    "                     converters={\"acc_train\":ast.literal_eval,\n",
    "                                 \"acc_val\":ast.literal_eval})\n",
    "    \n",
    "    total_it_max = read_data[\"it_max\"]\n",
    "    total_acc_train_max = read_data[\"acc_train_max\"]\n",
    "    total_acc_val_max = read_data[\"acc_val_max\"]\n",
    "    total_acc_train = read_data[\"acc_train\"].tolist()\n",
    "    total_acc_val = read_data[\"acc_val\"].tolist()\n",
    "    \n",
    "    best_run_max = total_acc_train_max.argmax()\n",
    "    best_it_max = total_it_max[best_run_max]\n",
    "    avg_acc_train_max = total_acc_train_max.mean()\n",
    "    avg_acc_val_max = total_acc_val_max.mean()\n",
    "    \n",
    "    best_run_last = np.argmax(np.array(total_acc_train)[:,num_iters-1])\n",
    "    avg_acc_train_last = np.mean(np.array(total_acc_train)[:,num_iters-1])\n",
    "    avg_acc_val_last = np.mean(np.array(total_acc_val)[:,num_iters-1])\n",
    "\n",
    "    \n",
    "    results = {}\n",
    "    results[\"num_runs\"] = [run+1]\n",
    "    results[\"best_run_max\"] = [best_run_max]\n",
    "    results[\"best_run_last\"] = [best_run_last]\n",
    "    results[\"best_it_max\"] = [best_it_max]\n",
    "    results[\"best_it_last\"] = [num_iters-1]\n",
    "    results[\"best_acc_train_max\"] = [total_acc_train[best_run_max][best_it_max]]\n",
    "    results[\"best_acc_train_last\"] = [total_acc_train[best_run_max][num_iters-1]]\n",
    "    results[\"best_acc_val_max\"] = [total_acc_val[best_run_max][best_it_max]]\n",
    "    results[\"best_acc_val_last\"] = [total_acc_val[best_run_max][num_iters-1]]\n",
    "    results[\"avg_acc_train_max\"] = [avg_acc_train_max]\n",
    "    results[\"avg_acc_train_last\"] = [avg_acc_train_last]\n",
    "    results[\"avg_acc_val_max\"] = [avg_acc_val_max]\n",
    "    results[\"avg_acc_val_last\"] = [avg_acc_val_last]\n",
    "\n",
    "    results = pd.DataFrame(results)\n",
    "\n",
    "    results_file_name = f\"{folder_name}/{time_now} - Results - {file_name}.csv\"\n",
    "    results.to_csv(results_file_name, index=False)\n",
    "    \n",
    "    \n",
    "    # ------------------- Plots ------------------- #\n",
    "    save_plots(time_now,\n",
    "               folder_name,\n",
    "               file_name,\n",
    "               run,\n",
    "               it_max,\n",
    "               acc_train,\n",
    "               acc_val,\n",
    "               losses,\n",
    "               pred_train,\n",
    "               pred_val,\n",
    "               j_train,\n",
    "               j_val\n",
    "              )\n",
    "    \n",
    "    if cv:\n",
    "        cv_str = \"True \"\n",
    "    else:\n",
    "        cv_str = \"False\"\n",
    "        \n",
    "    print(\n",
    "        f\" {cv_str} |\"\n",
    "        f\" {run:3d} |\"\n",
    "        f\" {it_max:4d}/{num_iters-1:4d} |\"\n",
    "        f\"  {acc_train[it_max]:0.0f}/{acc_train[num_iters-1]:0.0f}  |\"\n",
    "        f\" {acc_val[it_max]:0.0f}/{acc_val[num_iters-1]:0.0f} |\"\n",
    "        f\" {run_time:0.0f}\"\n",
    "    )\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_qcnn(gs_train, gs_val, labels_train, labels_val, cv):\n",
    "        \n",
    "    if random:\n",
    "        rng = np.random\n",
    "    else:\n",
    "        rng = np.random.RandomState(0)\n",
    "        \n",
    "    # weights and bias initialization\n",
    "    #weights_init = jax.random.uniform(0, max_weight_init, nweights)\n",
    "    key = jax.random.PRNGKey(0)\n",
    "    weights_init = jax.random.uniform(key, [nweights], minval=0, maxval=max_weight_init)\n",
    "    bias_init = jnp.array([0.0]*4)\n",
    "\n",
    "    # choose variational classifier\n",
    "    if optimizer == \"Nesterov\":\n",
    "        opt = NesterovMomentumOptimizer(stepsize)\n",
    "    elif optimizer == \"Adam\":\n",
    "        opt = qml.AdamOptimizer(stepsize=stepsize, beta1=0.9, beta2=0.99, eps=1e-08)\n",
    "    elif optimizer == \"GradientDescent\":\n",
    "        opt = qml.GradientDescentOptimizer(stepsize)\n",
    "\n",
    "    #Initiaize variables\n",
    "    weights = []\n",
    "    bias = []\n",
    "    losses = []\n",
    "    pred_train_arr = []\n",
    "    pred_val_arr = []\n",
    "    acc_train_arr = []\n",
    "    acc_val_arr = []\n",
    "\n",
    "    w = weights_init\n",
    "    b = bias_init\n",
    "    \n",
    "    for it in range(num_iters):\n",
    "        \n",
    "        if cv:\n",
    "            cv_size_batches, cv_limits_it = [], []\n",
    "            limit_iter, size_batch = 0, 0\n",
    "            \n",
    "            for i, ratio in enumerate(cv_ratios):\n",
    "                \n",
    "                if i < len(cv_ratios)-1:\n",
    "                    limit_iter += round(ratio*num_iters)\n",
    "                    size_batch += round(ratio*len(labels_train))\n",
    "                else:\n",
    "                    limit_iter = num_iters\n",
    "                    size_batch = len(labels_train)\n",
    "                \n",
    "                cv_limits_it.append(limit_iter)\n",
    "                cv_size_batches.append(size_batch)\n",
    "            \n",
    "            index_size_batch = np.argmax(it < np.array(cv_limits_it)) # This gives you the first occurrence where the condition is met\n",
    "            cv_size_batch = cv_size_batches[index_size_batch]\n",
    "            \n",
    "            gs_train_batch = gs_train[:cv_size_batch]\n",
    "            labels_train_batch = labels_train[:cv_size_batch]\n",
    "        \n",
    "        else:\n",
    "            batch_index = np.random.default_rng().choice(len(labels_train), size=batch_size, replace=False)\n",
    "            \n",
    "            gs_train_batch = gs_train[batch_index]\n",
    "            labels_train_batch = labels_train[batch_index]\n",
    "\n",
    "            \n",
    "        # Update the weights by one optimizer step\n",
    "        if num_cpus_batch == 0:\n",
    "            w, b, _, _, _ = opt.step(loss, w, b, gs_train_batch, labels_train_batch, 0)\n",
    "\n",
    "        else:\n",
    "            w, b, _, _, _ = opt.step(loss, w, b, gs_train_batch, labels_train_batch, num_cpus_batch, grad_fn=grad_loss)\n",
    "            \n",
    "#             args = [[single_loss, w, b, gs_train_batch[j], labels_train_batch[j]] for j in range(len(labels_train_batch))]\n",
    "\n",
    "#             with mp.Pool(num_cpus_batch) as pool:\n",
    "#                 w, b, _, _ = zip(*pool.starmap(opt.step, args))\n",
    "\n",
    "#             w = sum(w)/len(w)\n",
    "#             b = sum(b)/len(b)\n",
    "\n",
    "        weights.append(w)\n",
    "        bias.append(b)\n",
    "\n",
    "        # Compute predictions and accuracy on train and validation set\n",
    "        pred_train = pred(w, b, gs_train, num_cpus_train)\n",
    "        if with_val:\n",
    "            pred_val = pred(w, b, gs_val, num_cpus_val) if len(labels_val) > 0 else None\n",
    "        else:\n",
    "            pred_val = np.array([0]*len(labels_val))\n",
    "        \n",
    "        acc_train = acc(pred_train, labels_train)\n",
    "        if with_val:\n",
    "            acc_val = acc(pred_val, labels_val) if len(labels_val) > 0 else 0\n",
    "        else:\n",
    "            acc_val = 0\n",
    "        \n",
    "        # Save prediction for later plotting\n",
    "        pred_train_arr.append(pred_train)\n",
    "        pred_val_arr.append(pred_val)\n",
    "        acc_train_arr.append(acc_train)\n",
    "        acc_val_arr.append(acc_val)\n",
    "\n",
    "        l = loss(w, b, gs_train, labels_train, num_cpus_train)\n",
    "        losses.append(l)\n",
    "    \n",
    "    return weights, bias, losses, pred_train_arr, pred_val_arr, acc_train_arr, acc_val_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max train / Last run\n",
      "---------------------------------------------------\n",
      "  CV   | Run |   Iter    |Acc train|Acc val| Time  \n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "ename": "TracerArrayConversionError",
     "evalue": "The numpy.ndarray conversion method __array__() was called on traced array with shape int64[].\nThe error occurred while tracing the function pred at /tmp/ipykernel_3564963/2856908872.py:13 for jit. This value became a tracer due to JAX operations on these lines:\n\n  operation a:i64[] = convert_element_type[new_dtype=int64 weak_type=True] b\n    from line /tmp/ipykernel_3564963/2856908872.py:20 (pred)\n\n  operation a:i64[] = convert_element_type[new_dtype=int64 weak_type=True] b\n    from line /tmp/ipykernel_3564963/2856908872.py:20 (pred)\n\n  operation a:i64[] = convert_element_type[new_dtype=int64 weak_type=False] b\n    from line /tmp/ipykernel_3564963/2856908872.py:20 (pred)\n\n  operation a:bool[] = lt b c\n    from line /tmp/ipykernel_3564963/2856908872.py:20 (pred)\n\n  operation a:i64[] = convert_element_type[new_dtype=int64 weak_type=False] b\n    from line /tmp/ipykernel_3564963/2856908872.py:20 (pred)\n\n(Additional originating lines are not shown.)\nSee https://jax.readthedocs.io/en/latest/errors.html#jax.errors.TracerArrayConversionError",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTracerArrayConversionError\u001b[0m                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[350], line 39\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------ #\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# ------------------- Train the QCNN ------------------- #\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------ #\u001b[39;00m\n\u001b[1;32m     31\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     33\u001b[0m weights, \\\n\u001b[1;32m     34\u001b[0m bias, \\\n\u001b[1;32m     35\u001b[0m losses, \\\n\u001b[1;32m     36\u001b[0m pred_train_arr, \\\n\u001b[1;32m     37\u001b[0m pred_val_arr, \\\n\u001b[1;32m     38\u001b[0m acc_train_arr, \\\n\u001b[0;32m---> 39\u001b[0m acc_val_arr \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_qcnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgs_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mgs_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mlabels_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mlabels_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     44\u001b[0m \u001b[43m                        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m run_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# --------------------------------------------------------- #\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# ------------------- Save calculations ------------------- #\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# --------------------------------------------------------- #\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[345], line 84\u001b[0m, in \u001b[0;36mtrain_qcnn\u001b[0;34m(gs_train, gs_val, labels_train, labels_val, cv)\u001b[0m\n\u001b[1;32m     81\u001b[0m bias\u001b[38;5;241m.\u001b[39mappend(b)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# Compute predictions and accuracy on train and validation set\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m pred_train \u001b[38;5;241m=\u001b[39m \u001b[43mpred\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgs_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_cpus_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m with_val:\n\u001b[1;32m     86\u001b[0m     pred_val \u001b[38;5;241m=\u001b[39m pred(w, b, gs_val, num_cpus_val) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(labels_val) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping hidden 12 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[349], line 22\u001b[0m, in \u001b[0;36mpred\u001b[0;34m(weights, bias, ground_states, num_cpus)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(ground_states)):\n\u001b[1;32m     20\u001b[0m         predictions\u001b[38;5;241m.\u001b[39mappend(single_pred(weights, bias, ground_states[j]))\n\u001b[0;32m---> 22\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mvmap(single_pred, in_axes\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m0\u001b[39m])(weights, bias, ground_states)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/jax/_src/core.py:605\u001b[0m, in \u001b[0;36mTracer.__array__\u001b[0;34m(self, *args, **kw)\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[0;32m--> 605\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m TracerArrayConversionError(\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mTracerArrayConversionError\u001b[0m: The numpy.ndarray conversion method __array__() was called on traced array with shape int64[].\nThe error occurred while tracing the function pred at /tmp/ipykernel_3564963/2856908872.py:13 for jit. This value became a tracer due to JAX operations on these lines:\n\n  operation a:i64[] = convert_element_type[new_dtype=int64 weak_type=True] b\n    from line /tmp/ipykernel_3564963/2856908872.py:20 (pred)\n\n  operation a:i64[] = convert_element_type[new_dtype=int64 weak_type=True] b\n    from line /tmp/ipykernel_3564963/2856908872.py:20 (pred)\n\n  operation a:i64[] = convert_element_type[new_dtype=int64 weak_type=False] b\n    from line /tmp/ipykernel_3564963/2856908872.py:20 (pred)\n\n  operation a:bool[] = lt b c\n    from line /tmp/ipykernel_3564963/2856908872.py:20 (pred)\n\n  operation a:i64[] = convert_element_type[new_dtype=int64 weak_type=False] b\n    from line /tmp/ipykernel_3564963/2856908872.py:20 (pred)\n\n(Additional originating lines are not shown.)\nSee https://jax.readthedocs.io/en/latest/errors.html#jax.errors.TracerArrayConversionError"
     ]
    }
   ],
   "source": [
    "# with jax.profiler.trace(\"/tmp/jax-trace\", create_perfetto_link=True):\n",
    "\n",
    "time_now = datetime.now(pytz.timezone('Europe/Andorra')).strftime(\"%Y-%m-%d %H-%M-%S\")\n",
    "\n",
    "folder_name = f\"Results/{nqubits}q - {num_iters:} iters/\"\n",
    "if not os.path.isdir(f'{folder_name}'):\n",
    "    os.makedirs(f'{folder_name}')\n",
    "\n",
    "save_hyperparameters(time_now, folder_name, file_name=\"\")\n",
    "\n",
    "\n",
    "print(\"Max train / Last run\")\n",
    "print(\"---------------------------------------------------\")\n",
    "print(\"  CV   | Run |   Iter    |Acc train|Acc val| Time  \")\n",
    "print(\"---------------------------------------------------\")\n",
    "\n",
    "\n",
    "for run in range (num_runs):\n",
    "\n",
    "    # -------------------------------------------------------------- #\n",
    "    # ------------------- Generate ground states ------------------- #\n",
    "    # -------------------------------------------------------------- #\n",
    "\n",
    "    gs_train, labels_train, j_train = generate_gs(train_size, uniform_train, epsilon_train, num_cpus_train)\n",
    "    gs_val, labels_val, j_val = generate_gs(val_size, uniform_val, epsilon_val, num_cpus_val)\n",
    "\n",
    "    # ------------------------------------------------------ #\n",
    "    # ------------------- Train the QCNN ------------------- #\n",
    "    # ------------------------------------------------------ #\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    weights, \\\n",
    "    bias, \\\n",
    "    losses, \\\n",
    "    pred_train_arr, \\\n",
    "    pred_val_arr, \\\n",
    "    acc_train_arr, \\\n",
    "    acc_val_arr = train_qcnn(gs_train,\n",
    "                             gs_val,\n",
    "                             labels_train,\n",
    "                             labels_val,\n",
    "                             cv=False\n",
    "                            )\n",
    "\n",
    "    run_time = time.time() - start_time\n",
    "\n",
    "\n",
    "    # --------------------------------------------------------- #\n",
    "    # ------------------- Save calculations ------------------- #\n",
    "    # --------------------------------------------------------- #\n",
    "\n",
    "    save_data(time_now,\n",
    "              folder_name,\n",
    "              run,\n",
    "              weights,\n",
    "              bias,\n",
    "              losses,\n",
    "              j_train,\n",
    "              j_val,\n",
    "              pred_train_arr,\n",
    "              pred_val_arr,\n",
    "              acc_train_arr,\n",
    "              acc_val_arr,\n",
    "              run_time,\n",
    "              cv=False\n",
    "             )\n",
    "\n",
    "\n",
    "    # ---------------------------------------------------------------------- #\n",
    "    # ------------------------ QCNN with Curriculum ------------------------ #\n",
    "    # ---------------------------------------------------------------------- #\n",
    "    if with_cv:\n",
    "        # --------------------------------------------------------------------------------- #\n",
    "        # ------------------------ Sort training gs by their score ------------------------ #\n",
    "        # --------------------------------------------------------------------------------- #\n",
    "\n",
    "        score_it = num_iters-1 # num_iters-1 or it_max\n",
    "        scores = [single_loss(weights[score_it], bias[score_it], gs_train[i], labels_train[i]) for i in range(len(labels_train))]\n",
    "\n",
    "        table = {}\n",
    "        table[\"gs_train\"] = gs_train.tolist()\n",
    "        table[\"labels_train\"] = labels_train\n",
    "        table[\"j_train\"] = j_train.tolist()\n",
    "        table[\"scores\"] = scores\n",
    "\n",
    "        table = pd.DataFrame(table)\n",
    "        table.sort_values(by=[\"scores\"], inplace=True)\n",
    "\n",
    "        cv_gs_train = np.array(list(table[\"gs_train\"]))\n",
    "        cv_labels_train = np.array(list(table[\"labels_train\"]))\n",
    "        cv_j_train = np.array(list(table[\"j_train\"]))\n",
    "\n",
    "\n",
    "        # ---------------------------------------------------------------------------- #\n",
    "        # ------------------------ Train QCNN with Curriculum ------------------------ #\n",
    "        # ---------------------------------------------------------------------------- #\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        weights, \\\n",
    "        bias, \\\n",
    "        losses, \\\n",
    "        pred_train_arr, \\\n",
    "        pred_val_arr, \\\n",
    "        acc_train_arr, \\\n",
    "        acc_val_arr = train_qcnn(cv_gs_train,\n",
    "                                 gs_val,\n",
    "                                 cv_labels_train,\n",
    "                                 labels_val,\n",
    "                                 cv=True\n",
    "                                )\n",
    "\n",
    "        run_time = time.time() - start_time\n",
    "\n",
    "\n",
    "        # --------------------------------------------------------- #\n",
    "        # ------------------- Save calculations ------------------- #\n",
    "        # --------------------------------------------------------- #\n",
    "        save_data(time_now,\n",
    "                  folder_name,\n",
    "                  run,\n",
    "                  weights,\n",
    "                  bias,\n",
    "                  losses,\n",
    "                  cv_j_train,\n",
    "                  j_val,\n",
    "                  pred_train_arr,\n",
    "                  pred_val_arr,\n",
    "                  acc_train_arr,\n",
    "                  acc_val_arr,\n",
    "                  run_time,\n",
    "                  cv=True\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Miscellaneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(mp.cpu_count()) #256\n",
    "\n",
    "# gs = gs_train\n",
    "# lab = labels_train\n",
    "\n",
    "# for i in range(10, 120, 10):\n",
    "#     num_cpus_test = i\n",
    "#     start_time = time.time()\n",
    "#     loss(weights[0], bias[0], gs, lab, num_cpus_test)\n",
    "#     print(f\"{i} --- {(time.time() - start_time):.2f} seconds ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define regions coordinates\n",
    "x01, y01 = region01e_coords[:,0], region01e_coords[:,1]\n",
    "x02, y02 = region02e_coords[:,0], region02e_coords[:,1]\n",
    "x1, y1 = region1e_coords[:,0], region1e_coords[:,1]\n",
    "x2, y2 = region2e_coords[:,0], region2e_coords[:,1]\n",
    "x3, y3 = region3e_coords[:,0], region3e_coords[:,1]\n",
    "\n",
    "# put the regions into the plot\n",
    "plt.fill(x01, y01, facecolor='lightskyblue')    # class 0\n",
    "plt.fill(x02, y02, facecolor='lightskyblue')    # class 0\n",
    "plt.fill(x1, y1, facecolor='sandybrown')        # class 1\n",
    "plt.fill(x2, y2, facecolor='salmon')            # class 2\n",
    "plt.fill(x3, y3, facecolor='lightgreen')        # class 3\n",
    "\n",
    "plt.axis('square')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
