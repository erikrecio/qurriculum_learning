{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as pnp\n",
    "from pennylane.optimize import NesterovMomentumOptimizer\n",
    "from shapely.geometry import Polygon, Point\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "plt.ioff()\n",
    "\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os.path\n",
    "import pytz\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Running parameters\n",
    "num_iters = 1000    # Number of training iterations\n",
    "num_runs = 1\n",
    "\n",
    "# Circuit and optimization parameters\n",
    "nqubits = 4         # Num qubits, min 4, always 2**num_layers qubits\n",
    "with_bias = False    # Add a bias to the output of the quantum circuit\n",
    "random = True\n",
    "optimizer = \"Adam\"  # \"Adam\", \"Nesterov\"\n",
    "loss_type = \"cross-entropy\" # \"projectors\", \"cross-entropy\"\n",
    "\n",
    "# Data hyper-parameters\n",
    "batch_size = 100     # batch training size\n",
    "train_size = 100      # Total ground states that will be used for training\n",
    "val_size = 1000      # Total gound states with training + validation\n",
    "\n",
    "# How the training data is generated\n",
    "uniform_train = False    # True - Uniform, False - Balanced\n",
    "epsilon_train = True   # True - epsilon, False - no epsilon\n",
    "uniform_val = True\n",
    "epsilon_val = False\n",
    "\n",
    "# Multiprocess hyperparameters. recommended: (num_data, num_cpus) -> (20, 10), (100, 20-30), (200, 40-50) (1000, 50-70)\n",
    "num_cpus_batch = 20\n",
    "num_cpus_train = 20\n",
    "num_cpus_val = 50\n",
    "\n",
    "# Tweak training hyper-parameters\n",
    "max_weight_init = 2*np.pi  # weight_init goes from 0 to this number. Max = 2*np.pi. Other options = 0.01\n",
    "stepsize = 0.01         # stepsize of the gradient descent.\n",
    "\n",
    "# Constant definitions\n",
    "layers = int(np.log2(nqubits))\n",
    "nweights = 30*(layers-1) + 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def X(i):\n",
    "    return qml.PauliX(i)\n",
    "\n",
    "def Z(i):\n",
    "    return qml.PauliZ(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Gound states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ground_state(j1, j2):\n",
    "    \n",
    "    hamiltonian = 0\n",
    "    for i in range(nqubits):\n",
    "        hamiltonian += Z(i)\n",
    "        hamiltonian -= j1 * X(i) @ X((i+1)%nqubits)\n",
    "        hamiltonian -= j2 * X((i-1)%nqubits) @ Z(i) @ X((i+1)%nqubits)\n",
    "    \n",
    "    _, eigvecs = np.linalg.eigh(qml.matrix(hamiltonian))\n",
    "    \n",
    "    return eigvecs[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define coordinates of the points of each region# Definir las coordenadas de los puntos de cada región\n",
    "region01_coords = np.array([(-2, 1), (2, 1), (4, 3), (4, 4), (-4, 4), (-4, 3)])    # Class 0\n",
    "region02_coords = np.array([(-3, -4), (0, -1), (3, -4)])                           # Class 0\n",
    "region1_coords = np.array([(0, -1), (3, -4), (4, -4), (4, 3)])                     # Class 1\n",
    "region2_coords = np.array([(0, -1), (-3, -4), (-4, -4), (-4, 3)])                  # Class 2\n",
    "region3_coords = np.array([(-2, 1), (2, 1), (0, -1)])                              # Class 3\n",
    "\n",
    "e = 0.2\n",
    "# Define coordinates of the points of each region far from the borders\n",
    "region01e_coords = np.array([(-2+(np.sqrt(2)-1)*e, 1+e), (2-(np.sqrt(2)-1)*e, 1+e), (4, 3+np.sqrt(2)*e), (4, 4), (-4, 4), (-4, 3+np.sqrt(2)*e)])    # Class 0 with epsilon\n",
    "region02e_coords = np.array([(-3+np.sqrt(2)*e, -4), (0, -1-np.sqrt(2)*e), (3-np.sqrt(2)*e, -4)])                                                    # Class 0 with epsilon\n",
    "region1e_coords = np.array([(0+np.sqrt(2)*e, -1), (3+np.sqrt(2)*e, -4), (4, -4), (4, 3-np.sqrt(2)*e)])                                              # Class 1 with epsilon\n",
    "region2e_coords = np.array([(0-np.sqrt(2)*e, -1), (-3-np.sqrt(2)*e, -4), (-4, -4), (-4, 3-np.sqrt(2)*e)])                                           # Class 2 with epsilon\n",
    "region3e_coords = np.array([(-2+e/np.tan(np.pi/8), 1-e), (2-e/np.tan(np.pi/8), 1-e), (0, -1+np.sqrt(2)*e)])                                         # Class 3 with epsilon\n",
    "\n",
    "\n",
    "def labeling(x, y):\n",
    "\n",
    "    # Crear objetos Polygon para cada región\n",
    "    region01_poly = Polygon(region01_coords)\n",
    "    region02_poly = Polygon(region02_coords)\n",
    "    region1_poly = Polygon(region1_coords)\n",
    "    region2_poly = Polygon(region2_coords)\n",
    "    region3_poly = Polygon(region3_coords)\n",
    "    \n",
    "    \n",
    "    p = Point(x, y)\n",
    "    if region01_poly.contains(p):\n",
    "        return 0\n",
    "    elif region02_poly.contains(p):\n",
    "        return 0\n",
    "    elif region1_poly.contains(p):\n",
    "        return 1\n",
    "    elif region2_poly.contains(p):\n",
    "        return 2\n",
    "    elif region3_poly.contains(p):\n",
    "        return 3\n",
    "    else:\n",
    "        return None # if the point is not in any region\n",
    "    \n",
    "\n",
    "def labeling_epsilon(x, y):\n",
    "    \n",
    "    # Crear objetos Polygon para cada región\n",
    "    region01e_poly = Polygon(region01e_coords)\n",
    "    region02e_poly = Polygon(region02e_coords)\n",
    "    region1e_poly = Polygon(region1e_coords)\n",
    "    region2e_poly = Polygon(region2e_coords)\n",
    "    region3e_poly = Polygon(region3e_coords)\n",
    "    \n",
    "    \n",
    "    p = Point(x, y)\n",
    "    if region01e_poly.contains(p):\n",
    "        return 0\n",
    "    elif region02e_poly.contains(p):\n",
    "        return 0\n",
    "    elif region1e_poly.contains(p):\n",
    "        return 1\n",
    "    elif region2e_poly.contains(p):\n",
    "        return 2\n",
    "    elif region3e_poly.contains(p):\n",
    "        return 3\n",
    "    else:\n",
    "        return None # if the point is not in any region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate ground states\n",
    "def generate_gs(num_points, uniform, epsilon, num_cpus):\n",
    "\n",
    "    if random:\n",
    "        rng = np.random\n",
    "    else:\n",
    "        rng = np.random.RandomState(0)\n",
    "        \n",
    "\n",
    "    if uniform:\n",
    "        if epsilon:\n",
    "            j_list = []\n",
    "            num = 0\n",
    "            while num < num_points:\n",
    "                j = rng.uniform(-4, 4, 2)\n",
    "                l = labeling_epsilon(j[0], j[1])\n",
    "\n",
    "                if l in [0,1,2,3]:\n",
    "                    num += 1\n",
    "                    j_list.append(j)\n",
    "\n",
    "            j_list = np.array(j_list)\n",
    "            \n",
    "        else:\n",
    "            j_list = rng.uniform(-4, 4, (num_points,2))\n",
    "    \n",
    "    \n",
    "    else: # Then it's balanced\n",
    "        npoints_class = num_points//4\n",
    "        num_points = 4*npoints_class\n",
    "        \n",
    "        npoints_01 = npoints_class//2\n",
    "        npoints_02 = npoints_class - npoints_01\n",
    "        \n",
    "        j_list = []\n",
    "        num_0, num_1, num_2, num_3 = 0, 0, 0, 0\n",
    "        num_01, num_02 = 0, 0\n",
    "        \n",
    "        while num_0 != npoints_class or num_1 != npoints_class or num_2 != npoints_class or num_3 != npoints_class:\n",
    "            j = rng.uniform(-4, 4, 2)\n",
    "            l = labeling_epsilon(j[0], j[1]) if epsilon else labeling(j[0], j[1])\n",
    "\n",
    "            if l==0 and num_0 < npoints_class:\n",
    "                \n",
    "                p = Point(j[0], j[1])\n",
    "                if Polygon(region01_coords).contains(p) and num_01 < npoints_01:\n",
    "                    num_01 += 1\n",
    "                    num_0 += 1\n",
    "                    j_list.append(j)\n",
    "                elif Polygon(region02_coords).contains(p) and num_02 < npoints_02:\n",
    "                    num_02 += 1\n",
    "                    num_0 += 1\n",
    "                    j_list.append(j)\n",
    "                \n",
    "            elif l==1 and num_1 < npoints_class:\n",
    "                num_1 += 1\n",
    "                j_list.append(j)\n",
    "            elif l==2 and num_2 < npoints_class:\n",
    "                num_2 += 1\n",
    "                j_list.append(j)\n",
    "            elif l==3 and num_3 < npoints_class:\n",
    "                num_3 += 1\n",
    "                j_list.append(j)\n",
    "\n",
    "        j_list = np.array(j_list)\n",
    "    \n",
    "    \n",
    "    if num_cpus == 0:\n",
    "        gs_list = []\n",
    "        labels_list = []\n",
    "\n",
    "        for i in range(num_points):\n",
    "            gs_list.append(ground_state(j_list[i,0], j_list[i,1]))\n",
    "            labels_list.append(labeling(j_list[i,0], j_list[i,1]))\n",
    "            \n",
    "    else:\n",
    "        args = [[j_list[i,0], j_list[i,1]] for i in range(num_points)]\n",
    "        \n",
    "        with mp.Pool(num_cpus) as pool:\n",
    "            gs_list = pool.starmap(ground_state, args)\n",
    "        \n",
    "        with mp.Pool(num_cpus) as pool:\n",
    "            labels_list = pool.starmap(labeling, args)\n",
    "\n",
    "\n",
    "    gs_list = np.array(gs_list)\n",
    "    labels_list = np.array(labels_list)\n",
    "\n",
    "    return gs_list, labels_list, j_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convolutional_layer(q1, q2, weights):\n",
    "    qml.U3(wires=q1, theta=weights[0], phi=weights[1], delta=weights[2])\n",
    "    qml.U3(wires=q1, theta=weights[3], phi=weights[4], delta=weights[5])\n",
    "    qml.CNOT(wires=[q2, q1])\n",
    "    qml.RZ(wires=q1, phi=weights[6])\n",
    "    qml.RY(wires=q2, phi=weights[7])\n",
    "    qml.CNOT(wires=[q1, q2])\n",
    "    qml.RY(wires=q2, phi=weights[8])\n",
    "    qml.CNOT(wires=[q2, q1])\n",
    "    qml.U3(wires=q1, theta=weights[9], phi=weights[10], delta=weights[11])\n",
    "    qml.U3(wires=q1, theta=weights[12], phi=weights[13], delta=weights[14])\n",
    "\n",
    "def pooling_layer(q1, q2, weights):\n",
    "    qml.U3(wires=q1, theta=weights[0], phi=weights[1], delta=weights[2])\n",
    "    qml.U3(wires=q1, theta=weights[3], phi=weights[4], delta=weights[5])\n",
    "    qml.CNOT(wires=[q2, q1])\n",
    "    qml.RZ(wires=q1, phi=weights[6])\n",
    "    qml.RY(wires=q2, phi=weights[7])\n",
    "    qml.CNOT(wires=[q1, q2])\n",
    "    qml.RY(wires=q2, phi=weights[8])\n",
    "    qml.CNOT(wires=[q2, q1])\n",
    "    qml.U3(wires=q1, theta=weights[9], phi=weights[10], delta=weights[11])\n",
    "    qml.U3(wires=q1, theta=weights[12], phi=weights[13], delta=weights[14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_circuit(weights, state_ini):\n",
    "    \n",
    "    qubits = list(range(nqubits))\n",
    "    \n",
    "    qml.QubitStateVector(state_ini, wires=qubits)\n",
    "\n",
    "    for j in range(layers-1):\n",
    "        \n",
    "        len_qubits = len(qubits)\n",
    "        \n",
    "        for i in range(len_qubits//2):\n",
    "            convolutional_layer(qubits[2*i], qubits[(2*i+1)%len_qubits], weights[15*2*j:15*(2*j+1)])\n",
    "        \n",
    "        for i in range(len_qubits//2):\n",
    "            convolutional_layer(qubits[2*i+1], qubits[(2*i+2)%len_qubits], weights[15*2*j:15*(2*j+1)])\n",
    "            \n",
    "        for i in range(len_qubits//2):\n",
    "            pooling_layer(qubits[2*i], qubits[(2*i+1)%len_qubits], weights[15*(2*j+1):15*(2*j+2)])\n",
    "\n",
    "        qub = []\n",
    "        for i in range(len_qubits):\n",
    "            if i%2 == 1:\n",
    "                qub.append(qubits[i])\n",
    "                \n",
    "        qubits = qub\n",
    "    \n",
    "    convolutional_layer(qubits[0], qubits[1], weights[15*(2*layers-2):15*(2*layers-1)])\n",
    "    \n",
    "    return qml.expval(Z(qubits[0])), qml.expval(Z(qubits[1])), qml.expval(Z(qubits[0]) @ Z(qubits[1]))\n",
    "\n",
    "# dev_draw = qml.device(\"qiskit.aer\", wires=nqubits)\n",
    "dev = qml.device(\"default.qubit\", wires=nqubits)\n",
    "\n",
    "# cnn_draw = qml.QNode(cnn_circuit, dev_draw)\n",
    "cnn_circuit = qml.QNode(cnn_circuit, dev, interface=\"auto\", diff_method=\"best\")\n",
    "\n",
    "\n",
    "def cnn(weights, state_ini):\n",
    "    z0, z1, zz01 = cnn_circuit(weights, state_ini)\n",
    "\n",
    "    proj_00 = (1+zz01+z0+z1)/4\n",
    "    proj_01 = (1-zz01-z0+z1)/4\n",
    "    proj_10 = (1-zz01+z0-z1)/4\n",
    "    proj_11 = (1+zz01-z0-z1)/4\n",
    "\n",
    "    return pnp.array([proj_00, proj_01, proj_10, proj_11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def variational_classifier(weights, bias, state_ini):\n",
    "    return cnn(weights, state_ini) + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# draw circuit\n",
    "\n",
    "# weights = np.random.uniform(0, 2*np.pi, nweights)\n",
    "# drawer = qml.draw(cnn_circuit)\n",
    "# print(drawer(weights, gs_list[0]))\n",
    "\n",
    "# z0, z1, zz01 = cnn_draw(gs_list[0], weights)\n",
    "# print(z0, z1, zz01)\n",
    "# dev_draw._circuit.draw(output=\"mpl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def log2_arraybox(abox):\n",
    "    return pnp._np.numpy_boxes.ArrayBox(value = np.log2(abox._value), trace = abox._trace, node = abox._node)\n",
    "\n",
    "\n",
    "def single_loss(weights, bias, ground_state, label):\n",
    "    \n",
    "    proj = variational_classifier(weights, bias, ground_state)\n",
    "\n",
    "    if loss_type == \"projectors\":\n",
    "            cost = proj[label]\n",
    "\n",
    "    elif loss_type == \"cross-entropy\":\n",
    "        \n",
    "            if isinstance(proj[label], pnp._np.numpy_boxes.ArrayBox):\n",
    "                cost = -log2_arraybox(proj[label])\n",
    "            else:\n",
    "                cost = -np.log2(proj[label])\n",
    "    \n",
    "    return cost\n",
    "\n",
    "\n",
    "def loss(weights, bias, ground_states, labels, num_cpus):\n",
    "    \n",
    "    if num_cpus == 0:\n",
    "        cost = 0\n",
    "\n",
    "        for j in range(len(labels)):\n",
    "            cost += single_loss(weights, bias, ground_states[j], labels[j])\n",
    "    \n",
    "    else:\n",
    "        args = [[weights, bias, ground_states[j], labels[j]] for j in range(len(labels))]\n",
    "\n",
    "        with mp.Pool(num_cpus) as pool:\n",
    "            cost_arr = pool.starmap(single_loss, args)\n",
    "\n",
    "        cost = sum(cost_arr)\n",
    "    \n",
    "    return cost/len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def single_pred(weights, bias, ground_state):\n",
    "    \n",
    "    projectors = variational_classifier(weights, bias, ground_state)\n",
    "    \n",
    "    if loss_type == \"projectors\":\n",
    "        pred = np.argmin(projectors)\n",
    "    elif loss_type == \"cross-entropy\":\n",
    "        pred = np.argmax(projectors)\n",
    "\n",
    "    return pred\n",
    "\n",
    "\n",
    "def pred(weights, bias, ground_states, num_cpus):\n",
    "    \n",
    "    if num_cpus == 0:\n",
    "        predictions = []\n",
    "        \n",
    "        for j in range(len(ground_states)):\n",
    "            predictions.append(single_pred(weights, bias, ground_states[j]))\n",
    "    else:\n",
    "        args = [[weights, bias, ground_states[j]] for j in range(len(ground_states))]\n",
    "\n",
    "        with mp.Pool(num_cpus) as pool:\n",
    "            predictions = pool.starmap(single_pred, args)\n",
    "            \n",
    "    return np.array(predictions)\n",
    "\n",
    "\n",
    "def acc(predictions, labels):\n",
    "    return sum(predictions==labels)*100/len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_qcnn(gs_train, gs_val, labels_train, labels_val, j_train, j_val):\n",
    "        \n",
    "    if random:\n",
    "        rng = np.random\n",
    "    else:\n",
    "        rng = np.random.RandomState(0)\n",
    "        \n",
    "    # weights and bias initialization\n",
    "    weights_init = pnp.random.uniform(0, max_weight_init, nweights, requires_grad=True)\n",
    "\n",
    "    if with_bias:\n",
    "        bias_init = pnp.array([0.0]*4, requires_grad=True)\n",
    "    else:\n",
    "        bias_init = np.array([0.0]*4)\n",
    "\n",
    "    # choose variational classifier\n",
    "    if optimizer == \"Nesterov\":\n",
    "        opt = NesterovMomentumOptimizer(stepsize)\n",
    "    elif optimizer == \"Adam\":\n",
    "        opt = qml.AdamOptimizer(stepsize)\n",
    "\n",
    "    #Initiaize variables\n",
    "    weights = []\n",
    "    bias = []\n",
    "    losses = []\n",
    "    pred_train_arr = []\n",
    "    pred_val_arr = []\n",
    "    acc_train_arr = []\n",
    "    acc_val_arr = []\n",
    "\n",
    "    w = weights_init\n",
    "    b = bias_init\n",
    "    \n",
    "    for it in range(num_iters):\n",
    "        batch_index = np.random.default_rng().choice(len(labels_train), size=batch_size, replace=False)\n",
    "        gs_train_batch = gs_train[batch_index]\n",
    "        labels_train_batch = labels_train[batch_index]\n",
    "\n",
    "        # Update the weights by one optimizer step\n",
    "        if num_cpus_batch == 0:\n",
    "            w, b, _, _ = opt.step(loss, w, b, gs_train_batch, labels_train_batch)\n",
    "\n",
    "        else:\n",
    "            args = [[single_loss, w, b, gs_train_batch[j], labels_train_batch[j]] for j in range(len(labels_train_batch))]\n",
    "\n",
    "            with mp.Pool(num_cpus_batch) as pool:\n",
    "                w, b, _, _ = zip(*pool.starmap(opt.step, args))\n",
    "\n",
    "            w = sum(w)/len(w)\n",
    "            b = sum(b)/len(b)\n",
    "\n",
    "        weights.append(w)\n",
    "        bias.append(b)\n",
    "\n",
    "        # Compute predictions and accuracy on train and validation set\n",
    "        pred_train = pred(w, b, gs_train, num_cpus_train)\n",
    "        pred_val = pred(w, b, gs_val, num_cpus_val) if len(labels_val) > 0 else None\n",
    "\n",
    "        acc_train = acc(pred_train, labels_train)\n",
    "        acc_val = acc(pred_val, labels_val) if len(labels_val) > 0 else 0\n",
    "\n",
    "        # Save prediction for later plotting\n",
    "        pred_train_arr.append(pred_train)\n",
    "        pred_val_arr.append(pred_val)\n",
    "        acc_train_arr.append(acc_train)\n",
    "        acc_val_arr.append(acc_val)\n",
    "\n",
    "        l = loss(w, b, gs_train, labels_train, num_cpus_train)\n",
    "        losses.append(l)\n",
    "    \n",
    "    return weights, bias, losses, pred_train_arr, pred_val_arr, acc_train_arr, acc_val_arr, j_train, j_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max train / Last run\n",
      "---------------------------------------\n",
      "Run |  Iter   |Acc train|Acc val| Time \n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"Max train / Last run\")\n",
    "print(\"---------------------------------------\")\n",
    "print(\"Run |  Iter   |Acc train|Acc val| Time \")\n",
    "print(\"---------------------------------------\")\n",
    "\n",
    "total_weights = []\n",
    "total_bias = []\n",
    "total_losses = []\n",
    "total_pred_train = []\n",
    "total_pred_val = []\n",
    "total_acc_train = []\n",
    "total_acc_val = []\n",
    "total_it_max = []\n",
    "total_acc_train_max = []\n",
    "total_acc_val_max = []\n",
    "total_j_train = []\n",
    "total_j_val = []\n",
    "total_time = []\n",
    "\n",
    "\n",
    "for run in range (num_runs):\n",
    "    \n",
    "    # Generate ground states\n",
    "    gs_train, labels_train, j_train = generate_gs(train_size, uniform_train, epsilon_train, num_cpus_train)\n",
    "    gs_val, labels_val, j_val = generate_gs(val_size, uniform_val, epsilon_val, num_cpus_val)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Train the QCNN\n",
    "    weights, bias, losses, pred_train_arr, pred_val_arr, acc_train_arr, acc_val_arr, j_train, j_val = train_qcnn(gs_train, gs_val, labels_train, labels_val, j_train, j_val)\n",
    "    \n",
    "    run_time = time.time()-start_time\n",
    "    \n",
    "    it_max = np.argmax(np.array(acc_train_arr))\n",
    "    acc_train_max = acc_train_arr[it_max]\n",
    "    acc_val_max = acc_val_arr[it_max]\n",
    "    \n",
    "    total_weights.append(weights)\n",
    "    total_bias.append(bias)\n",
    "    total_losses.append(losses)\n",
    "    total_pred_train.append(pred_train_arr)\n",
    "    total_pred_val.append(pred_val_arr)\n",
    "    total_acc_train.append(acc_train_arr)\n",
    "    total_acc_val.append(acc_val_arr)\n",
    "    total_it_max.append(it_max)\n",
    "    total_acc_train_max.append(acc_train_max)\n",
    "    total_acc_val_max.append(acc_val_max)\n",
    "    total_j_train.append(j_train)\n",
    "    total_j_val.append(j_val)\n",
    "    total_time.append(run_time)\n",
    "    \n",
    "    print(\n",
    "        f\"{run:3d} |\"\n",
    "        f\" {it_max:3d}/{num_iters-1:3d} |\"\n",
    "        f\"  {acc_train_arr[it_max]:0.0f}/{acc_train_arr[num_iters-1]:0.0f}  |\"\n",
    "        f\" {acc_val_arr[it_max]:0.0f}/{acc_val_arr[num_iters-1]:0.0f} |\"\n",
    "        f\" {run_time:0.0f}\"\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "run_max_last = np.argmax(np.array(total_acc_train)[:,num_iters-1])\n",
    "avg_acc_train_last = np.mean(np.array(total_acc_train)[:,num_iters-1])\n",
    "avg_acc_val_last = np.mean(np.array(total_acc_val)[:,num_iters-1])\n",
    "\n",
    "run_max = np.argmax(np.array(total_acc_train_max))\n",
    "it_max_run_max = total_it_max[run_max]\n",
    "avg_acc_train_max = sum(total_acc_train_max)/len(total_acc_train_max)\n",
    "avg_acc_val_max = sum(total_acc_val_max)/len(total_acc_val_max)\n",
    "\n",
    "\n",
    "print(\n",
    "    f\"Max/Last -> \"\n",
    "    f\"Run: {run_max:3d}/{run_max_last:3d} | \"\n",
    "    f\"Iter: {it_max_run_max:3d}/{num_iters-1:3d} | \"\n",
    "    f\"Acc train: {total_acc_train[run_max][it_max_run_max]:0.0f}/{total_acc_train[run_max_last][num_iters-1]:0.0f} | \"\n",
    "    f\"Acc val: {total_acc_val[run_max][it_max_run_max]:0.0f}/{total_acc_val[run_max_last][num_iters-1]:0.0f} || \"\n",
    ")\n",
    "print(\n",
    "    f\"Averages -> \"\n",
    "    f\"Acc train {avg_acc_train_max:0.0f}/{avg_acc_train_last:0.0f} | \"\n",
    "    f\"Acc val {avg_acc_val_max:0.0f}/{avg_acc_val_last:0.0f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data():\n",
    "\n",
    "    time_now = datetime.now(pytz.timezone('Europe/Andorra')).strftime(\"%Y-%m-%d %H-%M-%S\")\n",
    "\n",
    "    folder_name = f\"Results/{nqubits}q - {num_iters:} iters/no_qurriculum\"\n",
    "    if not os.path.isdir(f'{folder_name}'):\n",
    "        os.makedirs(f'{folder_name}')\n",
    "\n",
    "    ut = \"unif-T\" if uniform_train else \"no-unif-T\"\n",
    "    et = \"eps-T\" if epsilon_train else \"no-eps-T\"\n",
    "    uv = \"unif-V\" if uniform_val else \"no-unif-V\"\n",
    "    ev = \"eps-V\" if epsilon_val else \"no-eps-V\"\n",
    "\n",
    "    file_name = f'{train_size} Train - {val_size} Val, {ut}, {et}, {uv}, {ev}'\n",
    "    \n",
    "    \n",
    "    # -------------------- Total Data -------------------- #\n",
    "    data = {}\n",
    "    data[\"total_weights\"] = total_weights\n",
    "    data[\"total_bias\"] = total_bias\n",
    "    data[\"total_losses\"] = total_losses\n",
    "    data[\"total_pred_train\"] = total_pred_train\n",
    "    data[\"total_pred_val\"] = total_pred_val\n",
    "    data[\"total_acc_train\"] = total_acc_train\n",
    "    data[\"total_acc_val\"] = total_acc_val\n",
    "    data[\"total_it_max\"] = total_it_max\n",
    "    data[\"total_acc_train_max\"] = total_acc_train_max\n",
    "    data[\"total_acc_val_max\"] = total_acc_val_max\n",
    "    data[\"total_j_train\"] = total_j_train\n",
    "    data[\"total_j_val\"] = total_j_val\n",
    "    data[\"total_time\"] = total_time\n",
    "\n",
    "    data = pd.DataFrame(data)\n",
    "\n",
    "    data_file_name = f\"{time_now} - Data - {file_name}\"\n",
    "    data.to_csv(f'{folder_name}/{data_file_name}.csv', index=False)\n",
    "    \n",
    "    \n",
    "    # --------------- Hyperparameters -----------------#\n",
    "    hyperparameters = {}\n",
    "    hyperparameters[\"num_iters\"] = [num_iters]\n",
    "    hyperparameters[\"num_runs\"] = [num_runs]\n",
    "    hyperparameters[\"nqubits\"] = [nqubits]\n",
    "    hyperparameters[\"with_bias\"] = [with_bias]\n",
    "    hyperparameters[\"random\"] = [random]\n",
    "    hyperparameters[\"optimizer\"] = [optimizer]\n",
    "    hyperparameters[\"loss_type\"] = [loss_type]\n",
    "    hyperparameters[\"batch_size\"] = [batch_size]\n",
    "    hyperparameters[\"train_size\"] = [train_size]\n",
    "    hyperparameters[\"val_size\"] = [val_size]\n",
    "    hyperparameters[\"uniform_train\"] = [uniform_train]\n",
    "    hyperparameters[\"epsilon_train\"] = [epsilon_train]\n",
    "    hyperparameters[\"uniform_val\"] = [uniform_val]\n",
    "    hyperparameters[\"epsilon_val\"] = [epsilon_val]\n",
    "    hyperparameters[\"num_cpus_batch\"] = [num_cpus_batch]\n",
    "    hyperparameters[\"num_cpus_train\"] = [num_cpus_train]\n",
    "    hyperparameters[\"num_cpus_val\"] = [num_cpus_val]\n",
    "    hyperparameters[\"max_weight_init\"] = [max_weight_init]\n",
    "    hyperparameters[\"stepsize\"] = [stepsize]\n",
    "\n",
    "    hyperparameters = pd.DataFrame(hyperparameters)\n",
    "\n",
    "    hyperparameters_file_name = f\"{time_now} - Hyperparameters - {file_name}\"\n",
    "    hyperparameters.to_csv(f'{folder_name}/{hyperparameters_file_name}.csv', index=False)\n",
    "    \n",
    "    \n",
    "    # ------------------- Results ------------------- #\n",
    "    results = {}\n",
    "    results[\"best_run_max\"] = run_max\n",
    "    results[\"best_run_last\"] = run_max_last\n",
    "    results[\"best_acc_train_max\"] = [total_acc_train[run_max][it_max_run_max]]\n",
    "    results[\"best_acc_train_last\"] = [total_acc_train[run_max_last][num_iters-1]]\n",
    "    results[\"best_acc_val_max\"] = [total_acc_val[run_max][it_max_run_max]]\n",
    "    results[\"best_acc_val_last\"] = [total_acc_val[run_max_last][num_iters-1]]\n",
    "    results[\"avg_acc_train_max\"] = [avg_acc_train_max]\n",
    "    results[\"avg_acc_train_last\"] = [avg_acc_train_last]\n",
    "    results[\"avg_acc_val_max\"] = [avg_acc_val_max]\n",
    "    results[\"avg_acc_val_last\"] = [avg_acc_val_last]\n",
    "\n",
    "    results = pd.DataFrame(results)\n",
    "\n",
    "    results_file_name = f\"{time_now} - Results - {file_name}\"\n",
    "    results.to_csv(f'{folder_name}/{results_file_name}.csv', index=False)\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### # Copy data from file\n",
    "\n",
    "# run_max = np.argmax(np.array(total_acc_train_max))\n",
    "# it_max_run_max = total_it_max[run_max]\n",
    "\n",
    "# avg_acc_train_max = sum(total_acc_train_max)/len(total_acc_train_max)\n",
    "# avg_acc_val_max = sum(total_acc_val_max)/len(total_acc_val_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_multi_image(filename):\n",
    "    pp = PdfPages(filename)\n",
    "    fig_nums = plt.get_fignums()\n",
    "    figs = [plt.figure(n) for n in fig_nums]\n",
    "    for fig in figs:\n",
    "        fig.savefig(pp, format='pdf')\n",
    "    pp.close()\n",
    "\n",
    "def close_all_figures():\n",
    "    fig_nums = plt.get_fignums()\n",
    "    for n in fig_nums:\n",
    "        plt.figure(n)\n",
    "        plt.close()\n",
    "\n",
    "for plot_run in range(len(total_it_max)):\n",
    "\n",
    "    fig, axis = plt.subplots(1,3)\n",
    "    fig.set_figheight(6.5)\n",
    "    fig.set_figwidth(20)\n",
    "    fig.tight_layout(pad=2, w_pad=3.5)\n",
    "    \n",
    "    # ---------------------------------------------------------------------- #\n",
    "    # -------------------- Loss and accuracy figure ------------------------ #\n",
    "    # ---------------------------------------------------------------------- #\n",
    "\n",
    "    acc_train_arr = total_acc_train[plot_run]\n",
    "    acc_val_arr = total_acc_val[plot_run]\n",
    "    losses = total_losses[plot_run]\n",
    "\n",
    "    iterations = range(1, len(acc_train_arr)+1)\n",
    "\n",
    "    color1 = 'darkred'\n",
    "    axis[0].set_xlabel('Iterations')\n",
    "    axis[0].set_ylabel('Accuracy %', color=color1)\n",
    "    axis[0].plot(iterations, acc_train_arr, label=\"Training\", color=color1)\n",
    "    axis[0].plot(iterations, acc_val_arr, '-.', label=\"Validation\", color=color1)\n",
    "    axis[0].tick_params(axis='y', labelcolor=color1)\n",
    "    axis[0].set_ylim(0,100)\n",
    "\n",
    "    ax2 = axis[0].twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "    color2 = 'darkblue'\n",
    "    ax2.set_ylabel('Loss', color=color2)  # we already handled the x-label with axis[0]\n",
    "    ax2.plot(iterations, losses, label=\"Loss\", color=color2)\n",
    "    ax2.tick_params(axis='y', labelcolor=color2)\n",
    "    # ax2.set_ylim(bottom=0)\n",
    "\n",
    "    # fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "    # plt.legend()\n",
    "    axis[0].set_title(f\"Accuracy and Loss - Run {plot_run}\")\n",
    "\n",
    "\n",
    "    # ---------------------------------------------------------------------- #\n",
    "    # ---------------------------- Max iter -------------------------------- #\n",
    "    # ---------------------------------------------------------------------- #\n",
    "\n",
    "    plot_iter = total_it_max[plot_run]\n",
    "    pred_train_arr = total_pred_train[plot_run]\n",
    "    pred_val_arr = total_pred_val[plot_run]\n",
    "    j_train = total_j_train[plot_run]\n",
    "    j_val = total_j_val[plot_run]\n",
    "\n",
    "    # define regions coordinates\n",
    "    x01, y01 = region01_coords[:,0], region01_coords[:,1]\n",
    "    x02, y02 = region02_coords[:,0], region02_coords[:,1]\n",
    "    x1, y1 = region1_coords[:,0], region1_coords[:,1]\n",
    "    x2, y2 = region2_coords[:,0], region2_coords[:,1]\n",
    "    x3, y3 = region3_coords[:,0], region3_coords[:,1]\n",
    "\n",
    "    # put the regions into the plot\n",
    "    axis[1].fill(x01, y01, facecolor='lightskyblue')    # class 0\n",
    "    axis[1].fill(x02, y02, facecolor='lightskyblue')    # class 0\n",
    "    axis[1].fill(x1, y1, facecolor='sandybrown')        # class 1\n",
    "    axis[1].fill(x2, y2, facecolor='salmon')            # class 2\n",
    "    axis[1].fill(x3, y3, facecolor='lightgreen')        # class 3\n",
    "\n",
    "    pred_train_plot = np.array(pred_train_arr[plot_iter])\n",
    "    pred_val_plot = np.array(pred_val_arr[plot_iter])\n",
    "\n",
    "    colors = [\"b\", \"orange\", \"r\", \"g\"]\n",
    "\n",
    "    # plot datapoints\n",
    "    for i in range(4):\n",
    "        axis[1].scatter(\n",
    "            j_train[:, 0][pred_train_plot==i],\n",
    "            j_train[:, 1][pred_train_plot==i],\n",
    "            c=colors[i],\n",
    "            marker=\"o\",\n",
    "            edgecolors=\"k\",\n",
    "            label=f\"class {i+1} train\",\n",
    "        )\n",
    "        axis[1].scatter(\n",
    "            j_val[:, 0][pred_val_plot==i],\n",
    "            j_val[:, 1][pred_val_plot==i],\n",
    "            c=colors[i],\n",
    "            marker=\"^\",\n",
    "            edgecolors=\"k\",\n",
    "            label=f\"class {i+1} validation\",\n",
    "        )\n",
    "\n",
    "\n",
    "    # plt.legend()\n",
    "    axis[1].set_title(f\"Max iteration ({total_acc_train[plot_run][plot_iter]:.0f}%/{total_acc_val[plot_run][plot_iter]:.0f}%)\")\n",
    "\n",
    "\n",
    "    # ---------------------------------------------------------------------- #\n",
    "    # ---------------------------- Last iter ------------------------------- #\n",
    "    # ---------------------------------------------------------------------- #\n",
    "\n",
    "\n",
    "    plot_iter = num_iters-1\n",
    "    pred_train_arr = total_pred_train[plot_run]\n",
    "    pred_val_arr = total_pred_val[plot_run]\n",
    "    j_train = total_j_train[plot_run]\n",
    "    j_val = total_j_val[plot_run]\n",
    "\n",
    "    # define regions coordinates\n",
    "    x01, y01 = region01_coords[:,0], region01_coords[:,1]\n",
    "    x02, y02 = region02_coords[:,0], region02_coords[:,1]\n",
    "    x1, y1 = region1_coords[:,0], region1_coords[:,1]\n",
    "    x2, y2 = region2_coords[:,0], region2_coords[:,1]\n",
    "    x3, y3 = region3_coords[:,0], region3_coords[:,1]\n",
    "\n",
    "    # put the regions into the plot\n",
    "    axis[2].fill(x01, y01, facecolor='lightskyblue')    # class 0\n",
    "    axis[2].fill(x02, y02, facecolor='lightskyblue')    # class 0\n",
    "    axis[2].fill(x1, y1, facecolor='sandybrown')        # class 1\n",
    "    axis[2].fill(x2, y2, facecolor='salmon')            # class 2\n",
    "    axis[2].fill(x3, y3, facecolor='lightgreen')        # class 3\n",
    "\n",
    "    pred_train_plot = np.array(pred_train_arr[plot_iter])\n",
    "    pred_val_plot = np.array(pred_val_arr[plot_iter])\n",
    "\n",
    "    colors = [\"b\", \"orange\", \"r\", \"g\"]\n",
    "\n",
    "    # plot datapoints\n",
    "    for i in range(4):\n",
    "        axis[2].scatter(\n",
    "            j_train[:, 0][pred_train_plot==i],\n",
    "            j_train[:, 1][pred_train_plot==i],\n",
    "            c=colors[i],\n",
    "            marker=\"o\",\n",
    "            edgecolors=\"k\",\n",
    "            label=f\"class {i+1} train\",\n",
    "        )\n",
    "        axis[2].scatter(\n",
    "            j_val[:, 0][pred_val_plot==i],\n",
    "            j_val[:, 1][pred_val_plot==i],\n",
    "            c=colors[i],\n",
    "            marker=\"^\",\n",
    "            edgecolors=\"k\",\n",
    "            label=f\"class {i+1} validation\",\n",
    "        )\n",
    "\n",
    "\n",
    "    # plt.legend()\n",
    "    axis[2].set_title(f\"Last iteration ({total_acc_train[plot_run][plot_iter]:.0f}%/{total_acc_val[plot_run][plot_iter]:.0f}%)\")\n",
    "\n",
    "# ---------------------------------------------------------------------- #\n",
    "# --------------------------- Save plots ------------------------------- #\n",
    "# ---------------------------------------------------------------------- #\n",
    "\n",
    "pdf_name = f\"{time_now} - Plots - {file_name}.pdf\"\n",
    "save_multi_image(f\"{folder_name}/{pdf_name}\")\n",
    "close_all_figures()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Max train / Last run\")\n",
    "print(\"---------------------------------------\")\n",
    "print(\"Run |  Iter   |Acc train|Acc val| Time \")\n",
    "print(\"---------------------------------------\")\n",
    "\n",
    "for info_run in range(len(total_it_max)):\n",
    "    \n",
    "    info_it_max = total_it_max[info_run]\n",
    "    \n",
    "    print(\n",
    "        f\"{info_run:3d} |\"\n",
    "        f\" {info_it_max:3d}/{num_iters-1:3d} |\"\n",
    "        f\"  {total_acc_train[info_run][info_it_max]:0.0f}/{total_acc_train[info_run][num_iters-1]:0.0f}  |\"\n",
    "        f\" {total_acc_val[info_run][info_it_max]:0.0f}/{total_acc_val[info_run][num_iters-1]:0.0f} |\"\n",
    "        f\" {total_time[info_run]:0.0f}\"\n",
    "    )\n",
    "\n",
    "print(\n",
    "    f\"Max/Last -> \"\n",
    "    f\"Run: {run_max:3d}/{run_max_last:3d} | \"\n",
    "    f\"Iter: {it_max_run_max:3d}/{num_iters-1:3d} | \"\n",
    "    f\"Acc train: {total_acc_train[run_max][it_max_run_max]:0.0f}/{total_acc_train[run_max_last][num_iters-1]:0.0f} | \"\n",
    "    f\"Acc val: {total_acc_val[run_max][it_max_run_max]:0.0f}/{total_acc_val[run_max_last][num_iters-1]:0.0f} || \"\n",
    ")\n",
    "print(\n",
    "    f\"Averages -> \"\n",
    "    f\"Acc train {avg_acc_train_max:0.0f}/{avg_acc_train_last:0.0f} | \"\n",
    "    f\"Acc val {avg_acc_val_max:0.0f}/{avg_acc_val_last:0.0f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_run = 4# run_max\n",
    "\n",
    "acc_train_arr = total_acc_train[plot_run]\n",
    "acc_val_arr = total_acc_val[plot_run]\n",
    "losses = total_losses[plot_run]\n",
    "\n",
    "iterations = range(1, len(acc_train_arr)+1)\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "color1 = 'darkred'\n",
    "ax1.set_xlabel('Iterations')\n",
    "ax1.set_ylabel('Accuracy %', color=color1)\n",
    "ax1.plot(iterations, acc_train_arr, label=\"Training\", color=color1)\n",
    "ax1.plot(iterations, acc_val_arr, '-.', label=\"Validation\", color=color1)\n",
    "ax1.tick_params(axis='y', labelcolor=color1)\n",
    "ax1.set_ylim(0,100)\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color2 = 'darkblue'\n",
    "ax2.set_ylabel('Loss', color=color2)  # we already handled the x-label with ax1\n",
    "ax2.plot(iterations, losses, label=\"Loss\", color=color2)\n",
    "ax2.tick_params(axis='y', labelcolor=color2)\n",
    "# ax2.set_ylim(bottom=0)\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "# plt.legend()\n",
    "plt.title(\"Accuracy and Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_run = run_max # run_max\n",
    "\n",
    "plot_iter = total_it_max[plot_run]\n",
    "pred_train_arr = total_pred_train[plot_run]\n",
    "pred_val_arr = total_pred_val[plot_run]\n",
    "j_train = total_j_train[plot_run]\n",
    "j_val = total_j_val[plot_run]\n",
    "\n",
    "# define regions coordinates\n",
    "x01, y01 = region01_coords[:,0], region01_coords[:,1]\n",
    "x02, y02 = region02_coords[:,0], region02_coords[:,1]\n",
    "x1, y1 = region1_coords[:,0], region1_coords[:,1]\n",
    "x2, y2 = region2_coords[:,0], region2_coords[:,1]\n",
    "x3, y3 = region3_coords[:,0], region3_coords[:,1]\n",
    "\n",
    "# plt.figure(figsize=(8, 8))\n",
    "\n",
    "# put the regions into the plot\n",
    "plt.fill(x01, y01, facecolor='lightskyblue')    # class 0\n",
    "plt.fill(x02, y02, facecolor='lightskyblue')    # class 0\n",
    "plt.fill(x1, y1, facecolor='sandybrown')        # class 1\n",
    "plt.fill(x2, y2, facecolor='salmon')            # class 2\n",
    "plt.fill(x3, y3, facecolor='lightgreen')        # class 3\n",
    "\n",
    "pred_train_plot = np.array(pred_train_arr[plot_iter])\n",
    "pred_val_plot = np.array(pred_val_arr[plot_iter])\n",
    "\n",
    "colors = [\"b\", \"orange\", \"r\", \"g\"]\n",
    "\n",
    "# plot datapoints\n",
    "for i in range(4):\n",
    "    plt.scatter(\n",
    "        j_train[:, 0][pred_train_plot==i],\n",
    "        j_train[:, 1][pred_train_plot==i],\n",
    "        c=colors[i],\n",
    "        marker=\"o\",\n",
    "        edgecolors=\"k\",\n",
    "        label=f\"class {i+1} train\",\n",
    "    )\n",
    "    plt.scatter(\n",
    "        j_val[:, 0][pred_val_plot==i],\n",
    "        j_val[:, 1][pred_val_plot==i],\n",
    "        c=colors[i],\n",
    "        marker=\"^\",\n",
    "        edgecolors=\"k\",\n",
    "        label=f\"class {i+1} validation\",\n",
    "    )\n",
    "\n",
    "\n",
    "# plt.legend()\n",
    "plt.axis('square')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Miscellaneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(mp.cpu_count()) #256\n",
    "\n",
    "gs = gs_val\n",
    "lab = labels_val\n",
    "\n",
    "for i in range(10, 120, 10):\n",
    "    num_cpus_test = i\n",
    "    start_time = time.time()\n",
    "    loss(w, b, gs, lab, num_cpus_test)\n",
    "    print(f\"{i} --- {(time.time() - start_time):.2f} seconds ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define regions coordinates\n",
    "x01, y01 = region01e_coords[:,0], region01e_coords[:,1]\n",
    "x02, y02 = region02e_coords[:,0], region02e_coords[:,1]\n",
    "x1, y1 = region1e_coords[:,0], region1e_coords[:,1]\n",
    "x2, y2 = region2e_coords[:,0], region2e_coords[:,1]\n",
    "x3, y3 = region3e_coords[:,0], region3e_coords[:,1]\n",
    "\n",
    "# put the regions into the plot\n",
    "plt.fill(x01, y01, facecolor='lightskyblue')    # class 0\n",
    "plt.fill(x02, y02, facecolor='lightskyblue')    # class 0\n",
    "plt.fill(x1, y1, facecolor='sandybrown')        # class 1\n",
    "plt.fill(x2, y2, facecolor='salmon')            # class 2\n",
    "plt.fill(x3, y3, facecolor='lightgreen')        # class 3\n",
    "\n",
    "plt.axis('square')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
