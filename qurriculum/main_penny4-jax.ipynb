{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jax.random\n",
    "import jax.numpy as jnp\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as pnp\n",
    "from pennylane.optimize import NesterovMomentumOptimizer\n",
    "# from catalyst import qjit\n",
    "from shapely.geometry import Polygon, Point\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "plt.ioff()\n",
    "\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pytz\n",
    "import ast\n",
    "from pypdf import PdfMerger\n",
    "\n",
    "import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Running parameters\n",
    "num_iters = 500    # Number of training iterations\n",
    "num_runs = 10\n",
    "cl_types = [\"NCL\", \"CL\", \"ACL\", \"SPCL\", \"SPACL\"]     # \"NCL\" - No curriculum, \"CL\" - Curriculum, \"ACL\" - Anti-curriculum, \"SPCL\" - Self paced curriculum, \"SPACL\" - Self paced anti-curriculum\n",
    "with_val = True\n",
    "\n",
    "# Circuit and optimization parameters\n",
    "nqubits = 8         # Num qubits, min 4, always 2**num_layers qubits\n",
    "with_bias = False    # Add a bias to the output of the quantum circuit\n",
    "optimizer = \"Adam\"  # \"Adam\", \"Nesterov\", \"GradientDescent\"\n",
    "loss_type = \"mean_squares\" # \"projectors\", \"cross_entropy\", \"mean_squares\"\n",
    "initialization = \"gaussian\" # \"gaussian\", \"uniform\"\n",
    "\n",
    "# Data hyper-parameters\n",
    "batch_size = 48     # batch training size\n",
    "train_size = 48      # Total ground states that will be used for training\n",
    "val_size = 1000      # Total gound states with training + validation\n",
    "cl_ratios = [0.4, 0.3, 0.2, 0.1]    # [0.1, 0.2, 0.3, 0.4], [0.2, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1], [0.3, 0.2, 0.2, 0.2, 0.1]\n",
    "\n",
    "# How the training data is generated\n",
    "uniform_train = True    # True - Uniform, False - Balanced\n",
    "uniform_val = True\n",
    "epsilon_train = True   # True - epsilon, False - no epsilon\n",
    "epsilon_val = False\n",
    "\n",
    "# Multiprocess hyperparameters. recommended: (num_data, num_cpus) -> (20, 10), (100, 20-30), (200, 40-50) (1000, 50-70)\n",
    "num_cpus_gs_train = 0 # 5\n",
    "num_cpus_gs_val = 0 # 10\n",
    "\n",
    "# Tweak training hyper-parameters\n",
    "max_weight_init = 2*np.pi  # weight_init goes from 0 to this number. Max = 2*np.pi. Other options = 0.01\n",
    "stepsize = 0.01         # stepsize of the gradient descent.\n",
    "\n",
    "# Constant definitions\n",
    "layers = int(np.log2(nqubits))\n",
    "nweights = 30*(layers-1) + 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def X(i):\n",
    "    return qml.PauliX(i)\n",
    "\n",
    "def Z(i):\n",
    "    return qml.PauliZ(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Gound states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ground_state(j1, j2):\n",
    "    \n",
    "    hamiltonian = 0\n",
    "    for i in range(nqubits):\n",
    "        hamiltonian += Z(i)\n",
    "        hamiltonian -= j1 * X(i) @ X((i+1)%nqubits)\n",
    "        hamiltonian -= j2 * X((i-1)%nqubits) @ Z(i) @ X((i+1)%nqubits)\n",
    "    \n",
    "    ham_matrix = qml.matrix(hamiltonian)\n",
    "    _, eigvecs = jnp.linalg.eigh(ham_matrix)\n",
    "    \n",
    "    return eigvecs[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define coordinates of the points of each region# Definir las coordenadas de los puntos de cada regi√≥n\n",
    "region01_coords = np.array([(-2, 1), (2, 1), (4, 3), (4, 4), (-4, 4), (-4, 3)])    # Class 0\n",
    "region02_coords = np.array([(-3, -4), (0, -1), (3, -4)])                           # Class 0\n",
    "region1_coords = np.array([(0, -1), (3, -4), (4, -4), (4, 3)])                     # Class 1\n",
    "region2_coords = np.array([(0, -1), (-3, -4), (-4, -4), (-4, 3)])                  # Class 2\n",
    "region3_coords = np.array([(-2, 1), (2, 1), (0, -1)])                              # Class 3\n",
    "\n",
    "e = 0.1\n",
    "# Define coordinates of the points of each region far from the borders\n",
    "region01e_coords = np.array([(-2+(np.sqrt(2)-1)*e, 1+e), (2-(np.sqrt(2)-1)*e, 1+e), (4, 3+np.sqrt(2)*e), (4, 4), (-4, 4), (-4, 3+np.sqrt(2)*e)])    # Class 0 with epsilon\n",
    "region02e_coords = np.array([(-3+np.sqrt(2)*e, -4), (0, -1-np.sqrt(2)*e), (3-np.sqrt(2)*e, -4)])                                                    # Class 0 with epsilon\n",
    "region1e_coords = np.array([(0+np.sqrt(2)*e, -1), (3+np.sqrt(2)*e, -4), (4, -4), (4, 3-np.sqrt(2)*e)])                                              # Class 1 with epsilon\n",
    "region2e_coords = np.array([(0-np.sqrt(2)*e, -1), (-3-np.sqrt(2)*e, -4), (-4, -4), (-4, 3-np.sqrt(2)*e)])                                           # Class 2 with epsilon\n",
    "region3e_coords = np.array([(-2+e/np.tan(np.pi/8), 1-e), (2-e/np.tan(np.pi/8), 1-e), (0, -1+np.sqrt(2)*e)])                                         # Class 3 with epsilon\n",
    "\n",
    "\n",
    "def labeling(x, y):\n",
    "\n",
    "    # Create Polygons for each region\n",
    "    region01_poly = Polygon(region01_coords)\n",
    "    region02_poly = Polygon(region02_coords)\n",
    "    region1_poly = Polygon(region1_coords)\n",
    "    region2_poly = Polygon(region2_coords)\n",
    "    region3_poly = Polygon(region3_coords)\n",
    "    \n",
    "    p = Point(x, y)\n",
    "    if region01_poly.contains(p):\n",
    "        return 0\n",
    "    elif region02_poly.contains(p):\n",
    "        return 0\n",
    "    elif region1_poly.contains(p):\n",
    "        return 1\n",
    "    elif region2_poly.contains(p):\n",
    "        return 2\n",
    "    elif region3_poly.contains(p):\n",
    "        return 3\n",
    "    else:\n",
    "        return None # if the point is not in any region\n",
    "    \n",
    "\n",
    "def labeling_epsilon(x, y):\n",
    "    \n",
    "    # Create Polygons for each region\n",
    "    region01e_poly = Polygon(region01e_coords)\n",
    "    region02e_poly = Polygon(region02e_coords)\n",
    "    region1e_poly = Polygon(region1e_coords)\n",
    "    region2e_poly = Polygon(region2e_coords)\n",
    "    region3e_poly = Polygon(region3e_coords)\n",
    "    \n",
    "    \n",
    "    p = Point(x, y)\n",
    "    if region01e_poly.contains(p):\n",
    "        return 0\n",
    "    elif region02e_poly.contains(p):\n",
    "        return 0\n",
    "    elif region1e_poly.contains(p):\n",
    "        return 1\n",
    "    elif region2e_poly.contains(p):\n",
    "        return 2\n",
    "    elif region3e_poly.contains(p):\n",
    "        return 3\n",
    "    else:\n",
    "        return None # if the point is not in any region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate ground states\n",
    "def generate_gs(num_points, uniform, epsilon, num_cpus):\n",
    "\n",
    "    if uniform:\n",
    "        if epsilon:\n",
    "            j_list = []\n",
    "            num = 0\n",
    "            while num < num_points:\n",
    "                j = np.random.uniform(-4, 4, 2)\n",
    "                l = labeling_epsilon(j[0], j[1])\n",
    "\n",
    "                if l in [0,1,2,3]:\n",
    "                    num += 1\n",
    "                    j_list.append(j)\n",
    "\n",
    "            j_list = np.array(j_list)\n",
    "            \n",
    "        else:\n",
    "            j_list = np.random.uniform(-4, 4, (num_points,2))\n",
    "    \n",
    "    \n",
    "    else: # Then it's balanced\n",
    "        npoints_class = num_points//4\n",
    "        num_points = 4*npoints_class\n",
    "        \n",
    "        npoints_02 = npoints_class//2\n",
    "        npoints_01 = npoints_class - npoints_02\n",
    "        \n",
    "        # npoints_class = num_points//5\n",
    "        # num_points = 5*npoints_class\n",
    "        \n",
    "        # npoints_02 = npoints_class\n",
    "        # npoints_01 = npoints_class\n",
    "        \n",
    "        \n",
    "        \n",
    "        j_list = []\n",
    "        num_01, num_02, num_1, num_2, num_3 = 0, 0, 0, 0, 0\n",
    "        \n",
    "        while num_01 != npoints_01 or num_02 != npoints_02 or num_1 != npoints_class or num_2 != npoints_class or num_3 != npoints_class:\n",
    "            j = np.random.uniform(-4, 4, 2)\n",
    "            l = labeling_epsilon(j[0], j[1]) if epsilon else labeling(j[0], j[1])\n",
    "\n",
    "            if l==0:\n",
    "                \n",
    "                p = Point(j[0], j[1])\n",
    "                if Polygon(region01_coords).contains(p) and num_01 < npoints_01:\n",
    "                    num_01 += 1\n",
    "                    j_list.append(j)\n",
    "                    \n",
    "                elif Polygon(region02_coords).contains(p) and num_02 < npoints_02:\n",
    "                    num_02 += 1\n",
    "                    j_list.append(j)\n",
    "                \n",
    "            elif l==1 and num_1 < npoints_class:\n",
    "                num_1 += 1\n",
    "                j_list.append(j)\n",
    "            elif l==2 and num_2 < npoints_class:\n",
    "                num_2 += 1\n",
    "                j_list.append(j)\n",
    "            elif l==3 and num_3 < npoints_class:\n",
    "                num_3 += 1\n",
    "                j_list.append(j)\n",
    "\n",
    "        j_list = np.array(j_list)\n",
    "    \n",
    "    \n",
    "    if num_cpus == 0:\n",
    "        gs_list = []\n",
    "        labels_list = []\n",
    "\n",
    "        for i in range(num_points):\n",
    "            gs_list.append(ground_state(j_list[i,0], j_list[i,1]))\n",
    "            labels_list.append(labeling(j_list[i,0], j_list[i,1]))\n",
    "            \n",
    "    else:\n",
    "        args = [[j_list[i,0], j_list[i,1]] for i in range(num_points)]\n",
    "        \n",
    "        with mp.Pool(num_cpus) as pool:\n",
    "            gs_list = pool.starmap(ground_state, args)\n",
    "        \n",
    "        with mp.Pool(num_cpus) as pool:\n",
    "            labels_list = pool.starmap(labeling, args)\n",
    "            \n",
    "        \n",
    "    gs_list = np.array(gs_list)\n",
    "    labels_list = np.array(labels_list)\n",
    "    \n",
    "    return gs_list, labels_list, j_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convolutional_layer(q1, q2, weights):\n",
    "    qml.U3(wires=q1, theta=weights[0], phi=weights[1], delta=weights[2])\n",
    "    qml.U3(wires=q1, theta=weights[3], phi=weights[4], delta=weights[5])\n",
    "    qml.CNOT(wires=[q2, q1])\n",
    "    qml.RZ(wires=q1, phi=weights[6])\n",
    "    qml.RY(wires=q2, phi=weights[7])\n",
    "    qml.CNOT(wires=[q1, q2])\n",
    "    qml.RY(wires=q2, phi=weights[8])\n",
    "    qml.CNOT(wires=[q2, q1])\n",
    "    qml.U3(wires=q1, theta=weights[9], phi=weights[10], delta=weights[11])\n",
    "    qml.U3(wires=q1, theta=weights[12], phi=weights[13], delta=weights[14])\n",
    "\n",
    "def pooling_layer(q1, q2, weights):\n",
    "    qml.U3(wires=q1, theta=weights[0], phi=weights[1], delta=weights[2])\n",
    "    qml.U3(wires=q1, theta=weights[3], phi=weights[4], delta=weights[5])\n",
    "    qml.CNOT(wires=[q2, q1])\n",
    "    qml.RZ(wires=q1, phi=weights[6])\n",
    "    qml.RY(wires=q2, phi=weights[7])\n",
    "    qml.CNOT(wires=[q1, q2])\n",
    "    qml.RY(wires=q2, phi=weights[8])\n",
    "    qml.CNOT(wires=[q2, q1])\n",
    "    qml.U3(wires=q1, theta=weights[9], phi=weights[10], delta=weights[11])\n",
    "    qml.U3(wires=q1, theta=weights[12], phi=weights[13], delta=weights[14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_circuit(weights, state_ini):\n",
    "    \n",
    "    qubits = list(range(nqubits))\n",
    "    \n",
    "    qml.QubitStateVector(state_ini, wires=qubits)\n",
    "\n",
    "    for j in range(layers-1):\n",
    "        \n",
    "        len_qubits = len(qubits)\n",
    "        \n",
    "        for i in range(len_qubits//2):\n",
    "            convolutional_layer(qubits[2*i], qubits[(2*i+1)%len_qubits], weights[15*2*j:15*(2*j+1)])\n",
    "        \n",
    "        for i in range(len_qubits//2):\n",
    "            convolutional_layer(qubits[2*i+1], qubits[(2*i+2)%len_qubits], weights[15*2*j:15*(2*j+1)])\n",
    "            \n",
    "        for i in range(len_qubits//2):\n",
    "            pooling_layer(qubits[2*i], qubits[(2*i+1)%len_qubits], weights[15*(2*j+1):15*(2*j+2)])\n",
    "\n",
    "        qub = []\n",
    "        for i in range(len_qubits):\n",
    "            if i%2 == 1:\n",
    "                qub.append(qubits[i])\n",
    "                \n",
    "        qubits = qub\n",
    "    \n",
    "    convolutional_layer(qubits[0], qubits[1], weights[15*(2*layers-2):15*(2*layers-1)])\n",
    "    \n",
    "    return qml.expval(Z(qubits[0])), qml.expval(Z(qubits[1])), qml.expval(Z(qubits[0]) @ Z(qubits[1]))\n",
    "\n",
    "# dev_draw = qml.device(\"qiskit.aer\", wires=nqubits)\n",
    "dev = qml.device(\"default.qubit\", wires=nqubits)\n",
    "\n",
    "# cnn_draw = qml.QNode(cnn_circuit, dev_draw)\n",
    "cnn_circuit = qml.QNode(cnn_circuit, dev, interface=\"jax\", diff_method=\"best\")\n",
    "\n",
    "\n",
    "def cnn(weights, state_ini):\n",
    "    z0, z1, zz01 = cnn_circuit(weights, state_ini)\n",
    "\n",
    "    proj_00 = (1+zz01+z0+z1)/4\n",
    "    proj_01 = (1-zz01-z0+z1)/4\n",
    "    proj_10 = (1-zz01+z0-z1)/4\n",
    "    proj_11 = (1+zz01-z0-z1)/4\n",
    "\n",
    "    return jnp.array([proj_00, proj_01, proj_10, proj_11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def variational_classifier(weights, bias, state_ini):\n",
    "    return cnn(weights, state_ini) + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# draw circuit\n",
    "\n",
    "# weights = np.random.uniform(0, 2*np.pi, nweights)\n",
    "# drawer = qml.draw(cnn_circuit)\n",
    "# print(drawer(weights, gs_list[0]))\n",
    "\n",
    "# z0, z1, zz01 = cnn_draw(gs_list[0], weights)\n",
    "# print(z0, z1, zz01)\n",
    "# dev_draw._circuit.draw(output=\"mpl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def single_loss(weights, bias, ground_state, label):\n",
    "    \n",
    "    proj = variational_classifier(weights, bias, ground_state)\n",
    "\n",
    "    if loss_type == \"projectors\":\n",
    "        cost = proj[label]\n",
    "\n",
    "    elif loss_type == \"cross_entropy\":\n",
    "        cost = -jnp.log2(proj[label])\n",
    "    \n",
    "    elif loss_type == \"mean_squares\":\n",
    "        cost = 1 + jnp.linalg.norm(proj)**2 - 2*proj[label]\n",
    "    \n",
    "    return cost\n",
    "\n",
    "@jax.jit\n",
    "def loss(weights, bias, ground_states, labels):\n",
    "    costs = jax.vmap(single_loss, in_axes=[None, None, 0, 0])(weights, bias, ground_states, labels)\n",
    "    return costs.sum()/len(labels)\n",
    "\n",
    "@jax.jit\n",
    "def grad_loss(weight, bias, ground_states, labels):\n",
    "    if with_bias:\n",
    "        w, b = jax.grad(loss, argnums=[0,1])(weight, bias, ground_states, labels)\n",
    "    else:\n",
    "        w = jax.grad(loss, argnums=0)(weight, bias, ground_states, labels)\n",
    "        b = 0\n",
    "    \n",
    "    return w, b, 0, 0 #jnp.zeros(ground_states.shape), jnp.zeros(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def single_pred(weights, bias, ground_state):\n",
    "    \n",
    "    projectors = variational_classifier(weights, bias, ground_state)\n",
    "    \n",
    "    if loss_type == \"projectors\":\n",
    "        pred = np.argmin(projectors)\n",
    "    elif loss_type in [\"cross_entropy\", \"mean_squares\"]:\n",
    "        pred = np.argmax(projectors)\n",
    "\n",
    "    return pred\n",
    "\n",
    "@jax.jit\n",
    "def pred(weights, bias, ground_states):\n",
    "    predictions = jax.vmap(single_pred, in_axes=[None, None, 0])(weights, bias, ground_states)\n",
    "    return predictions\n",
    "\n",
    "@jax.jit\n",
    "def acc(predictions, labels):\n",
    "    return sum(predictions==labels)*100/len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_multi_image(filename):\n",
    "    pp = PdfPages(filename)\n",
    "    fig_nums = plt.get_fignums()\n",
    "    figs = [plt.figure(n) for n in fig_nums]\n",
    "    for fig in figs:\n",
    "        fig.savefig(pp, format='pdf')\n",
    "    pp.close()\n",
    "\n",
    "def close_all_figures():\n",
    "    fig_nums = plt.get_fignums()\n",
    "    for n in fig_nums:\n",
    "        plt.figure(n)\n",
    "        plt.close()\n",
    "\n",
    "        \n",
    "def save_plots(time_now,\n",
    "               folder_name,\n",
    "               file_name,\n",
    "               plot_run,\n",
    "               it_max,\n",
    "               acc_train,\n",
    "               acc_val,\n",
    "               losses,\n",
    "               pred_train,\n",
    "               pred_val,\n",
    "               j_train,\n",
    "               j_val\n",
    "              ):\n",
    "\n",
    "\n",
    "    fig, axis = plt.subplots(1,3)\n",
    "    fig.set_figheight(6.5)\n",
    "    fig.set_figwidth(20)\n",
    "    fig.tight_layout(pad=2, w_pad=3.5)\n",
    "\n",
    "    # ---------------------------------------------------------------------- #\n",
    "    # -------------------- Loss and accuracy figure ------------------------ #\n",
    "    # ---------------------------------------------------------------------- #\n",
    "\n",
    "    iterations = range(1, num_iters+1)\n",
    "\n",
    "    color1 = 'darkred'\n",
    "    axis[0].set_xlabel('Iterations')\n",
    "    axis[0].set_ylabel('Accuracy %', color=color1)\n",
    "    axis[0].plot(iterations, acc_train, label=\"Training\", color=color1)\n",
    "    axis[0].plot(iterations, acc_val, '-.', label=\"Validation\", color=color1)\n",
    "    axis[0].tick_params(axis='y', labelcolor=color1)\n",
    "    axis[0].set_ylim(0,100)\n",
    "\n",
    "    ax2 = axis[0].twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "    color2 = 'darkblue'\n",
    "    ax2.set_ylabel('Loss', color=color2)  # we already handled the x-label with axis[0]\n",
    "    ax2.plot(iterations, losses, label=\"Loss\", color=color2)\n",
    "    ax2.tick_params(axis='y', labelcolor=color2)\n",
    "    # ax2.set_ylim(bottom=0)\n",
    "\n",
    "    # fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "    # plt.legend()\n",
    "    axis[0].set_title(f\"Accuracy and Loss - Run {plot_run}\")\n",
    "\n",
    "\n",
    "    # ----------------------------------------------------------------------------- #\n",
    "    # ---------------------------- Training points -------------------------------- #\n",
    "    # ----------------------------------------------------------------------------- #\n",
    "\n",
    "    plot_iter = num_iters-1\n",
    "\n",
    "    # define regions coordinates\n",
    "    x01, y01 = region01_coords[:,0], region01_coords[:,1]\n",
    "    x02, y02 = region02_coords[:,0], region02_coords[:,1]\n",
    "    x1, y1 = region1_coords[:,0], region1_coords[:,1]\n",
    "    x2, y2 = region2_coords[:,0], region2_coords[:,1]\n",
    "    x3, y3 = region3_coords[:,0], region3_coords[:,1]\n",
    "\n",
    "    # put the regions into the plot\n",
    "    axis[1].fill(x01, y01, facecolor='lightskyblue')    # class 0\n",
    "    axis[1].fill(x02, y02, facecolor='lightskyblue')    # class 0\n",
    "    axis[1].fill(x1, y1, facecolor='sandybrown')        # class 1\n",
    "    axis[1].fill(x2, y2, facecolor='salmon')            # class 2\n",
    "    axis[1].fill(x3, y3, facecolor='lightgreen')        # class 3\n",
    "\n",
    "    pred_train_plot = np.array(pred_train[plot_iter])\n",
    "    pred_val_plot = np.array(pred_val[plot_iter])\n",
    "\n",
    "    colors = [\"b\", \"orange\", \"r\", \"g\"]\n",
    "\n",
    "    # plot datapoints\n",
    "    for i in range(4):\n",
    "        axis[1].scatter(\n",
    "            j_train[:, 0][pred_train_plot==i],\n",
    "            j_train[:, 1][pred_train_plot==i],\n",
    "            c=colors[i],\n",
    "            marker=\"o\",\n",
    "            edgecolors=\"k\",\n",
    "            label=f\"class {i+1} train\",\n",
    "        )\n",
    "        # if with_val:\n",
    "        #     axis[1].scatter(\n",
    "        #         j_val[:, 0][pred_val_plot==i],\n",
    "        #         j_val[:, 1][pred_val_plot==i],\n",
    "        #         c=colors[i],\n",
    "        #         marker=\"^\",\n",
    "        #         edgecolors=\"k\",\n",
    "        #         label=f\"class {i+1} validation\",\n",
    "        #     )\n",
    "\n",
    "\n",
    "    # plt.legend()\n",
    "    axis[1].set_title(f\"Training ({acc_train[plot_iter]:.0f}%)\")\n",
    "\n",
    "\n",
    "    # ------------------------------------------------------------------------------ #\n",
    "    # ---------------------------- Validation points ------------------------------- #\n",
    "    # ------------------------------------------------------------------------------ #\n",
    "\n",
    "\n",
    "    plot_iter = num_iters-1\n",
    "\n",
    "    # define regions coordinates\n",
    "    x01, y01 = region01_coords[:,0], region01_coords[:,1]\n",
    "    x02, y02 = region02_coords[:,0], region02_coords[:,1]\n",
    "    x1, y1 = region1_coords[:,0], region1_coords[:,1]\n",
    "    x2, y2 = region2_coords[:,0], region2_coords[:,1]\n",
    "    x3, y3 = region3_coords[:,0], region3_coords[:,1]\n",
    "\n",
    "    # put the regions into the plot\n",
    "    axis[2].fill(x01, y01, facecolor='lightskyblue')    # class 0\n",
    "    axis[2].fill(x02, y02, facecolor='lightskyblue')    # class 0\n",
    "    axis[2].fill(x1, y1, facecolor='sandybrown')        # class 1\n",
    "    axis[2].fill(x2, y2, facecolor='salmon')            # class 2\n",
    "    axis[2].fill(x3, y3, facecolor='lightgreen')        # class 3\n",
    "\n",
    "    pred_train_plot = np.array(pred_train[plot_iter])\n",
    "    pred_val_plot = np.array(pred_val[plot_iter])\n",
    "\n",
    "    colors = [\"b\", \"orange\", \"r\", \"g\"]\n",
    "\n",
    "    # plot datapoints\n",
    "    for i in range(4):\n",
    "        # axis[2].scatter(\n",
    "        #     j_train[:, 0][pred_train_plot==i],\n",
    "        #     j_train[:, 1][pred_train_plot==i],\n",
    "        #     c=colors[i],\n",
    "        #     marker=\"o\",\n",
    "        #     edgecolors=\"k\",\n",
    "        #     label=f\"class {i+1} train\",\n",
    "        # )\n",
    "        if with_val:\n",
    "            axis[2].scatter(\n",
    "                j_val[:, 0][pred_val_plot==i],\n",
    "                j_val[:, 1][pred_val_plot==i],\n",
    "                c=colors[i],\n",
    "                marker=\"^\",\n",
    "                edgecolors=\"k\",\n",
    "                label=f\"class {i+1} validation\",\n",
    "            )\n",
    "\n",
    "\n",
    "    # plt.legend()\n",
    "    axis[2].set_title(f\"Validation ({acc_val[plot_iter]:.0f}%)\")\n",
    "\n",
    "    # ---------------------------------------------------------------------- #\n",
    "    # --------------------------- Save plots ------------------------------- #\n",
    "    # ---------------------------------------------------------------------- #\n",
    "\n",
    "    plots_pdf_name = f\"{folder_name}/{time_now} - Plots - {file_name}.pdf\"\n",
    "    \n",
    "    \n",
    "    # If the file doesn't exist we save it. If it does, we merge it.\n",
    "    if not os.path.isfile(plots_pdf_name):\n",
    "        save_multi_image(plots_pdf_name)\n",
    "    \n",
    "    else:\n",
    "        save_multi_image(plots_pdf_name + \"2\")\n",
    "        # Merge the new plot with the rest and delete the last file\n",
    "        merger = PdfMerger()\n",
    "        merger.append(plots_pdf_name)\n",
    "        merger.append(plots_pdf_name + \"2\")\n",
    "        merger.write(plots_pdf_name)\n",
    "        merger.close()\n",
    "        os.remove(plots_pdf_name + \"2\")\n",
    "    \n",
    "    close_all_figures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_hyperparameters(time_now, folder_name, file_name):\n",
    "    \n",
    "    # --------------- Hyperparameters -----------------#\n",
    "    hyperparameters = {}\n",
    "    hyperparameters[\"num_iters\"] = [num_iters]\n",
    "    hyperparameters[\"num_runs\"] = [num_runs]\n",
    "    hyperparameters[\"cl_types\"] = [cl_types]\n",
    "    hyperparameters[\"with_val\"] = [with_val]\n",
    "    hyperparameters[\"nqubits\"] = [nqubits]\n",
    "    hyperparameters[\"with_bias\"] = [with_bias]\n",
    "    hyperparameters[\"optimizer\"] = [optimizer]\n",
    "    hyperparameters[\"loss_type\"] = [loss_type]\n",
    "    hyperparameters[\"initialization\"] = [initialization]\n",
    "    hyperparameters[\"batch_size\"] = [batch_size]\n",
    "    hyperparameters[\"train_size\"] = [train_size]\n",
    "    hyperparameters[\"val_size\"] = [val_size]\n",
    "    hyperparameters[\"cl_ratios\"] = [cl_ratios]\n",
    "    hyperparameters[\"uniform_train\"] = [uniform_train]\n",
    "    hyperparameters[\"uniform_val\"] = [uniform_val]\n",
    "    hyperparameters[\"epsilon_train\"] = [epsilon_train]\n",
    "    hyperparameters[\"epsilon_val\"] = [epsilon_val]\n",
    "    hyperparameters[\"num_cpus_gs_train\"] = [num_cpus_gs_train]\n",
    "    hyperparameters[\"num_cpus_gs_val\"] = [num_cpus_gs_val]\n",
    "    hyperparameters[\"max_weight_init\"] = [max_weight_init]\n",
    "    hyperparameters[\"stepsize\"] = [stepsize]\n",
    "    hyperparameters[\"key\"] = [time_now]\n",
    "\n",
    "    hyperparameters = pd.DataFrame(hyperparameters)\n",
    "\n",
    "    hyperparameters_file_name = f\"{folder_name}/{time_now} - Hyperparameters{file_name}.csv\"\n",
    "    hyperparameters.to_csv(hyperparameters_file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(time_now,\n",
    "                folder_name,\n",
    "                run,\n",
    "                weights,\n",
    "                bias,\n",
    "                losses,\n",
    "                j_train,\n",
    "                j_val,\n",
    "                pred_train,\n",
    "                pred_val,\n",
    "                acc_train,\n",
    "                acc_val,\n",
    "                run_time,\n",
    "                cl\n",
    "               ):\n",
    "    \n",
    "    # -------------------- Total Data -------------------- #\n",
    "    data = {}\n",
    "    data[\"run\"] = run\n",
    "    \n",
    "    it_max = np.argmax(np.array(acc_train))\n",
    "    acc_train_max = acc_train[it_max]\n",
    "    acc_train_last = acc_train[num_iters-1]\n",
    "    acc_val_max = acc_val[it_max]\n",
    "    acc_val_last = acc_val[num_iters-1]\n",
    "    \n",
    "    data[\"it_max\"] = it_max\n",
    "    data[\"acc_train_max\"] = acc_train_max\n",
    "    data[\"acc_train_last\"] = acc_train_last\n",
    "    data[\"acc_val_max\"] = acc_val_max\n",
    "    data[\"acc_val_last\"] = acc_val_last\n",
    "    data[\"run_time\"] = run_time\n",
    "    \n",
    "    data[\"weights\"] = [weights]\n",
    "    data[\"bias\"] = [bias]\n",
    "    data[\"losses\"] = [losses]\n",
    "    data[\"j_train\"] = [j_train.tolist()]\n",
    "    data[\"j_val\"] = [j_val.tolist()]\n",
    "    data[\"pred_train\"] = [pred_train]\n",
    "    data[\"pred_val\"] = [pred_val]\n",
    "    data[\"acc_train\"] = [acc_train]\n",
    "    data[\"acc_val\"] = [acc_val]\n",
    "    \n",
    "\n",
    "    data = pd.DataFrame(data)\n",
    "    \n",
    "    data_file_name = f\"{folder_name}/{time_now} - Data - {cl}.csv\"\n",
    "    data.to_csv(data_file_name, index=False, mode='a', header = not os.path.exists(data_file_name))\n",
    "    \n",
    "    \n",
    "    # ------------------- Results ------------------- #\n",
    "    \n",
    "    read_data = pd.read_csv(data_file_name,\n",
    "                     usecols=[\"it_max\",\n",
    "                              \"acc_train_max\",\n",
    "                              \"acc_val_max\",\n",
    "                              \"acc_train\",\n",
    "                              \"acc_val\"],\n",
    "                     converters={\"acc_train\":ast.literal_eval,\n",
    "                                 \"acc_val\":ast.literal_eval})\n",
    "    \n",
    "    total_it_max = read_data[\"it_max\"]\n",
    "    total_acc_train_max = read_data[\"acc_train_max\"]\n",
    "    total_acc_val_max = read_data[\"acc_val_max\"]\n",
    "    total_acc_train = read_data[\"acc_train\"].tolist()\n",
    "    total_acc_val = read_data[\"acc_val\"].tolist()\n",
    "    \n",
    "    best_run_max = total_acc_train_max.argmax()\n",
    "    best_it_max = total_it_max[best_run_max]\n",
    "    avg_acc_train_max = total_acc_train_max.mean()\n",
    "    avg_acc_val_max = total_acc_val_max.mean()\n",
    "    \n",
    "    best_run_last = np.argmax(np.array(total_acc_train)[:,num_iters-1])\n",
    "    avg_acc_train_last = np.mean(np.array(total_acc_train)[:,num_iters-1])\n",
    "    avg_acc_val_last = np.mean(np.array(total_acc_val)[:,num_iters-1])\n",
    "\n",
    "    results = {}\n",
    "    results[\"type_cv\"] = [cl]\n",
    "    results[\"num_runs\"] = [run+1]\n",
    "    results[\"best_run_max\"] = [best_run_max]\n",
    "    results[\"best_run_last\"] = [best_run_last]\n",
    "    results[\"best_it_max\"] = [best_it_max]\n",
    "    results[\"best_it_last\"] = [num_iters-1]\n",
    "    results[\"best_acc_train_max\"] = [total_acc_train[best_run_max][best_it_max]]\n",
    "    results[\"best_acc_train_last\"] = [total_acc_train[best_run_max][num_iters-1]]\n",
    "    results[\"best_acc_val_max\"] = [total_acc_val[best_run_max][best_it_max]]\n",
    "    results[\"best_acc_val_last\"] = [total_acc_val[best_run_max][num_iters-1]]\n",
    "    results[\"avg_acc_train_max\"] = [avg_acc_train_max]\n",
    "    results[\"avg_acc_train_last\"] = [avg_acc_train_last]\n",
    "    results[\"avg_acc_val_max\"] = [avg_acc_val_max]\n",
    "    results[\"avg_acc_val_last\"] = [avg_acc_val_last]\n",
    "    results = pd.DataFrame(results)\n",
    "\n",
    "    results_file_name = f\"{folder_name}/{time_now} - Results.csv\"\n",
    "    \n",
    "    # If file exists, we update the info\n",
    "    if os.path.exists(results_file_name):\n",
    "        read_results = pd.read_csv(results_file_name)\n",
    "        row_index = read_results.loc[read_results[\"type_cv\"] == cl].index\n",
    "        \n",
    "        if row_index.shape != (0,):\n",
    "            read_results.drop(labels=row_index[0], axis=0, inplace=True) # we delete the line if it already exists\n",
    "            \n",
    "        results = pd.concat([read_results, results], ignore_index=True)\n",
    "    \n",
    "    results.to_csv(results_file_name, index=False)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ------------------- Plots ------------------- #\n",
    "    save_plots(time_now,\n",
    "               folder_name,\n",
    "               cl,\n",
    "               run,\n",
    "               it_max,\n",
    "               acc_train,\n",
    "               acc_val,\n",
    "               losses,\n",
    "               pred_train,\n",
    "               pred_val,\n",
    "               j_train,\n",
    "               j_val\n",
    "              )\n",
    "    \n",
    "    if cl == \"NCL\":\n",
    "        cl_str = \"NCL  \"\n",
    "    elif cl==\"CL\":\n",
    "        cl_str = \"CL   \"\n",
    "    elif cl==\"ACL\":\n",
    "        cl_str = \"ACL  \"\n",
    "    elif cl==\"SPCL\":\n",
    "        cl_str = \"SPCL \"\n",
    "    elif cl==\"SPACL\":\n",
    "        cl_str = \"SPACL\"\n",
    "        \n",
    "    print(\n",
    "        f\" {cl_str} |\"\n",
    "        f\" {run:3d} |\"\n",
    "        f\" {it_max:4d}/{num_iters-1:4d} |\"\n",
    "        f\"  {acc_train[it_max]:0.0f}/{acc_train[num_iters-1]:0.0f}  |\"\n",
    "        f\" {acc_val[it_max]:0.0f}/{acc_val[num_iters-1]:0.0f} |\"\n",
    "        f\" {run_time:0.0f}\"\n",
    "    )\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdamOptimizer2(qml.AdamOptimizer):\n",
    "    def apply_grad(self, grad, args):\n",
    "        r\"\"\"Update the variables args to take a single optimization step. Flattens and unflattens\n",
    "        the inputs to maintain nested iterables as the parameters of the optimization.\n",
    "\n",
    "        Args:\n",
    "            grad (tuple[ndarray]): the gradient of the objective\n",
    "                function at point :math:`x^{(t)}`: :math:`\\nabla f(x^{(t)})`\n",
    "            args (tuple): the current value of the variables :math:`x^{(t)}`\n",
    "\n",
    "        Returns:\n",
    "            list: the new values :math:`x^{(t+1)}`\n",
    "        \"\"\"\n",
    "        args_new = list(args)\n",
    "\n",
    "        if self.accumulation is None:\n",
    "            self.accumulation = {\"fm\": [0] * len(args), \"sm\": [0] * len(args), \"t\": 0}\n",
    "\n",
    "        self.accumulation[\"t\"] += 1\n",
    "\n",
    "        # Update step size (instead of correcting for bias)\n",
    "        new_stepsize = (\n",
    "            self.stepsize\n",
    "            * pnp.sqrt(1 - self.beta2 ** self.accumulation[\"t\"])\n",
    "            / (1 - self.beta1 ** self.accumulation[\"t\"])\n",
    "        )\n",
    "\n",
    "        trained_index = 0\n",
    "        for index, arg in enumerate(args):\n",
    "            self._update_accumulation(index, grad[trained_index])\n",
    "            args_new[index] = arg - new_stepsize * self.accumulation[\"fm\"][index] / (\n",
    "                pnp.sqrt(self.accumulation[\"sm\"][index]) + self.eps\n",
    "            )\n",
    "            trained_index += 1\n",
    "\n",
    "        return args_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientDescentOptimizer2(qml.GradientDescentOptimizer):\n",
    "    def apply_grad(self, grad, args):\n",
    "        r\"\"\"Update the variables to take a single optimization step. Flattens and unflattens\n",
    "        the inputs to maintain nested iterables as the parameters of the optimization.\n",
    "\n",
    "        Args:\n",
    "            grad (tuple [array]): the gradient of the objective\n",
    "                function at point :math:`x^{(t)}`: :math:`\\nabla f(x^{(t)})`\n",
    "            args (tuple): the current value of the variables :math:`x^{(t)}`\n",
    "\n",
    "        Returns:\n",
    "            list [array]: the new values :math:`x^{(t+1)}`\n",
    "        \"\"\"\n",
    "        args_new = list(args)\n",
    "\n",
    "        trained_index = 0\n",
    "        for index, arg in enumerate(args):\n",
    "            args_new[index] = arg - self.stepsize * grad[trained_index]\n",
    "\n",
    "            trained_index += 1\n",
    "\n",
    "        return args_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_qcnn(gs_train, gs_val, labels_train, labels_val, j_train, cl):\n",
    "    \n",
    "    if initialization == \"uniform\":\n",
    "        weights_init = np.random.uniform(0, max_weight_init, nweights)\n",
    "    elif initialization == \"gaussian\":\n",
    "        weights_init = np.random.normal(0, 1/np.sqrt(nqubits), nweights)\n",
    "        \n",
    "    bias_init = np.array([0.0]*4)\n",
    "    \n",
    "    # choose variational classifier\n",
    "    if optimizer == \"Nesterov\":\n",
    "        opt = NesterovMomentumOptimizer(stepsize)\n",
    "    elif optimizer == \"Adam\":\n",
    "        opt = AdamOptimizer2(stepsize=stepsize, beta1=0.9, beta2=0.99, eps=1e-08)\n",
    "    elif optimizer == \"GradientDescent\":\n",
    "        opt = GradientDescentOptimizer2(stepsize)\n",
    "\n",
    "    #Initiaize variables\n",
    "    weights = []\n",
    "    bias = []\n",
    "    losses = []\n",
    "    pred_train_arr = []\n",
    "    pred_val_arr = []\n",
    "    acc_train_arr = []\n",
    "    acc_val_arr = []\n",
    "\n",
    "    w = weights_init\n",
    "    b = bias_init\n",
    "    \n",
    "    for it in range(num_iters):\n",
    "        \n",
    "        # For self paced learning, we sort the datapoints at every iteration\n",
    "        if cl in [\"SPCL\", \"SPACL\"]:\n",
    "        \n",
    "            scores = jax.vmap(single_loss, in_axes=[None, None, 0, 0])(jnp.array(w), jnp.array(b), jnp.array(gs_train), jnp.array(labels_train)).tolist()\n",
    "            \n",
    "            table = {}\n",
    "            table[\"gs_train\"] = gs_train.tolist()\n",
    "            table[\"labels_train\"] = labels_train\n",
    "            table[\"j_train\"] = j_train.tolist()\n",
    "            table[\"scores\"] = scores\n",
    "\n",
    "            table = pd.DataFrame(table)\n",
    "            \n",
    "            if cl == \"SPCL\":\n",
    "                table.sort_values(by=[\"scores\"], inplace=True, ascending=True)\n",
    "            elif cl == \"SPACL\":\n",
    "                table.sort_values(by=[\"scores\"], inplace=True, ascending=False)\n",
    "\n",
    "            gs_train = np.array(list(table[\"gs_train\"]))\n",
    "            labels_train = np.array(list(table[\"labels_train\"]))\n",
    "            j_train = np.array(list(table[\"j_train\"]))\n",
    "        \n",
    "        \n",
    "        # Once they are sorted, we select the first datapoints into the batch lists\n",
    "        if cl in [\"CL\", \"ACL\", \"SPCL\", \"SPACL\"]:\n",
    "            cv_size_batches, cv_limits_it = [], []\n",
    "            limit_iter, size_batch = 0, 0\n",
    "            \n",
    "            for i, ratio in enumerate(cl_ratios):\n",
    "                \n",
    "                if i < len(cl_ratios)-1:\n",
    "                    limit_iter += round(1/len(cl_ratios)*num_iters) #round(ratio*num_iters)\n",
    "                    size_batch += round(ratio*len(labels_train))\n",
    "                else:\n",
    "                    limit_iter = num_iters\n",
    "                    size_batch = len(labels_train)\n",
    "                \n",
    "                cv_limits_it.append(limit_iter)\n",
    "                cv_size_batches.append(size_batch)\n",
    "            \n",
    "            index_size_batch = np.argmax(it < np.array(cv_limits_it)) # This gives you the first occurrence where the condition is met\n",
    "            cv_size_batch = cv_size_batches[index_size_batch]\n",
    "            \n",
    "            gs_train_batch = gs_train[:cv_size_batch]\n",
    "            labels_train_batch = labels_train[:cv_size_batch]\n",
    "        \n",
    "        else:\n",
    "            batch_index = np.random.default_rng().choice(len(labels_train), size=batch_size, replace=False)\n",
    "            \n",
    "            gs_train_batch = gs_train[batch_index]\n",
    "            labels_train_batch = labels_train[batch_index]\n",
    "\n",
    "            \n",
    "        # Update the weights by one optimizer step\n",
    "        w, b, _, _ = opt.step(loss, w, b, gs_train_batch, labels_train_batch, grad_fn=grad_loss)\n",
    "        \n",
    "        weights.append(w.tolist())\n",
    "        bias.append(b.tolist())\n",
    "\n",
    "        # Compute predictions and accuracy on train and validation set\n",
    "        pred_train = pred(w, b, gs_train)\n",
    "        if with_val:\n",
    "            pred_val = pred(w, b, gs_val) if len(labels_val) > 0 else None\n",
    "        else:\n",
    "            pred_val = np.array([0]*len(labels_val))\n",
    "        \n",
    "        acc_train = acc(pred_train, labels_train)\n",
    "        if with_val:\n",
    "            acc_val = acc(pred_val, labels_val) if len(labels_val) > 0 else 0\n",
    "        else:\n",
    "            acc_val = 0\n",
    "        \n",
    "        \n",
    "        # Save prediction for later plotting\n",
    "        pred_train_arr.append(pred_train.tolist())\n",
    "        pred_val_arr.append(pred_val.tolist())\n",
    "        acc_train_arr.append(float(acc_train))\n",
    "        acc_val_arr.append(float(acc_val))\n",
    "\n",
    "        l = loss(w, b, gs_train, labels_train)\n",
    "        losses.append(l.tolist())\n",
    "    \n",
    "    return weights, bias, losses, pred_train_arr, pred_val_arr, acc_train_arr, acc_val_arr, j_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    # with jax.profiler.trace(\"/tmp/jax-trace\", create_perfetto_link=True):\n",
    "\n",
    "    time_now = datetime.now(pytz.timezone('Europe/Andorra')).strftime(\"%Y-%m-%d %H-%M-%S\")\n",
    "\n",
    "    folder_name = f\"Results/{nqubits}q - {num_iters:} iters/\"\n",
    "    if not os.path.isdir(f'{folder_name}'):\n",
    "        os.makedirs(f'{folder_name}')\n",
    "\n",
    "    save_hyperparameters(time_now, folder_name, file_name=\"\")\n",
    "\n",
    "\n",
    "    # -------------------------------------------------------------- #\n",
    "    # ------------------- Generate ground states ------------------- #\n",
    "    # -------------------------------------------------------------- #\n",
    "\n",
    "    print(\"Generating ground states...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    gs_train, labels_train, j_train = generate_gs(train_size, uniform_train, epsilon_train, num_cpus_gs_train)\n",
    "    if with_val:\n",
    "        gs_val, labels_val, j_val = generate_gs(val_size, uniform_val, epsilon_val, num_cpus_gs_val)\n",
    "\n",
    "    run_time = time.time() - start_time\n",
    "\n",
    "    print(f\"Ground states generated - {run_time:.0f}s\")\n",
    "    print()\n",
    "    print(\"Max train / Last run\")\n",
    "    print(\"-------------------------------------------------\")\n",
    "    print(\"  CL   | Run |   Iter    |Acc train|Acc val| Time  \")\n",
    "    print(\"-------------------------------------------------\")\n",
    "\n",
    "    for run in range (num_runs):\n",
    "        \n",
    "        for cl in cl_types:\n",
    "            # ----------------------------------------------------------------------------------------------- #\n",
    "            # ------------------------ Sort training gs by their score if curriculum ------------------------ #\n",
    "            # ----------------------------------------------------------------------------------------------- #\n",
    "\n",
    "            if cl in [\"CL\", \"ACL\"]:\n",
    "                score_it = num_iters-1 # num_iters-1 or it_max\n",
    "                scores = jax.vmap(single_loss, in_axes=[None, None, 0, 0])(jnp.array(weights[score_it]), jnp.array(bias[score_it]), jnp.array(gs_train), jnp.array(labels_train)).tolist()\n",
    "                \n",
    "                table = {}\n",
    "                table[\"gs_train\"] = gs_train.tolist()\n",
    "                table[\"labels_train\"] = labels_train\n",
    "                table[\"j_train\"] = j_train.tolist()\n",
    "                table[\"scores\"] = scores\n",
    "\n",
    "                table = pd.DataFrame(table)\n",
    "                \n",
    "                if cl == \"CL\":\n",
    "                    table.sort_values(by=[\"scores\"], inplace=True, ascending=True)\n",
    "                elif cl == \"ACL\":\n",
    "                    table.sort_values(by=[\"scores\"], inplace=True, ascending=False)\n",
    "\n",
    "                gs_train = np.array(list(table[\"gs_train\"]))\n",
    "                labels_train = np.array(list(table[\"labels_train\"]))\n",
    "                j_train = np.array(list(table[\"j_train\"]))\n",
    "\n",
    "\n",
    "            # ------------------------------------------------------------ #\n",
    "            # ------------------------ Train QCNN ------------------------ #\n",
    "            # ------------------------------------------------------------ #\n",
    "\n",
    "            start_time = time.time()\n",
    "\n",
    "            weights, \\\n",
    "            bias, \\\n",
    "            losses, \\\n",
    "            pred_train_arr, \\\n",
    "            pred_val_arr, \\\n",
    "            acc_train_arr, \\\n",
    "            acc_val_arr, \\\n",
    "            cv_j_train = train_qcnn(gs_train,\n",
    "                                    gs_val,\n",
    "                                    labels_train,\n",
    "                                    labels_val,\n",
    "                                    j_train,\n",
    "                                    cl=cl\n",
    "                                    )\n",
    "\n",
    "            run_time = time.time() - start_time\n",
    "\n",
    "\n",
    "            # --------------------------------------------------------- #\n",
    "            # ------------------- Save calculations ------------------- #\n",
    "            # --------------------------------------------------------- #\n",
    "            save_data(time_now,\n",
    "                    folder_name,\n",
    "                    run,\n",
    "                    weights,\n",
    "                    bias,\n",
    "                    losses,\n",
    "                    cv_j_train,\n",
    "                    j_val,\n",
    "                    pred_train_arr,\n",
    "                    pred_val_arr,\n",
    "                    acc_train_arr,\n",
    "                    acc_val_arr,\n",
    "                    run_time,\n",
    "                    cl=cl\n",
    "                    )\n",
    "\n",
    "    print(\"---------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating ground states...\n",
      "Ground states generated - 90s\n",
      "\n",
      "Max train / Last run\n",
      "-------------------------------------------------\n",
      "  CL   | Run |   Iter    |Acc train|Acc val| Time  \n",
      "-------------------------------------------------\n",
      " NCL   |   0 |  235/ 499 |  90/85  | 81/80 | 107\n",
      " CL    |   0 |  404/ 499 |  90/90  | 85/87 | 150\n",
      " ACL   |   0 |  385/ 499 |  100/92  | 92/87 | 78\n",
      " SPCL  |   0 |  407/ 499 |  92/85  | 84/83 | 80\n",
      " SPACL |   0 |  122/ 499 |  100/92  | 87/88 | 68\n",
      " NCL   |   1 |  230/ 499 |  92/90  | 86/87 | 69\n",
      " CL    |   1 |  407/ 499 |  85/85  | 82/86 | 64\n",
      " ACL   |   1 |  387/ 499 |  100/92  | 89/91 | 75\n",
      " SPCL  |   1 |  393/ 499 |  90/88  | 86/88 | 88\n",
      " SPACL |   1 |   94/ 499 |  100/92  | 89/88 | 72\n",
      " NCL   |   2 |  100/ 499 |  92/85  | 86/84 | 66\n",
      " CL    |   2 |  484/ 499 |  90/90  | 85/86 | 80\n",
      " ACL   |   2 |  383/ 499 |  98/90  | 89/86 | 76\n",
      " SPCL  |   2 |  468/ 499 |  96/94  | 89/86 | 82\n",
      " SPACL |   2 |   88/ 499 |  100/98  | 93/94 | 82\n",
      " NCL   |   3 |  264/ 499 |  96/92  | 88/89 | 72\n",
      " CL    |   3 |  360/ 499 |  92/92  | 85/87 | 62\n",
      " ACL   |   3 |  296/ 499 |  98/88  | 88/83 | 66\n",
      " SPCL  |   3 |  489/ 499 |  92/92  | 86/86 | 73\n",
      " SPACL |   3 |   36/ 499 |  100/94  | 89/88 | 86\n",
      " NCL   |   4 |  451/ 499 |  94/94  | 87/87 | 85\n",
      " CL    |   4 |  477/ 499 |  94/92  | 88/88 | 61\n",
      " ACL   |   4 |  477/ 499 |  94/92  | 87/87 | 84\n",
      " SPCL  |   4 |  416/ 499 |  96/96  | 84/88 | 97\n",
      " SPACL |   4 |   74/ 499 |  100/88  | 85/85 | 88\n",
      " NCL   |   5 |  354/ 499 |  90/90  | 83/84 | 87\n",
      " CL    |   5 |  456/ 499 |  88/85  | 79/80 | 83\n",
      " ACL   |   5 |  392/ 499 |  100/94  | 91/90 | 80\n",
      " SPCL  |   5 |  424/ 499 |  98/94  | 91/91 | 87\n",
      " SPACL |   5 |   75/ 499 |  100/90  | 89/86 | 90\n",
      " NCL   |   6 |  358/ 499 |  92/92  | 87/86 | 95\n",
      " CL    |   6 |  414/ 499 |  92/92  | 87/87 | 90\n",
      " ACL   |   6 |  378/ 499 |  92/88  | 83/85 | 64\n",
      " SPCL  |   6 |  379/ 499 |  94/88  | 84/84 | 70\n",
      " SPACL |   6 |   78/ 499 |  100/85  | 93/83 | 75\n",
      " NCL   |   7 |   19/ 499 |  90/88  | 77/86 | 75\n",
      " CL    |   7 |  428/ 499 |  92/92  | 86/87 | 69\n",
      " ACL   |   7 |  379/ 499 |  98/85  | 89/86 | 95\n",
      " SPCL  |   7 |  445/ 499 |  98/98  | 93/93 | 100\n",
      " SPACL |   7 |  161/ 499 |  100/83  | 88/82 | 72\n",
      " NCL   |   8 |   15/ 499 |  100/96  | 93/91 | 75\n",
      " CL    |   8 |  472/ 499 |  92/92  | 86/88 | 81\n",
      " ACL   |   8 |  459/ 499 |  98/98  | 94/94 | 64\n",
      " SPCL  |   8 |  413/ 499 |  98/98  | 91/90 | 59\n",
      " SPACL |   8 |   34/ 499 |  100/94  | 92/92 | 60\n",
      " NCL   |   9 |  279/ 499 |  94/94  | 90/92 | 79\n",
      " CL    |   9 |  469/ 499 |  88/88  | 77/79 | 75\n",
      " ACL   |   9 |  402/ 499 |  94/92  | 89/90 | 72\n",
      " SPCL  |   9 |  410/ 499 |  92/92  | 90/90 | 74\n",
      " SPACL |   9 |   75/ 499 |  100/85  | 92/84 | 85\n",
      "---------------------------------------------------\n",
      "Generating ground states...\n",
      "Ground states generated - 90s\n",
      "\n",
      "Max train / Last run\n",
      "-------------------------------------------------\n",
      "  CL   | Run |   Iter    |Acc train|Acc val| Time  \n",
      "-------------------------------------------------\n",
      " NCL   |   0 |  378/ 499 |  92/92  | 80/81 | 92\n",
      " CL    |   0 |  497/ 499 |  83/83  | 76/76 | 92\n",
      " ACL   |   0 |  486/ 499 |  88/85  | 74/82 | 84\n",
      " SPCL  |   0 |  443/ 499 |  94/90  | 86/85 | 68\n",
      " SPACL |   0 |   81/ 499 |  100/85  | 82/78 | 77\n",
      " NCL   |   1 |  196/ 499 |  88/81  | 79/79 | 74\n",
      " CL    |   1 |  450/ 499 |  90/90  | 81/82 | 69\n",
      " ACL   |   1 |  385/ 499 |  96/90  | 88/84 | 65\n",
      " SPCL  |   1 |  467/ 499 |  83/83  | 75/75 | 71\n",
      " SPACL |   1 |  142/ 499 |  100/94  | 88/79 | 85\n",
      " NCL   |   2 |  201/ 499 |  90/85  | 84/80 | 72\n",
      " CL    |   2 |  446/ 499 |  90/90  | 81/83 | 66\n",
      " ACL   |   2 |  381/ 499 |  98/98  | 90/89 | 67\n",
      " SPCL  |   2 |  493/ 499 |  92/92  | 81/81 | 76\n",
      " SPACL |   2 |   48/ 499 |  100/81  | 85/75 | 75\n",
      " NCL   |   3 |  100/ 499 |  98/90  | 85/83 | 73\n",
      " CL    |   3 |  132/ 499 |  75/75  | 67/72 | 78\n",
      " ACL   |   3 |  347/ 499 |  100/96  | 90/83 | 71\n",
      " SPCL  |   3 |  436/ 499 |  100/90  | 89/86 | 73\n",
      " SPACL |   3 |   48/ 499 |  100/90  | 84/83 | 87\n",
      " NCL   |   4 |  356/ 499 |  88/85  | 78/79 | 74\n",
      " CL    |   4 |  420/ 499 |  85/85  | 80/81 | 60\n",
      " ACL   |   4 |  404/ 499 |  83/75  | 76/71 | 63\n",
      " SPCL  |   4 |  482/ 499 |  96/96  | 82/84 | 59\n",
      " SPACL |   4 |  196/ 499 |  100/75  | 91/72 | 64\n",
      " NCL   |   5 |  479/ 499 |  85/85  | 78/81 | 75\n",
      " CL    |   5 |  430/ 499 |  85/83  | 78/78 | 53\n",
      " ACL   |   5 |  427/ 499 |  92/92  | 86/86 | 67\n",
      " SPCL  |   5 |  498/ 499 |  81/81  | 74/74 | 66\n",
      " SPACL |   5 |   42/ 499 |  100/88  | 89/80 | 78\n",
      " NCL   |   6 |  462/ 499 |  98/98  | 86/86 | 86\n",
      " CL    |   6 |  129/ 499 |  77/75  | 72/72 | 85\n",
      " ACL   |   6 |  489/ 499 |  92/92  | 89/89 | 82\n",
      " SPCL  |   6 |  432/ 499 |  98/98  | 88/91 | 66\n",
      " SPACL |   6 |  101/ 499 |  100/77  | 91/74 | 70\n",
      " NCL   |   7 |  236/ 499 |  94/88  | 84/84 | 83\n",
      " CL    |   7 |  413/ 499 |  81/81  | 76/79 | 65\n",
      " ACL   |   7 |  465/ 499 |  75/73  | 73/71 | 69\n",
      " SPCL  |   7 |  430/ 499 |  96/96  | 86/85 | 71\n",
      " SPACL |   7 |   54/ 499 |  100/94  | 94/89 | 84\n",
      " NCL   |   8 |  145/ 499 |  92/88  | 81/84 | 71\n",
      " CL    |   8 |  393/ 499 |  85/85  | 77/80 | 68\n",
      " ACL   |   8 |  403/ 499 |  92/92  | 87/84 | 66\n",
      " SPCL  |   8 |  430/ 499 |  73/73  | 62/67 | 72\n",
      " SPACL |   8 |   90/ 499 |  100/77  | 88/72 | 96\n",
      " NCL   |   9 |  263/ 499 |  92/85  | 82/82 | 86\n",
      " CL    |   9 |  428/ 499 |  88/83  | 78/80 | 85\n",
      " ACL   |   9 |  408/ 499 |  88/83  | 78/78 | 76\n",
      " SPCL  |   9 |  421/ 499 |  90/83  | 80/81 | 81\n",
      " SPACL |   9 |  156/ 499 |  100/96  | 94/84 | 73\n",
      "---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for cl_ratios in [[0.1, 0.2, 0.3, 0.4]]: # [0.4, 0.3, 0.2, 0.1]]:\n",
    "\n",
    "    for bol in [True, False]:\n",
    "        uniform_train = bol\n",
    "        uniform_val = bol\n",
    "        main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Plot sorted points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nqubits = 4\n",
    "# num_iters = 2000\n",
    "# time_now = \"2024-01-11 15-16-08\"\n",
    "# folder_name = f\"Results/{nqubits}q - {num_iters:} iters\"\n",
    "\n",
    "def plots_sorted_points():\n",
    "    file_name = \"NCL\"\n",
    "    data_file_name = f\"{folder_name}/{time_now} - Data - {file_name}.csv\"\n",
    "    only_train = True\n",
    "\n",
    "    # Read the saved data #####################\n",
    "    read_data = pd.read_csv(data_file_name,\n",
    "                            usecols=[\"weights\",\n",
    "                                    \"bias\",\n",
    "                                    \"j_train\",\n",
    "                                    \"j_val\",\n",
    "                                    \"pred_train\",\n",
    "                                    \"pred_val\"],\n",
    "                            converters={\"weights\":ast.literal_eval,\n",
    "                                        \"bias\":ast.literal_eval,\n",
    "                                        \"j_train\":ast.literal_eval,\n",
    "                                        \"j_val\":ast.literal_eval,\n",
    "                                        \"pred_train\":ast.literal_eval,\n",
    "                                        \"pred_val\":ast.literal_eval})\n",
    "\n",
    "\n",
    "    j_train = read_data[\"j_train\"][0]\n",
    "    j_val = read_data[\"j_val\"][0]\n",
    "\n",
    "    if only_train:\n",
    "        js = j_train\n",
    "    else:\n",
    "        js = j_train + j_val\n",
    "        \n",
    "    losses = []\n",
    "    gs_list = []\n",
    "    labels_list = []\n",
    "    for (j1, j2) in js:\n",
    "        gs_list.append(ground_state(j1, j2))\n",
    "        labels_list.append(labeling(j1, j2))\n",
    "\n",
    "\n",
    "    for run in range(num_runs):\n",
    "        \n",
    "        last_iter = len(read_data[\"weights\"][run])-1\n",
    "\n",
    "        weights = read_data[\"weights\"][run][last_iter]\n",
    "        bias = read_data[\"bias\"][run][last_iter]\n",
    "        pred_train = read_data[\"pred_train\"][run][last_iter]\n",
    "        pred_val = read_data[\"pred_val\"][run][last_iter]\n",
    "\n",
    "        if only_train:\n",
    "            preds = pred_train\n",
    "        else:\n",
    "            preds = pred_train + pred_val\n",
    "\n",
    "        # Calculate losses #####################\n",
    "        losses = jax.vmap(single_loss, in_axes=[None, None, 0, 0])(jnp.array(weights), jnp.array(bias), jnp.array(gs_list), jnp.array(labels_list)).tolist()\n",
    "\n",
    "        # Sort the points by the loss #####################\n",
    "        table = {}\n",
    "        table[\"js\"] = js\n",
    "        table[\"preds\"] = preds\n",
    "        table[\"losses\"] = losses\n",
    "\n",
    "        table = pd.DataFrame(table)\n",
    "        table.sort_values(by=[\"losses\"], inplace=True)\n",
    "\n",
    "        cv_js = np.array(list(table[\"js\"]))\n",
    "        cv_preds = np.array(list(table[\"preds\"]))\n",
    "\n",
    "        # Make the plots #####################\n",
    "\n",
    "        for i in range(11):\n",
    "            ratio_ini_points = 0\n",
    "            ratio_end_points = i/10\n",
    "\n",
    "            first_point = int(len(cv_js)*ratio_ini_points)\n",
    "            last_point = int(len(cv_js)*ratio_end_points)\n",
    "\n",
    "            j_plot = cv_js[first_point:last_point]\n",
    "            pred_plot = cv_preds[first_point:last_point]\n",
    "\n",
    "            fig, axis = plt.subplots(1,1)\n",
    "            \n",
    "            # define regions coordinates\n",
    "            x01, y01 = region01_coords[:,0], region01_coords[:,1]\n",
    "            x02, y02 = region02_coords[:,0], region02_coords[:,1]\n",
    "            x1, y1 = region1_coords[:,0], region1_coords[:,1]\n",
    "            x2, y2 = region2_coords[:,0], region2_coords[:,1]\n",
    "            x3, y3 = region3_coords[:,0], region3_coords[:,1]\n",
    "\n",
    "            # put the regions into the plot\n",
    "            axis.fill(x01, y01, facecolor='lightskyblue')    # class 0\n",
    "            axis.fill(x02, y02, facecolor='lightskyblue')    # class 0\n",
    "            axis.fill(x1, y1, facecolor='sandybrown')        # class 1\n",
    "            axis.fill(x2, y2, facecolor='salmon')            # class 2\n",
    "            axis.fill(x3, y3, facecolor='lightgreen')        # class 3\n",
    "\n",
    "            colors = [\"b\", \"orange\", \"r\", \"g\"]\n",
    "\n",
    "            # plot datapoints\n",
    "            for i in range(4):\n",
    "                axis.scatter(\n",
    "                    j_plot[:, 0][pred_plot==i],\n",
    "                    j_plot[:, 1][pred_plot==i],\n",
    "                    c=colors[i],\n",
    "                    marker=\"o\",\n",
    "                    edgecolors=\"k\",\n",
    "                    label=f\"class {i+1} train\",\n",
    "                )\n",
    "\n",
    "\n",
    "            # plt.legend()\n",
    "            axis.axis('square')\n",
    "            axis.set_title(f\"Loss sorted points for run {run}\")\n",
    "            # plt.show()\n",
    "\n",
    "        only_train_str = \"only train\" if only_train else \"all points\"\n",
    "        plots_pdf_name = f\"{folder_name}/{time_now} - Plots loss sorted run {run} - {file_name} {only_train_str}.pdf\"\n",
    "        save_multi_image(plots_pdf_name)\n",
    "        close_all_figures()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Miscellaneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(mp.cpu_count()) #256\n",
    "\n",
    "# gs = gs_train\n",
    "# lab = labels_train\n",
    "\n",
    "# for i in range(10, 120, 10):\n",
    "#     num_cpus_test = i\n",
    "#     start_time = time.time()\n",
    "#     loss(weights[0], bias[0], gs, lab, num_cpus_test)\n",
    "#     print(f\"{i} --- {(time.time() - start_time):.2f} seconds ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define regions coordinates\n",
    "x01, y01 = region01e_coords[:,0], region01e_coords[:,1]\n",
    "x02, y02 = region02e_coords[:,0], region02e_coords[:,1]\n",
    "x1, y1 = region1e_coords[:,0], region1e_coords[:,1]\n",
    "x2, y2 = region2e_coords[:,0], region2e_coords[:,1]\n",
    "x3, y3 = region3e_coords[:,0], region3e_coords[:,1]\n",
    "\n",
    "# put the regions into the plot\n",
    "plt.fill(x01, y01, facecolor='lightskyblue')    # class 0\n",
    "plt.fill(x02, y02, facecolor='lightskyblue')    # class 0\n",
    "plt.fill(x1, y1, facecolor='sandybrown')        # class 1\n",
    "plt.fill(x2, y2, facecolor='salmon')            # class 2\n",
    "plt.fill(x3, y3, facecolor='lightgreen')        # class 3\n",
    "\n",
    "plt.axis('square')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
