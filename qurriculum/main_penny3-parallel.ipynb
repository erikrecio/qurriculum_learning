{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jax.random\n",
    "import jax.numpy as jnp\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as pnp\n",
    "from pennylane.optimize import NesterovMomentumOptimizer\n",
    "from shapely.geometry import Polygon, Point\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "plt.ioff()\n",
    "\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pytz\n",
    "import ast\n",
    "from pypdf import PdfMerger\n",
    "\n",
    "import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Running parameters\n",
    "num_iters = 1000    # Number of training iterations\n",
    "num_runs = 2\n",
    "with_cv = False\n",
    "with_val = False\n",
    "\n",
    "# Circuit and optimization parameters\n",
    "nqubits = 4         # Num qubits, min 4, always 2**num_layers qubits\n",
    "with_bias = False    # Add a bias to the output of the quantum circuit\n",
    "random = True\n",
    "optimizer = \"GradientDescent\"  # \"Adam\", \"Nesterov\", \"GradientDescent\"\n",
    "loss_type = \"cross-entropy\" # \"projectors\", \"cross-entropy\"\n",
    "\n",
    "# Data hyper-parameters\n",
    "batch_size = 100     # batch training size\n",
    "train_size = 100      # Total ground states that will be used for training\n",
    "val_size = 1000      # Total gound states with training + validation\n",
    "cv_ratios = [0.3, 0.2, 0.2, 0.2, 0.1]\n",
    "\n",
    "# How the training data is generated\n",
    "uniform_train = True    # True - Uniform, False - Balanced\n",
    "epsilon_train = True   # True - epsilon, False - no epsilon\n",
    "uniform_val = True\n",
    "epsilon_val = False\n",
    "\n",
    "# Multiprocess hyperparameters. recommended: (num_data, num_cpus) -> (20, 10), (100, 20-30), (200, 40-50) (1000, 50-70)\n",
    "num_cpus_batch = 0 # 20\n",
    "num_cpus_train = 0 # 20\n",
    "num_cpus_val = 0 # 60\n",
    "\n",
    "# Tweak training hyper-parameters\n",
    "max_weight_init = 2*np.pi  # weight_init goes from 0 to this number. Max = 2*np.pi. Other options = 0.01\n",
    "stepsize = 0.01         # stepsize of the gradient descent.\n",
    "\n",
    "# Constant definitions\n",
    "layers = int(np.log2(nqubits))\n",
    "nweights = 30*(layers-1) + 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def X(i):\n",
    "    return qml.PauliX(i)\n",
    "\n",
    "def Z(i):\n",
    "    return qml.PauliZ(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Gound states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ground_state(j1, j2):\n",
    "    \n",
    "    hamiltonian = 0\n",
    "    for i in range(nqubits):\n",
    "        hamiltonian += Z(i)\n",
    "        hamiltonian -= j1 * X(i) @ X((i+1)%nqubits)\n",
    "        hamiltonian -= j2 * X((i-1)%nqubits) @ Z(i) @ X((i+1)%nqubits)\n",
    "    \n",
    "    _, eigvecs = np.linalg.eigh(qml.matrix(hamiltonian))\n",
    "    \n",
    "    return eigvecs[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define coordinates of the points of each region# Definir las coordenadas de los puntos de cada regi√≥n\n",
    "region01_coords = np.array([(-2, 1), (2, 1), (4, 3), (4, 4), (-4, 4), (-4, 3)])    # Class 0\n",
    "region02_coords = np.array([(-3, -4), (0, -1), (3, -4)])                           # Class 0\n",
    "region1_coords = np.array([(0, -1), (3, -4), (4, -4), (4, 3)])                     # Class 1\n",
    "region2_coords = np.array([(0, -1), (-3, -4), (-4, -4), (-4, 3)])                  # Class 2\n",
    "region3_coords = np.array([(-2, 1), (2, 1), (0, -1)])                              # Class 3\n",
    "\n",
    "e = 0.1\n",
    "# Define coordinates of the points of each region far from the borders\n",
    "region01e_coords = np.array([(-2+(np.sqrt(2)-1)*e, 1+e), (2-(np.sqrt(2)-1)*e, 1+e), (4, 3+np.sqrt(2)*e), (4, 4), (-4, 4), (-4, 3+np.sqrt(2)*e)])    # Class 0 with epsilon\n",
    "region02e_coords = np.array([(-3+np.sqrt(2)*e, -4), (0, -1-np.sqrt(2)*e), (3-np.sqrt(2)*e, -4)])                                                    # Class 0 with epsilon\n",
    "region1e_coords = np.array([(0+np.sqrt(2)*e, -1), (3+np.sqrt(2)*e, -4), (4, -4), (4, 3-np.sqrt(2)*e)])                                              # Class 1 with epsilon\n",
    "region2e_coords = np.array([(0-np.sqrt(2)*e, -1), (-3-np.sqrt(2)*e, -4), (-4, -4), (-4, 3-np.sqrt(2)*e)])                                           # Class 2 with epsilon\n",
    "region3e_coords = np.array([(-2+e/np.tan(np.pi/8), 1-e), (2-e/np.tan(np.pi/8), 1-e), (0, -1+np.sqrt(2)*e)])                                         # Class 3 with epsilon\n",
    "\n",
    "\n",
    "def labeling(x, y):\n",
    "\n",
    "    # Create Polygons for each region\n",
    "    region01_poly = Polygon(region01_coords)\n",
    "    region02_poly = Polygon(region02_coords)\n",
    "    region1_poly = Polygon(region1_coords)\n",
    "    region2_poly = Polygon(region2_coords)\n",
    "    region3_poly = Polygon(region3_coords)\n",
    "    \n",
    "    p = Point(x, y)\n",
    "    if region01_poly.contains(p):\n",
    "        return 0\n",
    "    elif region02_poly.contains(p):\n",
    "        return 0\n",
    "    elif region1_poly.contains(p):\n",
    "        return 1\n",
    "    elif region2_poly.contains(p):\n",
    "        return 2\n",
    "    elif region3_poly.contains(p):\n",
    "        return 3\n",
    "    else:\n",
    "        return None # if the point is not in any region\n",
    "    \n",
    "\n",
    "def labeling_epsilon(x, y):\n",
    "    \n",
    "    # Create Polygons for each region\n",
    "    region01e_poly = Polygon(region01e_coords)\n",
    "    region02e_poly = Polygon(region02e_coords)\n",
    "    region1e_poly = Polygon(region1e_coords)\n",
    "    region2e_poly = Polygon(region2e_coords)\n",
    "    region3e_poly = Polygon(region3e_coords)\n",
    "    \n",
    "    \n",
    "    p = Point(x, y)\n",
    "    if region01e_poly.contains(p):\n",
    "        return 0\n",
    "    elif region02e_poly.contains(p):\n",
    "        return 0\n",
    "    elif region1e_poly.contains(p):\n",
    "        return 1\n",
    "    elif region2e_poly.contains(p):\n",
    "        return 2\n",
    "    elif region3e_poly.contains(p):\n",
    "        return 3\n",
    "    else:\n",
    "        return None # if the point is not in any region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate ground states\n",
    "def generate_gs(num_points, uniform, epsilon, num_cpus):\n",
    "\n",
    "    if random:\n",
    "        rng = np.random\n",
    "    else:\n",
    "        rng = np.random.RandomState(0)\n",
    "        \n",
    "\n",
    "    if uniform:\n",
    "        if epsilon:\n",
    "            j_list = []\n",
    "            num = 0\n",
    "            while num < num_points:\n",
    "                j = rng.uniform(-4, 4, 2)\n",
    "                l = labeling_epsilon(j[0], j[1])\n",
    "\n",
    "                if l in [0,1,2,3]:\n",
    "                    num += 1\n",
    "                    j_list.append(j)\n",
    "\n",
    "            j_list = np.array(j_list)\n",
    "            \n",
    "        else:\n",
    "            j_list = rng.uniform(-4, 4, (num_points,2))\n",
    "    \n",
    "    \n",
    "    else: # Then it's balanced\n",
    "        npoints_class = num_points//4\n",
    "        num_points = 4*npoints_class\n",
    "        \n",
    "        npoints_02 = npoints_class//2\n",
    "        npoints_01 = npoints_class - npoints_02\n",
    "        \n",
    "        j_list = []\n",
    "        num_0, num_1, num_2, num_3 = 0, 0, 0, 0\n",
    "        num_01, num_02 = 0, 0\n",
    "        \n",
    "        while num_0 != npoints_class or num_1 != npoints_class or num_2 != npoints_class or num_3 != npoints_class:\n",
    "            j = rng.uniform(-4, 4, 2)\n",
    "            l = labeling_epsilon(j[0], j[1]) if epsilon else labeling(j[0], j[1])\n",
    "\n",
    "            if l==0 and num_0 < npoints_class:\n",
    "                \n",
    "                p = Point(j[0], j[1])\n",
    "                if Polygon(region01_coords).contains(p) and num_01 < npoints_01:\n",
    "                    num_01 += 1\n",
    "                    num_0 += 1\n",
    "                    j_list.append(j)\n",
    "                elif Polygon(region02_coords).contains(p) and num_02 < npoints_02:\n",
    "                    num_02 += 1\n",
    "                    num_0 += 1\n",
    "                    j_list.append(j)\n",
    "                \n",
    "            elif l==1 and num_1 < npoints_class:\n",
    "                num_1 += 1\n",
    "                j_list.append(j)\n",
    "            elif l==2 and num_2 < npoints_class:\n",
    "                num_2 += 1\n",
    "                j_list.append(j)\n",
    "            elif l==3 and num_3 < npoints_class:\n",
    "                num_3 += 1\n",
    "                j_list.append(j)\n",
    "\n",
    "        j_list = np.array(j_list)\n",
    "    \n",
    "    \n",
    "    if num_cpus == 0:\n",
    "        gs_list = []\n",
    "        labels_list = []\n",
    "\n",
    "        for i in range(num_points):\n",
    "            gs_list.append(ground_state(j_list[i,0], j_list[i,1]))\n",
    "            labels_list.append(labeling(j_list[i,0], j_list[i,1]))\n",
    "            \n",
    "    else:\n",
    "        args = [[j_list[i,0], j_list[i,1]] for i in range(num_points)]\n",
    "        \n",
    "        with mp.Pool(num_cpus) as pool:\n",
    "            gs_list = pool.starmap(ground_state, args)\n",
    "        \n",
    "        with mp.Pool(num_cpus) as pool:\n",
    "            labels_list = pool.starmap(labeling, args)\n",
    "            \n",
    "        \n",
    "    gs_list = np.array(gs_list)\n",
    "    labels_list = np.array(labels_list)\n",
    "\n",
    "    return gs_list, labels_list, j_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convolutional_layer(q1, q2, weights):\n",
    "    qml.U3(wires=q1, theta=weights[0], phi=weights[1], delta=weights[2])\n",
    "    qml.U3(wires=q1, theta=weights[3], phi=weights[4], delta=weights[5])\n",
    "    qml.CNOT(wires=[q2, q1])\n",
    "    qml.RZ(wires=q1, phi=weights[6])\n",
    "    qml.RY(wires=q2, phi=weights[7])\n",
    "    qml.CNOT(wires=[q1, q2])\n",
    "    qml.RY(wires=q2, phi=weights[8])\n",
    "    qml.CNOT(wires=[q2, q1])\n",
    "    qml.U3(wires=q1, theta=weights[9], phi=weights[10], delta=weights[11])\n",
    "    qml.U3(wires=q1, theta=weights[12], phi=weights[13], delta=weights[14])\n",
    "\n",
    "def pooling_layer(q1, q2, weights):\n",
    "    qml.U3(wires=q1, theta=weights[0], phi=weights[1], delta=weights[2])\n",
    "    qml.U3(wires=q1, theta=weights[3], phi=weights[4], delta=weights[5])\n",
    "    qml.CNOT(wires=[q2, q1])\n",
    "    qml.RZ(wires=q1, phi=weights[6])\n",
    "    qml.RY(wires=q2, phi=weights[7])\n",
    "    qml.CNOT(wires=[q1, q2])\n",
    "    qml.RY(wires=q2, phi=weights[8])\n",
    "    qml.CNOT(wires=[q2, q1])\n",
    "    qml.U3(wires=q1, theta=weights[9], phi=weights[10], delta=weights[11])\n",
    "    qml.U3(wires=q1, theta=weights[12], phi=weights[13], delta=weights[14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_circuit(weights, state_ini):\n",
    "    \n",
    "    qubits = list(range(nqubits))\n",
    "    \n",
    "    qml.QubitStateVector(state_ini, wires=qubits)\n",
    "\n",
    "    for j in range(layers-1):\n",
    "        \n",
    "        len_qubits = len(qubits)\n",
    "        \n",
    "        for i in range(len_qubits//2):\n",
    "            convolutional_layer(qubits[2*i], qubits[(2*i+1)%len_qubits], weights[15*2*j:15*(2*j+1)])\n",
    "        \n",
    "        for i in range(len_qubits//2):\n",
    "            convolutional_layer(qubits[2*i+1], qubits[(2*i+2)%len_qubits], weights[15*2*j:15*(2*j+1)])\n",
    "            \n",
    "        for i in range(len_qubits//2):\n",
    "            pooling_layer(qubits[2*i], qubits[(2*i+1)%len_qubits], weights[15*(2*j+1):15*(2*j+2)])\n",
    "\n",
    "        qub = []\n",
    "        for i in range(len_qubits):\n",
    "            if i%2 == 1:\n",
    "                qub.append(qubits[i])\n",
    "                \n",
    "        qubits = qub\n",
    "    \n",
    "    convolutional_layer(qubits[0], qubits[1], weights[15*(2*layers-2):15*(2*layers-1)])\n",
    "    \n",
    "    return qml.expval(Z(qubits[0])), qml.expval(Z(qubits[1])), qml.expval(Z(qubits[0]) @ Z(qubits[1]))\n",
    "\n",
    "# dev_draw = qml.device(\"qiskit.aer\", wires=nqubits)\n",
    "dev = qml.device(\"default.qubit\", wires=nqubits)\n",
    "\n",
    "# cnn_draw = qml.QNode(cnn_circuit, dev_draw)\n",
    "cnn_circuit = qml.QNode(cnn_circuit, dev, interface=\"jax\", diff_method=\"best\")\n",
    "\n",
    "\n",
    "def cnn(weights, state_ini):\n",
    "    z0, z1, zz01 = cnn_circuit(weights, state_ini)\n",
    "\n",
    "    proj_00 = (1+zz01+z0+z1)/4\n",
    "    proj_01 = (1-zz01-z0+z1)/4\n",
    "    proj_10 = (1-zz01+z0-z1)/4\n",
    "    proj_11 = (1+zz01-z0-z1)/4\n",
    "\n",
    "    return jnp.array([proj_00, proj_01, proj_10, proj_11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def variational_classifier(weights, bias, state_ini):\n",
    "    return cnn(weights, state_ini) + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# draw circuit\n",
    "\n",
    "# weights = np.random.uniform(0, 2*np.pi, nweights)\n",
    "# drawer = qml.draw(cnn_circuit)\n",
    "# print(drawer(weights, gs_list[0]))\n",
    "\n",
    "# z0, z1, zz01 = cnn_draw(gs_list[0], weights)\n",
    "# print(z0, z1, zz01)\n",
    "# dev_draw._circuit.draw(output=\"mpl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def single_loss(weights, bias, ground_state, label):\n",
    "    \n",
    "    proj = variational_classifier(weights, bias, ground_state)\n",
    "\n",
    "    if loss_type == \"projectors\":\n",
    "        cost = proj[label]\n",
    "\n",
    "    elif loss_type == \"cross-entropy\":\n",
    "        cost = -jnp.log2(proj[label])\n",
    "    \n",
    "    return cost\n",
    "\n",
    "@jax.jit\n",
    "def loss(weights, bias, ground_states, labels):\n",
    "    costs = jax.vmap(single_loss, in_axes=[None, None, 0, 0])(weights, bias, ground_states, labels)\n",
    "    return costs.sum()/len(labels)\n",
    "\n",
    "@jax.jit\n",
    "def grad_loss(weight, bias, ground_states, labels):\n",
    "    w, b = jax.grad(loss, argnums=[0,1])(weight, bias, ground_states, labels)\n",
    "    return w, b, jnp.zeros(ground_states.shape), jnp.zeros(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Array([ 1.00091829e+00,  1.05881314e-02, -4.20941511e-02,  9.06440638e-01,\n",
      "       -4.40121759e-02,  1.05881314e-02,  2.40863412e-01, -1.36502648e-01,\n",
      "        1.95232633e-02, -5.36693304e-01,  5.77991295e-01, -6.46955518e-02,\n",
      "        7.59678800e-01,  2.03723008e-01,  5.77991295e-01, -2.99958407e-01,\n",
      "       -3.75972443e-01, -2.12357873e-01,  1.99114055e-01, -5.95622102e-02,\n",
      "       -3.75972443e-01,  1.73635813e-02, -1.85208505e-01,  5.06984733e-01,\n",
      "       -2.08166817e-17, -8.32667268e-17, -4.16333634e-17,  5.55111512e-17,\n",
      "        8.32667268e-17, -7.28583860e-17, -5.10505298e-02, -9.28526993e-02,\n",
      "       -1.81228075e-01, -6.35373445e-02,  1.58865880e-01, -9.28526993e-02,\n",
      "       -8.57710276e-02,  3.42536615e-01,  2.58595285e-01,  1.58146362e-01,\n",
      "        4.51057015e-02,  3.93295539e-02,  1.73568398e-01, -9.71445147e-17,\n",
      "        4.51057015e-02], dtype=float64), Array([-3.00103833, -1.65092106, -1.63243877, -0.25768692], dtype=float64), Array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float64), Array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],      dtype=float64))\n"
     ]
    }
   ],
   "source": [
    "gs_train, labels_train, j_train = generate_gs(train_size, uniform_train, epsilon_train, num_cpus_train)\n",
    "key = jax.random.PRNGKey(0)\n",
    "weights_init = jax.random.uniform(key, [nweights], minval=0, maxval=max_weight_init)\n",
    "bias_init = jnp.array([0.0]*4)\n",
    "\n",
    "print(grad_loss(weights_init, bias_init, gs_train, labels_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def single_pred(weights, bias, ground_state):\n",
    "    \n",
    "    projectors = variational_classifier(weights, bias, ground_state)\n",
    "    \n",
    "    if loss_type == \"projectors\":\n",
    "        pred = np.argmin(projectors)\n",
    "    elif loss_type == \"cross-entropy\":\n",
    "        pred = np.argmax(projectors)\n",
    "\n",
    "    return pred\n",
    "\n",
    "@jax.jit\n",
    "def pred(weights, bias, ground_states):\n",
    "    predictions = jax.vmap(single_pred, in_axes=[None, None, 0])(weights, bias, ground_states)\n",
    "    return predictions\n",
    "\n",
    "@jax.jit\n",
    "def acc(predictions, labels):\n",
    "    return sum(predictions==labels)*100/len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_multi_image(filename):\n",
    "    pp = PdfPages(filename)\n",
    "    fig_nums = plt.get_fignums()\n",
    "    figs = [plt.figure(n) for n in fig_nums]\n",
    "    for fig in figs:\n",
    "        fig.savefig(pp, format='pdf')\n",
    "    pp.close()\n",
    "\n",
    "def close_all_figures():\n",
    "    fig_nums = plt.get_fignums()\n",
    "    for n in fig_nums:\n",
    "        plt.figure(n)\n",
    "        plt.close()\n",
    "\n",
    "        \n",
    "def save_plots(time_now,\n",
    "               folder_name,\n",
    "               file_name,\n",
    "               plot_run,\n",
    "               it_max,\n",
    "               acc_train,\n",
    "               acc_val,\n",
    "               losses,\n",
    "               pred_train,\n",
    "               pred_val,\n",
    "               j_train,\n",
    "               j_val\n",
    "              ):\n",
    "\n",
    "\n",
    "    fig, axis = plt.subplots(1,3)\n",
    "    fig.set_figheight(6.5)\n",
    "    fig.set_figwidth(20)\n",
    "    fig.tight_layout(pad=2, w_pad=3.5)\n",
    "\n",
    "    # ---------------------------------------------------------------------- #\n",
    "    # -------------------- Loss and accuracy figure ------------------------ #\n",
    "    # ---------------------------------------------------------------------- #\n",
    "\n",
    "    iterations = range(1, num_iters+1)\n",
    "\n",
    "    color1 = 'darkred'\n",
    "    axis[0].set_xlabel('Iterations')\n",
    "    axis[0].set_ylabel('Accuracy %', color=color1)\n",
    "    axis[0].plot(iterations, acc_train, label=\"Training\", color=color1)\n",
    "    axis[0].plot(iterations, acc_val, '-.', label=\"Validation\", color=color1)\n",
    "    axis[0].tick_params(axis='y', labelcolor=color1)\n",
    "    axis[0].set_ylim(0,100)\n",
    "\n",
    "    ax2 = axis[0].twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "    color2 = 'darkblue'\n",
    "    ax2.set_ylabel('Loss', color=color2)  # we already handled the x-label with axis[0]\n",
    "    ax2.plot(iterations, losses, label=\"Loss\", color=color2)\n",
    "    ax2.tick_params(axis='y', labelcolor=color2)\n",
    "    # ax2.set_ylim(bottom=0)\n",
    "\n",
    "    # fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "    # plt.legend()\n",
    "    axis[0].set_title(f\"Accuracy and Loss - Run {plot_run}\")\n",
    "\n",
    "\n",
    "    # ---------------------------------------------------------------------- #\n",
    "    # ---------------------------- Max iter -------------------------------- #\n",
    "    # ---------------------------------------------------------------------- #\n",
    "\n",
    "    plot_iter = it_max\n",
    "\n",
    "    # define regions coordinates\n",
    "    x01, y01 = region01_coords[:,0], region01_coords[:,1]\n",
    "    x02, y02 = region02_coords[:,0], region02_coords[:,1]\n",
    "    x1, y1 = region1_coords[:,0], region1_coords[:,1]\n",
    "    x2, y2 = region2_coords[:,0], region2_coords[:,1]\n",
    "    x3, y3 = region3_coords[:,0], region3_coords[:,1]\n",
    "\n",
    "    # put the regions into the plot\n",
    "    axis[1].fill(x01, y01, facecolor='lightskyblue')    # class 0\n",
    "    axis[1].fill(x02, y02, facecolor='lightskyblue')    # class 0\n",
    "    axis[1].fill(x1, y1, facecolor='sandybrown')        # class 1\n",
    "    axis[1].fill(x2, y2, facecolor='salmon')            # class 2\n",
    "    axis[1].fill(x3, y3, facecolor='lightgreen')        # class 3\n",
    "\n",
    "    pred_train_plot = np.array(pred_train[plot_iter])\n",
    "    pred_val_plot = np.array(pred_val[plot_iter])\n",
    "\n",
    "    colors = [\"b\", \"orange\", \"r\", \"g\"]\n",
    "\n",
    "    # plot datapoints\n",
    "    for i in range(4):\n",
    "        axis[1].scatter(\n",
    "            j_train[:, 0][pred_train_plot==i],\n",
    "            j_train[:, 1][pred_train_plot==i],\n",
    "            c=colors[i],\n",
    "            marker=\"o\",\n",
    "            edgecolors=\"k\",\n",
    "            label=f\"class {i+1} train\",\n",
    "        )\n",
    "        if with_val:\n",
    "            axis[1].scatter(\n",
    "                j_val[:, 0][pred_val_plot==i],\n",
    "                j_val[:, 1][pred_val_plot==i],\n",
    "                c=colors[i],\n",
    "                marker=\"^\",\n",
    "                edgecolors=\"k\",\n",
    "                label=f\"class {i+1} validation\",\n",
    "            )\n",
    "\n",
    "\n",
    "    # plt.legend()\n",
    "    axis[1].set_title(f\"Max iteration ({acc_train[plot_iter]:.0f}%/{acc_val[plot_iter]:.0f}%)\")\n",
    "\n",
    "\n",
    "    # ---------------------------------------------------------------------- #\n",
    "    # ---------------------------- Last iter ------------------------------- #\n",
    "    # ---------------------------------------------------------------------- #\n",
    "\n",
    "\n",
    "    plot_iter = num_iters-1\n",
    "\n",
    "    # define regions coordinates\n",
    "    x01, y01 = region01_coords[:,0], region01_coords[:,1]\n",
    "    x02, y02 = region02_coords[:,0], region02_coords[:,1]\n",
    "    x1, y1 = region1_coords[:,0], region1_coords[:,1]\n",
    "    x2, y2 = region2_coords[:,0], region2_coords[:,1]\n",
    "    x3, y3 = region3_coords[:,0], region3_coords[:,1]\n",
    "\n",
    "    # put the regions into the plot\n",
    "    axis[2].fill(x01, y01, facecolor='lightskyblue')    # class 0\n",
    "    axis[2].fill(x02, y02, facecolor='lightskyblue')    # class 0\n",
    "    axis[2].fill(x1, y1, facecolor='sandybrown')        # class 1\n",
    "    axis[2].fill(x2, y2, facecolor='salmon')            # class 2\n",
    "    axis[2].fill(x3, y3, facecolor='lightgreen')        # class 3\n",
    "\n",
    "    pred_train_plot = np.array(pred_train[plot_iter])\n",
    "    pred_val_plot = np.array(pred_val[plot_iter])\n",
    "\n",
    "    colors = [\"b\", \"orange\", \"r\", \"g\"]\n",
    "\n",
    "    # plot datapoints\n",
    "    for i in range(4):\n",
    "        axis[2].scatter(\n",
    "            j_train[:, 0][pred_train_plot==i],\n",
    "            j_train[:, 1][pred_train_plot==i],\n",
    "            c=colors[i],\n",
    "            marker=\"o\",\n",
    "            edgecolors=\"k\",\n",
    "            label=f\"class {i+1} train\",\n",
    "        )\n",
    "        if with_val:\n",
    "            axis[2].scatter(\n",
    "                j_val[:, 0][pred_val_plot==i],\n",
    "                j_val[:, 1][pred_val_plot==i],\n",
    "                c=colors[i],\n",
    "                marker=\"^\",\n",
    "                edgecolors=\"k\",\n",
    "                label=f\"class {i+1} validation\",\n",
    "            )\n",
    "\n",
    "\n",
    "    # plt.legend()\n",
    "    axis[2].set_title(f\"Last iteration ({acc_train[plot_iter]:.0f}%/{acc_val[plot_iter]:.0f}%)\")\n",
    "\n",
    "    # ---------------------------------------------------------------------- #\n",
    "    # --------------------------- Save plots ------------------------------- #\n",
    "    # ---------------------------------------------------------------------- #\n",
    "\n",
    "    plots_pdf_name = f\"{folder_name}/{time_now} - Plots - {file_name}.pdf\"\n",
    "    \n",
    "    \n",
    "    # If the file doesn't exist we save it. If it does, we merge it.\n",
    "    if not os.path.isfile(plots_pdf_name):\n",
    "        save_multi_image(plots_pdf_name)\n",
    "    \n",
    "    else:\n",
    "        save_multi_image(plots_pdf_name + \"2\")\n",
    "        # Merge the new plot with the rest and delete the last file\n",
    "        merger = PdfMerger()\n",
    "        merger.append(plots_pdf_name)\n",
    "        merger.append(plots_pdf_name + \"2\")\n",
    "        merger.write(plots_pdf_name)\n",
    "        merger.close()\n",
    "        os.remove(plots_pdf_name + \"2\")\n",
    "    \n",
    "    close_all_figures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_hyperparameters(time_now, folder_name, file_name):\n",
    "    \n",
    "    # --------------- Hyperparameters -----------------#\n",
    "    hyperparameters = {}\n",
    "    hyperparameters[\"num_iters\"] = [num_iters]\n",
    "    hyperparameters[\"num_runs\"] = [num_runs]\n",
    "    hyperparameters[\"with_cv\"] = [with_cv]\n",
    "    hyperparameters[\"with_val\"] = [with_val]\n",
    "    hyperparameters[\"nqubits\"] = [nqubits]\n",
    "    hyperparameters[\"with_bias\"] = [with_bias]\n",
    "    hyperparameters[\"random\"] = [random]\n",
    "    hyperparameters[\"optimizer\"] = [optimizer]\n",
    "    hyperparameters[\"loss_type\"] = [loss_type]\n",
    "    hyperparameters[\"batch_size\"] = [batch_size]\n",
    "    hyperparameters[\"train_size\"] = [train_size]\n",
    "    hyperparameters[\"val_size\"] = [val_size]\n",
    "    hyperparameters[\"cv_ratios\"] = [cv_ratios]\n",
    "    hyperparameters[\"uniform_train\"] = [uniform_train]\n",
    "    hyperparameters[\"epsilon_train\"] = [epsilon_train]\n",
    "    hyperparameters[\"uniform_val\"] = [uniform_val]\n",
    "    hyperparameters[\"epsilon_val\"] = [epsilon_val]\n",
    "    hyperparameters[\"num_cpus_batch\"] = [num_cpus_batch]\n",
    "    hyperparameters[\"num_cpus_train\"] = [num_cpus_train]\n",
    "    hyperparameters[\"num_cpus_val\"] = [num_cpus_val]\n",
    "    hyperparameters[\"max_weight_init\"] = [max_weight_init]\n",
    "    hyperparameters[\"stepsize\"] = [stepsize]\n",
    "\n",
    "    hyperparameters = pd.DataFrame(hyperparameters)\n",
    "\n",
    "    hyperparameters_file_name = f\"{folder_name}/{time_now} - Hyperparameters{file_name}.csv\"\n",
    "    hyperparameters.to_csv(hyperparameters_file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(time_now,\n",
    "                folder_name,\n",
    "                run,\n",
    "                weights,\n",
    "                bias,\n",
    "                losses,\n",
    "                j_train,\n",
    "                j_val,\n",
    "                pred_train,\n",
    "                pred_val,\n",
    "                acc_train,\n",
    "                acc_val,\n",
    "                run_time,\n",
    "                cv\n",
    "               ):\n",
    "    \n",
    "    if cv:\n",
    "        file_name = f\"CV\"# - {train_size} Train - {val_size} Val\"\n",
    "    else:\n",
    "        file_name = f\"NCV\"# - {train_size} Train - {val_size} Val\"\n",
    "        \n",
    "    # -------------------- Total Data -------------------- #\n",
    "    data = {}\n",
    "    data[\"run\"] = run\n",
    "    \n",
    "    it_max = np.argmax(np.array(acc_train))\n",
    "    acc_train_max = acc_train[it_max]\n",
    "    acc_train_last = acc_train[num_iters-1]\n",
    "    acc_val_max = acc_val[it_max]\n",
    "    acc_val_last = acc_val[num_iters-1]\n",
    "    \n",
    "    data[\"it_max\"] = it_max\n",
    "    data[\"acc_train_max\"] = acc_train_max\n",
    "    data[\"acc_train_last\"] = acc_train_last\n",
    "    data[\"acc_val_max\"] = acc_val_max\n",
    "    data[\"acc_val_last\"] = acc_val_last\n",
    "    data[\"run_time\"] = run_time\n",
    "    \n",
    "    data[\"weights\"] = [weights]\n",
    "    data[\"bias\"] = [bias]\n",
    "    data[\"losses\"] = [losses]\n",
    "    data[\"j_train\"] = [j_train]\n",
    "    data[\"j_val\"] = [j_val]\n",
    "    data[\"pred_train\"] = [pred_train]\n",
    "    data[\"pred_val\"] = [pred_val]\n",
    "    data[\"acc_train\"] = [acc_train]\n",
    "    data[\"acc_val\"] = [acc_val]\n",
    "    \n",
    "\n",
    "    data = pd.DataFrame(data)\n",
    "    \n",
    "    data_file_name = f\"{folder_name}/{time_now} - Data - {file_name}.csv\"\n",
    "    data.to_csv(data_file_name, mode='a', index=False, header=not os.path.exists(data_file_name))\n",
    "    \n",
    "    \n",
    "    # ------------------- Results ------------------- #\n",
    "    \n",
    "    read_data = pd.read_csv(data_file_name,\n",
    "                     usecols=[\"it_max\",\n",
    "                              \"acc_train_max\",\n",
    "                              \"acc_val_max\",\n",
    "                              \"acc_train\",\n",
    "                              \"acc_val\"],\n",
    "                     converters={\"acc_train\":ast.literal_eval,\n",
    "                                 \"acc_val\":ast.literal_eval})\n",
    "    \n",
    "    total_it_max = read_data[\"it_max\"]\n",
    "    total_acc_train_max = read_data[\"acc_train_max\"]\n",
    "    total_acc_val_max = read_data[\"acc_val_max\"]\n",
    "    total_acc_train = read_data[\"acc_train\"].tolist()\n",
    "    total_acc_val = read_data[\"acc_val\"].tolist()\n",
    "    \n",
    "    best_run_max = total_acc_train_max.argmax()\n",
    "    best_it_max = total_it_max[best_run_max]\n",
    "    avg_acc_train_max = total_acc_train_max.mean()\n",
    "    avg_acc_val_max = total_acc_val_max.mean()\n",
    "    \n",
    "    best_run_last = np.argmax(np.array(total_acc_train)[:,num_iters-1])\n",
    "    avg_acc_train_last = np.mean(np.array(total_acc_train)[:,num_iters-1])\n",
    "    avg_acc_val_last = np.mean(np.array(total_acc_val)[:,num_iters-1])\n",
    "\n",
    "    \n",
    "    results = {}\n",
    "    results[\"num_runs\"] = [run+1]\n",
    "    results[\"best_run_max\"] = [best_run_max]\n",
    "    results[\"best_run_last\"] = [best_run_last]\n",
    "    results[\"best_it_max\"] = [best_it_max]\n",
    "    results[\"best_it_last\"] = [num_iters-1]\n",
    "    results[\"best_acc_train_max\"] = [total_acc_train[best_run_max][best_it_max]]\n",
    "    results[\"best_acc_train_last\"] = [total_acc_train[best_run_max][num_iters-1]]\n",
    "    results[\"best_acc_val_max\"] = [total_acc_val[best_run_max][best_it_max]]\n",
    "    results[\"best_acc_val_last\"] = [total_acc_val[best_run_max][num_iters-1]]\n",
    "    results[\"avg_acc_train_max\"] = [avg_acc_train_max]\n",
    "    results[\"avg_acc_train_last\"] = [avg_acc_train_last]\n",
    "    results[\"avg_acc_val_max\"] = [avg_acc_val_max]\n",
    "    results[\"avg_acc_val_last\"] = [avg_acc_val_last]\n",
    "\n",
    "    results = pd.DataFrame(results)\n",
    "\n",
    "    results_file_name = f\"{folder_name}/{time_now} - Results - {file_name}.csv\"\n",
    "    results.to_csv(results_file_name, index=False)\n",
    "    \n",
    "    \n",
    "    # ------------------- Plots ------------------- #\n",
    "    save_plots(time_now,\n",
    "               folder_name,\n",
    "               file_name,\n",
    "               run,\n",
    "               it_max,\n",
    "               acc_train,\n",
    "               acc_val,\n",
    "               losses,\n",
    "               pred_train,\n",
    "               pred_val,\n",
    "               j_train,\n",
    "               j_val\n",
    "              )\n",
    "    \n",
    "    if cv:\n",
    "        cv_str = \"True \"\n",
    "    else:\n",
    "        cv_str = \"False\"\n",
    "        \n",
    "    print(\n",
    "        f\" {cv_str} |\"\n",
    "        f\" {run:3d} |\"\n",
    "        f\" {it_max:4d}/{num_iters-1:4d} |\"\n",
    "        f\"  {acc_train[it_max]:0.0f}/{acc_train[num_iters-1]:0.0f}  |\"\n",
    "        f\" {acc_val[it_max]:0.0f}/{acc_val[num_iters-1]:0.0f} |\"\n",
    "        f\" {run_time:0.0f}\"\n",
    "    )\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_qcnn(gs_train, gs_val, labels_train, labels_val, cv):\n",
    "        \n",
    "    if random:\n",
    "        rng = np.random\n",
    "    else:\n",
    "        rng = np.random.RandomState(0)\n",
    "        \n",
    "    # weights and bias initialization\n",
    "    weights_init = pnp.random.uniform(0, max_weight_init, nweights, requires_grad=True)\n",
    "    # key = jax.random.PRNGKey(0)\n",
    "    # weights_init = jax.random.uniform(key, [nweights], minval=0, maxval=max_weight_init)\n",
    "    \n",
    "    bias_init = pnp.array([0.0]*4, requires_grad=True)\n",
    "\n",
    "    # choose variational classifier\n",
    "    if optimizer == \"Nesterov\":\n",
    "        opt = NesterovMomentumOptimizer(stepsize)\n",
    "    elif optimizer == \"Adam\":\n",
    "        opt = qml.AdamOptimizer(stepsize=stepsize, beta1=0.9, beta2=0.99, eps=1e-08)\n",
    "    elif optimizer == \"GradientDescent\":\n",
    "        opt = qml.GradientDescentOptimizer(stepsize)\n",
    "\n",
    "    #Initiaize variables\n",
    "    weights = []\n",
    "    bias = []\n",
    "    losses = []\n",
    "    pred_train_arr = []\n",
    "    pred_val_arr = []\n",
    "    acc_train_arr = []\n",
    "    acc_val_arr = []\n",
    "\n",
    "    w = weights_init\n",
    "    b = bias_init\n",
    "    \n",
    "    for it in range(num_iters):\n",
    "        \n",
    "        if cv:\n",
    "            cv_size_batches, cv_limits_it = [], []\n",
    "            limit_iter, size_batch = 0, 0\n",
    "            \n",
    "            for i, ratio in enumerate(cv_ratios):\n",
    "                \n",
    "                if i < len(cv_ratios)-1:\n",
    "                    limit_iter += round(ratio*num_iters)\n",
    "                    size_batch += round(ratio*len(labels_train))\n",
    "                else:\n",
    "                    limit_iter = num_iters\n",
    "                    size_batch = len(labels_train)\n",
    "                \n",
    "                cv_limits_it.append(limit_iter)\n",
    "                cv_size_batches.append(size_batch)\n",
    "            \n",
    "            index_size_batch = np.argmax(it < np.array(cv_limits_it)) # This gives you the first occurrence where the condition is met\n",
    "            cv_size_batch = cv_size_batches[index_size_batch]\n",
    "            \n",
    "            gs_train_batch = gs_train[:cv_size_batch]\n",
    "            labels_train_batch = labels_train[:cv_size_batch]\n",
    "        \n",
    "        else:\n",
    "            batch_index = np.random.default_rng().choice(len(labels_train), size=batch_size, replace=False)\n",
    "            \n",
    "            gs_train_batch = gs_train[batch_index]\n",
    "            labels_train_batch = labels_train[batch_index]\n",
    "\n",
    "            \n",
    "        # Update the weights by one optimizer step\n",
    "        w, b, _, _ = opt.step(loss, w, b, gs_train_batch, labels_train_batch, grad_fn=grad_loss)\n",
    "        \n",
    "        weights.append(w)\n",
    "        bias.append(b)\n",
    "\n",
    "        # Compute predictions and accuracy on train and validation set\n",
    "        pred_train = pred(w, b, gs_train)\n",
    "        if with_val:\n",
    "            pred_val = pred(w, b, gs_val) if len(labels_val) > 0 else None\n",
    "        else:\n",
    "            pred_val = np.array([0]*len(labels_val))\n",
    "        \n",
    "        acc_train = acc(pred_train, labels_train)\n",
    "        if with_val:\n",
    "            acc_val = acc(pred_val, labels_val) if len(labels_val) > 0 else 0\n",
    "        else:\n",
    "            acc_val = 0\n",
    "        \n",
    "        \n",
    "        # Save prediction for later plotting\n",
    "        pred_train_arr.append(np.array(pred_train))\n",
    "        pred_val_arr.append(np.array(pred_val))\n",
    "        acc_train_arr.append(float(acc_train))\n",
    "        acc_val_arr.append(float(acc_val))\n",
    "\n",
    "        l = loss(w, b, gs_train, labels_train)\n",
    "        losses.append(l)\n",
    "    \n",
    "    return weights, bias, losses, pred_train_arr, pred_val_arr, acc_train_arr, acc_val_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating ground states...\n",
      "Ground states generated - 18s\n",
      "\n",
      "Max train / Last run\n",
      "---------------------------------------------------\n",
      "  CV   | Run |   Iter    |Acc train|Acc val| Time  \n",
      "---------------------------------------------------\n",
      " False |   0 |    0/ 999 |  23/23  | 0/0 | 2\n",
      " False |   1 |    0/ 999 |  11/11  | 0/0 | 2\n",
      "---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# with jax.profiler.trace(\"/tmp/jax-trace\", create_perfetto_link=True):\n",
    "\n",
    "time_now = datetime.now(pytz.timezone('Europe/Andorra')).strftime(\"%Y-%m-%d %H-%M-%S\")\n",
    "\n",
    "folder_name = f\"Results/{nqubits}q - {num_iters:} iters/\"\n",
    "if not os.path.isdir(f'{folder_name}'):\n",
    "    os.makedirs(f'{folder_name}')\n",
    "\n",
    "save_hyperparameters(time_now, folder_name, file_name=\"\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------- #\n",
    "# ------------------- Generate ground states ------------------- #\n",
    "# -------------------------------------------------------------- #\n",
    "\n",
    "print(\"Generating ground states...\")\n",
    "start_time = time.time()\n",
    "\n",
    "gs_train, labels_train, j_train = generate_gs(train_size, uniform_train, epsilon_train, num_cpus_train)\n",
    "gs_val, labels_val, j_val = generate_gs(val_size, uniform_val, epsilon_val, num_cpus_val)\n",
    "\n",
    "run_time = time.time() - start_time\n",
    "\n",
    "print(f\"Ground states generated - {run_time:.0f}s\")\n",
    "print()\n",
    "print(\"Max train / Last run\")\n",
    "print(\"---------------------------------------------------\")\n",
    "print(\"  CV   | Run |   Iter    |Acc train|Acc val| Time  \")\n",
    "print(\"---------------------------------------------------\")\n",
    "\n",
    "for run in range (num_runs):\n",
    "    \n",
    "    # ------------------------------------------------------ #\n",
    "    # ------------------- Train the QCNN ------------------- #\n",
    "    # ------------------------------------------------------ #\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    weights, \\\n",
    "    bias, \\\n",
    "    losses, \\\n",
    "    pred_train_arr, \\\n",
    "    pred_val_arr, \\\n",
    "    acc_train_arr, \\\n",
    "    acc_val_arr = train_qcnn(gs_train,\n",
    "                             gs_val,\n",
    "                             labels_train,\n",
    "                             labels_val,\n",
    "                             cv=False\n",
    "                            )\n",
    "\n",
    "    run_time = time.time() - start_time\n",
    "\n",
    "\n",
    "    # --------------------------------------------------------- #\n",
    "    # ------------------- Save calculations ------------------- #\n",
    "    # --------------------------------------------------------- #\n",
    "\n",
    "    save_data(time_now,\n",
    "              folder_name,\n",
    "              run,\n",
    "              weights,\n",
    "              bias,\n",
    "              losses,\n",
    "              j_train,\n",
    "              j_val,\n",
    "              pred_train_arr,\n",
    "              pred_val_arr,\n",
    "              acc_train_arr,\n",
    "              acc_val_arr,\n",
    "              run_time,\n",
    "              cv=False\n",
    "             )\n",
    "\n",
    "\n",
    "    # ---------------------------------------------------------------------- #\n",
    "    # ------------------------ QCNN with Curriculum ------------------------ #\n",
    "    # ---------------------------------------------------------------------- #\n",
    "    if with_cv:\n",
    "        # --------------------------------------------------------------------------------- #\n",
    "        # ------------------------ Sort training gs by their score ------------------------ #\n",
    "        # --------------------------------------------------------------------------------- #\n",
    "\n",
    "        score_it = num_iters-1 # num_iters-1 or it_max\n",
    "        scores = [single_loss(weights[score_it], bias[score_it], gs_train[i], labels_train[i]) for i in range(len(labels_train))]\n",
    "\n",
    "        table = {}\n",
    "        table[\"gs_train\"] = gs_train.tolist()\n",
    "        table[\"labels_train\"] = labels_train\n",
    "        table[\"j_train\"] = j_train.tolist()\n",
    "        table[\"scores\"] = scores\n",
    "\n",
    "        table = pd.DataFrame(table)\n",
    "        table.sort_values(by=[\"scores\"], inplace=True)\n",
    "\n",
    "        cv_gs_train = np.array(list(table[\"gs_train\"]))\n",
    "        cv_labels_train = np.array(list(table[\"labels_train\"]))\n",
    "        cv_j_train = np.array(list(table[\"j_train\"]))\n",
    "\n",
    "\n",
    "        # ---------------------------------------------------------------------------- #\n",
    "        # ------------------------ Train QCNN with Curriculum ------------------------ #\n",
    "        # ---------------------------------------------------------------------------- #\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        weights, \\\n",
    "        bias, \\\n",
    "        losses, \\\n",
    "        pred_train_arr, \\\n",
    "        pred_val_arr, \\\n",
    "        acc_train_arr, \\\n",
    "        acc_val_arr = train_qcnn(cv_gs_train,\n",
    "                                 gs_val,\n",
    "                                 cv_labels_train,\n",
    "                                 labels_val,\n",
    "                                 cv=True\n",
    "                                )\n",
    "\n",
    "        run_time = time.time() - start_time\n",
    "\n",
    "\n",
    "        # --------------------------------------------------------- #\n",
    "        # ------------------- Save calculations ------------------- #\n",
    "        # --------------------------------------------------------- #\n",
    "        save_data(time_now,\n",
    "                  folder_name,\n",
    "                  run,\n",
    "                  weights,\n",
    "                  bias,\n",
    "                  losses,\n",
    "                  cv_j_train,\n",
    "                  j_val,\n",
    "                  pred_train_arr,\n",
    "                  pred_val_arr,\n",
    "                  acc_train_arr,\n",
    "                  acc_val_arr,\n",
    "                  run_time,\n",
    "                  cv=True\n",
    "                 )\n",
    "\n",
    "print(\"---------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Miscellaneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(mp.cpu_count()) #256\n",
    "\n",
    "# gs = gs_train\n",
    "# lab = labels_train\n",
    "\n",
    "# for i in range(10, 120, 10):\n",
    "#     num_cpus_test = i\n",
    "#     start_time = time.time()\n",
    "#     loss(weights[0], bias[0], gs, lab, num_cpus_test)\n",
    "#     print(f\"{i} --- {(time.time() - start_time):.2f} seconds ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define regions coordinates\n",
    "x01, y01 = region01e_coords[:,0], region01e_coords[:,1]\n",
    "x02, y02 = region02e_coords[:,0], region02e_coords[:,1]\n",
    "x1, y1 = region1e_coords[:,0], region1e_coords[:,1]\n",
    "x2, y2 = region2e_coords[:,0], region2e_coords[:,1]\n",
    "x3, y3 = region3e_coords[:,0], region3e_coords[:,1]\n",
    "\n",
    "# put the regions into the plot\n",
    "plt.fill(x01, y01, facecolor='lightskyblue')    # class 0\n",
    "plt.fill(x02, y02, facecolor='lightskyblue')    # class 0\n",
    "plt.fill(x1, y1, facecolor='sandybrown')        # class 1\n",
    "plt.fill(x2, y2, facecolor='salmon')            # class 2\n",
    "plt.fill(x3, y3, facecolor='lightgreen')        # class 3\n",
    "\n",
    "plt.axis('square')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
