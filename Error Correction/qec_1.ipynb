{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sympy.utilities.iterables import multiset_permutations\n",
    "\n",
    "import jax.random\n",
    "import jax.numpy as jnp\n",
    "import jax.scipy.optimize\n",
    "import jaxopt\n",
    "import optax\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "import pennylane as qml\n",
    "from functools import partial\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "plt.ioff()\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pytz\n",
    "import ast\n",
    "from pypdf import PdfMerger\n",
    "\n",
    "import contextlib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running parameters\n",
    "num_iters = 200    # Number of training iterations\n",
    "num_runs = 1\n",
    "cl_types = [\"NCL\"]#, \"CL\", \"ACL\", \"SPCL\", \"SPACL\"]     # \"NCL\" - No curriculum, \"CL\" - Curriculum, \"ACL\" - Anti-curriculum, \"SPCL\" - Self paced curriculum, \"SPACL\" - Self paced anti-curriculum\n",
    "\n",
    "# Circuit parameters\n",
    "nqubits = 9\n",
    "circuit_type = \"Shor\" # \"Variational\", \"Shor\"\n",
    "error_type = \"BitFlip\" # \"BitFlip\", \"PhaseFlip\", \"AmplitudeDamping\", \"PhaseDamping\", \"DepolarizingChannel\"\n",
    "error_prob = 0.1\n",
    "\n",
    "# Data hyper-parameters\n",
    "batch_size = 6    # batch training size\n",
    "train_size = 6    # Total states that will be used for training\n",
    "# val_size = 0      # Total states that will be used for validation\n",
    "cl_batch_ratios = [1/3, 1/3, 1/3]  # [0.3, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]\n",
    "cl_iter_ratios  = [1/4, 1/4, 1/2]  # [0.2, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2]\n",
    "\n",
    "# Optimization parameters\n",
    "optimizer = \"Adam\"  # \"Adam\", \"GradientDescent\", \"BFGS\"\n",
    "loss_type = \"fidelity\" # \"fidelity\"\n",
    "initialization = \"gaussian\" # \"gaussian\", \"uniform\"\n",
    "max_weight_init = 2*np.pi  # weight_init goes from 0 to this number. Max = 2*np.pi. Other options = 0.01\n",
    "stepsize = 0.01         # stepsize of the gradient descent.\n",
    "\n",
    "# Constant definitions\n",
    "cl_batches = []\n",
    "i_batch_size = 0\n",
    "for i in range(len(cl_iter_ratios)):\n",
    "    if i < len(cl_iter_ratios)-1:\n",
    "        i_batch_size += int(cl_batch_ratios[i]*train_size)\n",
    "        i_num_iters = int(cl_iter_ratios[i]*num_iters)\n",
    "    else:\n",
    "        i_batch_size = train_size\n",
    "        i_num_iters = num_iters - len(cl_batches)\n",
    "        \n",
    "    cl_batches += [i_batch_size]*i_num_iters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Generate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def X(i):\n",
    "    return qml.PauliX(i)\n",
    "\n",
    "def Y(i):\n",
    "    return qml.PauliY(i)\n",
    "\n",
    "def Z(i):\n",
    "    return qml.PauliZ(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset():\n",
    "    x_matrix = qml.matrix(X(0))\n",
    "    _, x_eigvecs = np.linalg.eigh(x_matrix)\n",
    "    \n",
    "    y_matrix = qml.matrix(Y(0))\n",
    "    _, y_eigvecs = np.linalg.eigh(y_matrix)\n",
    "\n",
    "    z_matrix = qml.matrix(Z(0))\n",
    "    _, z_eigvecs = np.linalg.eigh(z_matrix)\n",
    "    \n",
    "    eigvecs = np.concatenate((x_eigvecs, y_eigvecs, z_eigvecs), axis=1)\n",
    "    eigvecs = [np.tensordot(e, np.conjugate(e), axes=0) for e in eigvecs.T]\n",
    "\n",
    "    return np.array(eigvecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Quantum Circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def general_unitary_2q(q1, q2, weights):\n",
    "    qml.U3(wires=q1, theta=weights[0], phi=weights[1], delta=weights[2])\n",
    "    qml.U3(wires=q1, theta=weights[3], phi=weights[4], delta=weights[5])\n",
    "    qml.CNOT(wires=[q2, q1])\n",
    "    qml.RZ(wires=q1, phi=weights[6])\n",
    "    qml.RY(wires=q2, phi=weights[7])\n",
    "    qml.CNOT(wires=[q1, q2])\n",
    "    qml.RY(wires=q2, phi=weights[8])\n",
    "    qml.CNOT(wires=[q2, q1])\n",
    "    qml.U3(wires=q1, theta=weights[9], phi=weights[10], delta=weights[11])\n",
    "    qml.U3(wires=q1, theta=weights[12], phi=weights[13], delta=weights[14])\n",
    "\n",
    "def general_unitary_3q(q1, q2, q3, weights):\n",
    "    general_unitary_2q(q1, q2, weights[0:15])\n",
    "    general_unitary_2q(q2, q3, weights[15:30])\n",
    "    general_unitary_2q(q3, q1, weights[30:45])\n",
    "\n",
    "def noise_channel(error_prob):\n",
    "    for i in range(nqubits):\n",
    "        if error_type == \"BitFlip\":\n",
    "            qml.BitFlip(error_prob, i)\n",
    "        if error_type == \"PhaseFlip\":\n",
    "            qml.PhaseFlip(error_prob, i)\n",
    "        if error_type == \"AmplitudeDamping\":\n",
    "            qml.AmplitudeDamping(error_prob, i)\n",
    "        if error_type == \"PhaseDamping\":\n",
    "            qml.PhaseDamping(error_prob, i)\n",
    "        if error_type == \"DepolarizingChannel\":\n",
    "            qml.DepolarizingChannel(error_prob, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variational_channel(weights, error_prob):\n",
    "    # https://pennylane.ai/blog/2021/05/how-to-simulate-noise-with-pennylane/\n",
    "    w_u1 = weights[0:45]\n",
    "    w_u2 = weights[45:90]\n",
    "    \n",
    "    qml.adjoint(general_unitary_3q)(1, 4, 7, w_u2)\n",
    "    qml.adjoint(general_unitary_3q)(0, 1, 2, w_u1)\n",
    "    qml.adjoint(general_unitary_3q)(3, 4, 5, w_u1)\n",
    "    qml.adjoint(general_unitary_3q)(6, 7, 8, w_u1)\n",
    "    \n",
    "    noise_channel(error_prob)\n",
    "    \n",
    "    general_unitary_3q(6, 7, 8, w_u1)\n",
    "    general_unitary_3q(3, 4, 5, w_u1)\n",
    "    general_unitary_3q(0, 1, 2, w_u1)\n",
    "    general_unitary_3q(1, 4, 7, w_u2)\n",
    "    \n",
    "\n",
    "dev = qml.device(\"default.mixed\", wires=nqubits)\n",
    "@jax.jit\n",
    "@qml.qnode(dev, interface=\"jax\")\n",
    "def variational_circuit(weights, state_ini, error_prob):\n",
    "    qml.QubitDensityMatrix(state_ini, wires=[4])\n",
    "    variational_channel(weights, error_prob)\n",
    "    return qml.density_matrix([4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shor_channel(error_prob):\n",
    "    qml.CNOT(wires=[0, 3])\n",
    "    qml.CNOT(wires=[0, 6])\n",
    "    qml.Hadamard(wires=0)\n",
    "    qml.Hadamard(wires=3)\n",
    "    qml.Hadamard(wires=6)\n",
    "    qml.CNOT(wires=[0, 1])\n",
    "    qml.CNOT(wires=[3, 4])\n",
    "    qml.CNOT(wires=[6, 7])\n",
    "    qml.CNOT(wires=[0, 2])\n",
    "    qml.CNOT(wires=[3, 5])\n",
    "    qml.CNOT(wires=[6, 8])\n",
    "    noise_channel(error_prob)\n",
    "    qml.CNOT(wires=[0, 1])\n",
    "    qml.CNOT(wires=[3, 4])\n",
    "    qml.CNOT(wires=[6, 7])\n",
    "    qml.CNOT(wires=[0, 2])\n",
    "    qml.CNOT(wires=[3, 5])\n",
    "    qml.CNOT(wires=[6, 8])\n",
    "    qml.Toffoli(wires=[2,1,0])\n",
    "    qml.Toffoli(wires=[5,4,3])\n",
    "    qml.Toffoli(wires=[8,7,6])\n",
    "    qml.Hadamard(wires=0)\n",
    "    qml.Hadamard(wires=3)\n",
    "    qml.Hadamard(wires=6)\n",
    "    qml.CNOT(wires=[0, 3])\n",
    "    qml.CNOT(wires=[0, 6])\n",
    "    qml.Toffoli(wires=[6,3,0])\n",
    "\n",
    "dev = qml.device(\"default.mixed\", wires=nqubits)\n",
    "@jax.jit\n",
    "@qml.qnode(dev, interface=\"jax\")\n",
    "def shor_circuit(state_ini, error_prob):\n",
    "    qml.QubitDensityMatrix(state_ini, wires=[0])\n",
    "    shor_channel(error_prob)\n",
    "    return qml.density_matrix([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def circuit(weights, state_ini, error_prob):\n",
    "    if circuit_type == \"Variational\":\n",
    "        state_out = variational_circuit(weights, state_ini, error_prob)\n",
    "    elif circuit_type == \"Shor\":\n",
    "        state_out = shor_circuit(state_ini, error_prob)\n",
    "    \n",
    "    return state_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def single_loss(weights, ini_state, error_prob):\n",
    "    \n",
    "    out_state = circuit(weights, ini_state, error_prob)\n",
    "\n",
    "    if loss_type == \"fidelity\":\n",
    "        cost = 1 - qml.math.fidelity(out_state, ini_state)\n",
    "    \n",
    "    return cost\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def loss(weights, ini_states, error_prob):\n",
    "    costs = jax.vmap(single_loss, in_axes=[None, 0, None])(weights, ini_states, error_prob)\n",
    "    return costs.sum()/len(ini_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_multi_image(filename):\n",
    "    pp = PdfPages(filename)\n",
    "    fig_nums = plt.get_fignums()\n",
    "    figs = [plt.figure(n) for n in fig_nums]\n",
    "    for fig in figs:\n",
    "        fig.savefig(pp, bbox_inches='tight', format='pdf')\n",
    "    pp.close()\n",
    "\n",
    "\n",
    "def close_all_figures():\n",
    "    fig_nums = plt.get_fignums()\n",
    "    for n in fig_nums:\n",
    "        plt.figure(n)\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "def save_plots(time_now,\n",
    "               folder_name,\n",
    "               file_name,\n",
    "               plot_run,\n",
    "               losses_train\n",
    "            #    losses_val\n",
    "              ):\n",
    "\n",
    "\n",
    "    fig, axis = plt.subplots(1,1)\n",
    "    # fig.set_figheight(6.5)\n",
    "    # fig.set_figwidth(15)\n",
    "    fig.tight_layout()  # otherwise the right y-label is slightly clipped # rect=(1,1,5,1)\n",
    "\n",
    "    # ---------------------------------------------------------------------- #\n",
    "    # -------------------- Loss and accuracy figure ------------------------ #\n",
    "    # ---------------------------------------------------------------------- #\n",
    "\n",
    "    iterations = range(1, num_iters+1)\n",
    "\n",
    "    color2 = 'darkblue'\n",
    "    axis.set_ylabel('Loss', color=color2)  # we already handled the x-label with axis[0]\n",
    "    axis.plot(iterations, losses_train, label=\"Train Loss\", color=color2)\n",
    "    # axis.plot(iterations, losses_val, '-.', label=\"Val. Loss\", color=color2)\n",
    "    axis.tick_params(axis='y', labelcolor=color2)\n",
    "    axis.set_yscale(\"log\")\n",
    "    # axis.set_ylim(bottom=0.0, top=1.0)\n",
    "\n",
    "    # plt.legend()\n",
    "    axis.set_title(f\"Training and Validation Loss - Run {plot_run} ({losses_train[num_iters-1]:.2E})\") #/{losses_val[num_iters-1]:.2E})\")\n",
    "    \n",
    "    # ---------------------------------------------------------------------- #\n",
    "    # --------------------------- Save plots ------------------------------- #\n",
    "    # ---------------------------------------------------------------------- #\n",
    "\n",
    "    plots_pdf_name = f\"{folder_name}/{time_now} - Plots - {file_name}.pdf\"\n",
    "    \n",
    "    \n",
    "    # If the file doesn't exist we save it. If it does, we merge it.\n",
    "    if not os.path.isfile(plots_pdf_name):\n",
    "        save_multi_image(plots_pdf_name)\n",
    "    \n",
    "    else:\n",
    "        save_multi_image(plots_pdf_name + \"2\")\n",
    "        # Merge the new plot with the rest and delete the last file\n",
    "        merger = PdfMerger()\n",
    "        merger.append(plots_pdf_name)\n",
    "        merger.append(plots_pdf_name + \"2\")\n",
    "        merger.write(plots_pdf_name)\n",
    "        merger.close()\n",
    "        os.remove(plots_pdf_name + \"2\")\n",
    "    \n",
    "    close_all_figures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_hyperparameters(time_now, folder_name, file_name):\n",
    "    \n",
    "    # --------------- Hyperparameters -----------------#\n",
    "    hyperparameters = {}\n",
    "    hyperparameters[\"num_iters\"] = [num_iters]\n",
    "    hyperparameters[\"num_runs\"] = [num_runs]\n",
    "    hyperparameters[\"cl_types\"] = [cl_types]\n",
    "    hyperparameters[\"nqubits\"] = [nqubits]\n",
    "    hyperparameters[\"circuit_type\"] = [circuit_type]\n",
    "    hyperparameters[\"error_type\"] = [error_type]\n",
    "    hyperparameters[\"error_prob\"] = [error_prob]\n",
    "    hyperparameters[\"batch_size\"] = [batch_size]\n",
    "    hyperparameters[\"train_size\"] = [train_size]\n",
    "    # hyperparameters[\"val_size\"] = [val_size]\n",
    "    hyperparameters[\"cl_batch_ratios\"] = [cl_batch_ratios]\n",
    "    hyperparameters[\"cl_iter_ratios\"] = [cl_iter_ratios]\n",
    "    hyperparameters[\"optimizer\"] = [optimizer]\n",
    "    hyperparameters[\"loss_type\"] = [loss_type]\n",
    "    hyperparameters[\"initialization\"] = [initialization]\n",
    "    hyperparameters[\"max_weight_init\"] = [max_weight_init]\n",
    "    hyperparameters[\"stepsize\"] = [stepsize]\n",
    "    hyperparameters[\"key\"] = [time_now]\n",
    "\n",
    "    hyperparameters = pd.DataFrame(hyperparameters)\n",
    "\n",
    "    hyperparameters_file_name = f\"{folder_name}/{time_now} - Hyperparameters{file_name}.csv\"\n",
    "    hyperparameters.to_csv(hyperparameters_file_name, index=False, mode='a', header = not os.path.exists(hyperparameters_file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(time_now,\n",
    "              folder_name,\n",
    "              run,\n",
    "              weights,\n",
    "              losses_train,\n",
    "            #   losses_val,\n",
    "              run_time,\n",
    "              cl\n",
    "              ):\n",
    "    \n",
    "    # -------------------- Total Data -------------------- #\n",
    "    data = {}\n",
    "    data[\"run\"] = run\n",
    "    data[\"run_time\"] = run_time\n",
    "    data[\"weights\"] = [weights]\n",
    "    data[\"losses_train\"] = [losses_train]\n",
    "    # data[\"losses_val\"] = [losses_val]\n",
    "    \n",
    "\n",
    "    data = pd.DataFrame(data)\n",
    "    \n",
    "    data_file_name = f\"{folder_name}/{time_now} - Data - {cl}.csv\"\n",
    "    data.to_csv(data_file_name, index=False, mode='a', header = not os.path.exists(data_file_name))\n",
    "    \n",
    "    \n",
    "    # ------------------- Plots ------------------- #\n",
    "    save_plots(time_now,\n",
    "               folder_name,\n",
    "               cl,\n",
    "               run,\n",
    "               losses_train\n",
    "            #    losses_val\n",
    "              )\n",
    "    \n",
    "    if cl == \"NCL\":\n",
    "        cl_str = \"NCL  \"\n",
    "    elif cl==\"CL\":\n",
    "        cl_str = \"CL   \"\n",
    "    elif cl==\"ACL\":\n",
    "        cl_str = \"ACL  \"\n",
    "    elif cl==\"SPCL\":\n",
    "        cl_str = \"SPCL \"\n",
    "    elif cl==\"SPACL\":\n",
    "        cl_str = \"SPACL\"\n",
    "        \n",
    "    print(\n",
    "        f\" {cl_str} |\"\n",
    "        f\" {run:3d} |\"\n",
    "        f\" {run_time:0.0f}\"\n",
    "    )\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_plots_average_run(time_now, folder_name):\n",
    "        \n",
    "        transparency = 0.1\n",
    "        \n",
    "        if cl_types == [\"NCL\", \"CL\", \"ACL\", \"SPCL\", \"SPACL\"]:\n",
    "                arr_file_names = [[\"NCL\",\"CL\",\"ACL\"], [\"SPCL\",\"SPACL\"]]\n",
    "        else:\n",
    "                arr_file_names = [cl_types]\n",
    "\n",
    "        for file_names in arr_file_names:\n",
    "\n",
    "                fig, axis = plt.subplots(1,len(file_names))\n",
    "                if len(file_names) == 1:\n",
    "                        axis = [axis]\n",
    "                        fig.tight_layout(rect=(0,0,0,0))\n",
    "                else:\n",
    "                        fig.set_figheight(6)\n",
    "                        fig.set_figwidth(7*len(file_names))\n",
    "                        fig.tight_layout(pad=4, w_pad=7)\n",
    "\n",
    "                i = 0\n",
    "                for file_name in file_names:\n",
    "\n",
    "                        data_file_name = f\"{folder_name}/{time_now} - Data - {file_name}.csv\"\n",
    "\n",
    "                        # Read the saved data #####################\n",
    "                        read_data = pd.read_csv(data_file_name,\n",
    "                                                usecols=[\"losses_train\"],\n",
    "                                                        #  \"losses_val\"],\n",
    "                                                converters={\"losses_train\":ast.literal_eval})\n",
    "                                                        #     \"losses_val\":ast.literal_eval})\n",
    "\n",
    "                        all_runs_losses_train = list(map(np.array, read_data[\"losses_train\"]))\n",
    "                        # all_runs_losses_val = list(map(np.array, read_data[\"losses_val\"]))\n",
    "\n",
    "                        # We take the averages\n",
    "                        losses_train = sum(all_runs_losses_train)/num_runs\n",
    "                        # losses_val = sum(all_runs_losses_val)/num_runs\n",
    "\n",
    "                        iterations = range(1, num_iters+1)\n",
    "\n",
    "                        color2 = 'darkblue'\n",
    "                        axis[i].set_ylabel('Loss', color=color2)\n",
    "\n",
    "                        axis[i].plot(iterations, losses_train, label=\"Train Loss\", color=color2)\n",
    "                        for loss_train in all_runs_losses_train:\n",
    "                                axis[i].plot(iterations, loss_train, alpha=transparency, color=color2)\n",
    "\n",
    "                        # axis[i].plot(iterations, losses_val, '-.', label=\"Val. Loss\", color=color2)\n",
    "                        # for loss_val in all_runs_losses_val:\n",
    "                        #         axis[i].plot(iterations, loss_val, '-.', alpha=transparency, color=color2)\n",
    "\n",
    "                        axis[i].tick_params(axis='y', labelcolor=color2)\n",
    "                        axis[i].set_yscale(\"log\")\n",
    "                        # axis[i].set_ylim(bottom=0.0, top=1.0)\n",
    "\n",
    "                        # fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "                        # plt.legend()\n",
    "                        axis[i].set_title(f\"Training and Validation Loss - Average {file_name} ({losses_train[num_iters-1]:.2E})\") #/{losses_val[num_iters-1]:.2E})\")\n",
    "                        \n",
    "                        i += 1\n",
    "                        \n",
    "        plots_pdf_name = f\"{folder_name}/{time_now} - Average plots.pdf\"\n",
    "        save_multi_image(plots_pdf_name)\n",
    "        close_all_figures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_plots_last_loss_per_run(time_now, folder_name):\n",
    "\n",
    "    x_axis = list(range(1, num_runs+1)) + [\"Avg\"]\n",
    "\n",
    "    fig, axis = plt.subplots(1,1)\n",
    "    # fig.set_figheight(6)\n",
    "    # fig.set_figwidth(7)\n",
    "    # fig.tight_layout(pad=4, w_pad=7)\n",
    "\n",
    "    for cl in cl_types:\n",
    "        data_file_name = f\"{folder_name}/{time_now} - Data - {cl}.csv\"\n",
    "        read_data = pd.read_csv(data_file_name,\n",
    "                                usecols=[\"losses_train\"],\n",
    "                                converters={\"losses_train\":ast.literal_eval})\n",
    "\n",
    "        all_runs_losses_train = np.array(list(map(np.array, read_data[\"losses_train\"])))\n",
    "        \n",
    "        last_losses_train = all_runs_losses_train[:,num_iters-1]\n",
    "        \n",
    "        std_train = [0]*num_runs + [np.std(last_losses_train)]\n",
    "        \n",
    "        last_losses_train = list(last_losses_train) + [np.average(last_losses_train)]\n",
    "        \n",
    "        axis.set_ylabel('Loss')\n",
    "        axis.set_xlabel('Runs')\n",
    "        axis.set_xticks(range(len(x_axis)))\n",
    "        axis.set_xticklabels(x_axis)\n",
    "        axis.errorbar(range(len(x_axis)), last_losses_train, yerr=std_train, label=cl, fmt=\"o\", capsize=6)\n",
    "        axis.set_yscale(\"log\")\n",
    "        axis.set_title(f\"Last iteration loss per run - Training\")\n",
    "        axis.legend()\n",
    "\n",
    "    plots_pdf_name = f\"{folder_name}/{time_now} - Plots last loss per run.pdf\"\n",
    "    save_multi_image(plots_pdf_name)\n",
    "    close_all_figures()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_plots_error_rate(time_now, folder_name):\n",
    "\n",
    "    hyperparams_file_name = f\"{folder_name}/{time_now} - Hyperparameters.csv\"\n",
    "    read_hyperparams = pd.read_csv(hyperparams_file_name, usecols=[\"error_prob\"])\n",
    "    error_probs = list(read_hyperparams[\"error_prob\"])\n",
    "\n",
    "\n",
    "    if cl_types == [\"NCL\", \"CL\", \"ACL\", \"SPCL\", \"SPACL\"]:\n",
    "        arr_file_names = [[\"NCL\",\"CL\",\"ACL\"], [\"SPCL\",\"SPACL\"]]\n",
    "    else:\n",
    "        arr_file_names = [cl_types]\n",
    "        \n",
    "    for file_names in arr_file_names:\n",
    "\n",
    "        fig, axis = plt.subplots(1,len(file_names))\n",
    "        if len(file_names) == 1:\n",
    "            axis = [axis]\n",
    "            fig.tight_layout(rect=(0,0,0,0))\n",
    "        else:\n",
    "            fig.set_figheight(6)\n",
    "            fig.set_figwidth(7*len(file_names))\n",
    "            fig.tight_layout(pad=4, w_pad=7)\n",
    "        \n",
    "        i = 0\n",
    "        for file_name in file_names:\n",
    "            \n",
    "            data_file_name = f\"{folder_name}/{time_now} - Data - {file_name}.csv\"\n",
    "            read_data = pd.read_csv(data_file_name,\n",
    "                                    usecols=[\"losses_train\"],\n",
    "                                    converters={\"losses_train\":ast.literal_eval})\n",
    "            last_losses_train = np.array(list(map(np.array, read_data[\"losses_train\"])))[:,num_iters-1]\n",
    "\n",
    "            # ---------------------------------------------------------------------- #\n",
    "            # -------------------- Loss and accuracy figure ------------------------ #\n",
    "            # ---------------------------------------------------------------------- #\n",
    "\n",
    "            color2 = 'darkblue'\n",
    "            axis[i].set_xlabel('Error rate')\n",
    "            axis[i].set_ylabel('Loss')\n",
    "            axis[i].plot(error_probs, last_losses_train, label=\"Train Loss\", color=color2)\n",
    "            axis[i].set_yscale(\"log\")\n",
    "            axis[i].set_xscale(\"log\")\n",
    "            axis[i].set_title(f\"Last training loss vs error rate - {file_name}\")\n",
    "            i += 1\n",
    "    \n",
    "    plots_pdf_name = f\"{folder_name}/{time_now} - Plots error rate.pdf\"\n",
    "    save_multi_image(plots_pdf_name)\n",
    "    close_all_figures()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def sort_states(w, ini_states, ascending, error_prob):    \n",
    "    scores = jax.vmap(single_loss, in_axes=[None, 0])(jnp.array(w), jnp.array(ini_states), error_prob)\n",
    "    \n",
    "    p = jnp.where(ascending, scores.argsort(), scores.argsort()[::-1])\n",
    "    \n",
    "    return ini_states[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_qcnn(train_states, opt, cl, error_prob): #val_states,\n",
    "    \n",
    "    if initialization == \"uniform\":\n",
    "        weights_init = np.random.uniform(0, max_weight_init, 90)\n",
    "    elif initialization == \"gaussian\":\n",
    "        weights_init = np.random.normal(0, 1/np.sqrt(nqubits), 90)\n",
    "        \n",
    "    #Initiaize variables\n",
    "    weights = []\n",
    "    losses_train = []\n",
    "    # losses_val = []\n",
    "\n",
    "    w = weights_init\n",
    "    state = opt.init_state(weights_init, train_states[:2], error_prob)\n",
    "    \n",
    "    for it in range(num_iters):\n",
    "        \n",
    "        # For self paced learning, we sort the datapoints at every iteration\n",
    "        if cl in [\"SPCL\", \"SPACL\"]:\n",
    "            ascending = True if cl == \"SPCL\" else False\n",
    "            train_states = sort_states(w, train_states, ascending, error_prob)\n",
    "            \n",
    "        # Once they are sorted, we select the first datapoints into the batch lists\n",
    "        if cl in [\"CL\", \"ACL\", \"SPCL\", \"SPACL\"]:\n",
    "            train_states_batch = train_states[:cl_batches[it]]\n",
    "        \n",
    "        elif cl == \"NCL\":\n",
    "            batch_index = np.random.default_rng().choice(len(train_states), size=batch_size, replace=False)\n",
    "            train_states_batch = train_states[batch_index]\n",
    "\n",
    "            \n",
    "        # Update the weights by one optimizer step\n",
    "        with open(os.devnull, \"w\") as f, contextlib.redirect_stdout(f):\n",
    "            w, state = opt.update(w, state, train_states_batch, error_prob)\n",
    "        \n",
    "        if optimizer == \"GradientDescent\":\n",
    "            l_train = loss(w, train_states_batch, error_prob)\n",
    "        else:\n",
    "            l_train = state.value\n",
    "        \n",
    "        # l_val = loss(w, val_states)\n",
    "\n",
    "        # Compute difference between variational unitary and target unitary from hamiltonian evolution\n",
    "        \n",
    "        weights.append(w.tolist())\n",
    "        losses_train.append(float(l_train))\n",
    "        # losses_val.append(float(l_val))\n",
    "\n",
    "    return weights, losses_train #, losses_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    # with jax.profiler.trace(\"/tmp/jax-trace\", create_perfetto_link=True):\n",
    "\n",
    "    time_now = datetime.now(pytz.timezone('Europe/Andorra')).strftime(\"%Y-%m-%d %H-%M-%S\")\n",
    "\n",
    "    folder_name = f\"Results/{nqubits}q - {num_iters:} iters/\"\n",
    "    if not os.path.isdir(f'{folder_name}'):\n",
    "        os.makedirs(f'{folder_name}')\n",
    "\n",
    "    # t = time.time()\n",
    "    # key = jax.random.PRNGKey(int((t-int(t))*10**10))  # We start with a random (depending on time) seed for the jax keys\n",
    "\n",
    "    # choose variational classifier\n",
    "    if optimizer == \"GradientDescent\":\n",
    "        opt = jaxopt.GradientDescent(loss, stepsize=stepsize, verbose=False, jit=True)\n",
    "    elif optimizer == \"Adam\":\n",
    "        opt = jaxopt.OptaxSolver(loss, optax.adam(stepsize), verbose=False, jit=True)\n",
    "    elif optimizer == \"BFGS\":\n",
    "        opt = jaxopt.BFGS(loss, verbose=False, jit=True)\n",
    "    \n",
    "    \n",
    "    step = (np.log(10**(-1)) - np.log(10**(-4)))/9\n",
    "\n",
    "    error_probs = []\n",
    "    xpoint = np.log(10**(-4))\n",
    "    for i in range(10):\n",
    "        val = np.exp(xpoint)\n",
    "        error_probs.append(val)\n",
    "        xpoint += step\n",
    "        \n",
    "    num_runs = len(error_probs)\n",
    "    run = 0\n",
    "    global error_prob\n",
    "    for error_prob in error_probs:\n",
    "        \n",
    "        save_hyperparameters(time_now, folder_name, file_name=\"\")\n",
    "        \n",
    "        # -------------------------------------------------------------- #\n",
    "        # ------------------- Generate ground states ------------------- #\n",
    "        # -------------------------------------------------------------- #\n",
    "        \n",
    "        print(\"Generating dataset...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        states = generate_dataset()\n",
    "        \n",
    "        train_states = states[:train_size]\n",
    "        # val_states = states[train_size:]\n",
    "        \n",
    "        run_time = time.time() - start_time\n",
    "\n",
    "        print(f\"Dataset generated - {run_time:.0f}s\")\n",
    "        print()\n",
    "        print(\"Max train / Last run\")\n",
    "        print(\"---------------------\")\n",
    "        print(\"  CL   | Run | Time  \")\n",
    "        print(\"---------------------\")\n",
    "        \n",
    "        \n",
    "        for cl in cl_types:\n",
    "            # ----------------------------------------------------------------------------------------------- #\n",
    "            # ------------------------ Sort training gs by their score if curriculum ------------------------ #\n",
    "            # ----------------------------------------------------------------------------------------------- #\n",
    "\n",
    "            if cl in [\"CL\", \"ACL\"]:\n",
    "                score_it = num_iters-1\n",
    "                ascending = True if cl == \"CL\" else False\n",
    "                train_states = sort_states(weights_ncl[score_it], train_states, ascending, error_prob)\n",
    "\n",
    "            # ------------------------------------------------------------ #\n",
    "            # ------------------------ Train QCNN ------------------------ #\n",
    "            # ------------------------------------------------------------ #\n",
    "\n",
    "            start_time = time.time()\n",
    "\n",
    "            weights, \\\n",
    "            losses_train = train_qcnn(train_states,\n",
    "                                            opt=opt,\n",
    "                                            cl=cl,\n",
    "                                            error_prob=error_prob\n",
    "                                            )\n",
    "\n",
    "            run_time = time.time() - start_time\n",
    "            \n",
    "            if cl == \"NCL\":\n",
    "                weights_ncl = weights\n",
    "\n",
    "            # --------------------------------------------------------- #\n",
    "            # ------------------- Save calculations ------------------- #\n",
    "            # --------------------------------------------------------- #\n",
    "            save_data(time_now,\n",
    "                      folder_name,\n",
    "                      run,\n",
    "                      weights,\n",
    "                      losses_train,\n",
    "                      run_time,\n",
    "                      cl=cl\n",
    "                      )\n",
    "\n",
    "        print(\"---------------------\")\n",
    "        print()\n",
    "        run += 1\n",
    "    \n",
    "    # save_plots_average_run(time_now, folder_name)\n",
    "    # save_plots_last_loss_per_run(time_now, folder_name)\n",
    "    save_plots_error_rate(time_now, folder_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating dataset...\n",
      "Dataset generated - 0s\n",
      "\n",
      "Max train / Last run\n",
      "---------------------\n",
      "  CL   | Run | Time  \n",
      "---------------------\n"
     ]
    },
    {
     "ename": "TracerBoolConversionError",
     "evalue": "Attempted boolean conversion of traced array with shape bool[]..\nThe error occurred while tracing the function shor_circuit at C:\\Users\\erik.recio\\AppData\\Local\\Temp\\ipykernel_21044\\4088058128.py:31 for jit. This concrete value was not available in Python because it depends on the value of the argument state_ini.\nSee https://jax.readthedocs.io/en/latest/errors.html#jax.errors.TracerBoolConversionError",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTracerBoolConversionError\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[18], line 78\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------ #\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# ------------------------ Train QCNN ------------------------ #\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------ #\u001b[39;00m\n\u001b[0;32m     75\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     77\u001b[0m weights, \\\n\u001b[1;32m---> 78\u001b[0m losses_train \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_qcnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mcl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[43m                                \u001b[49m\u001b[43merror_prob\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_prob\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m                                \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m run_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cl \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNCL\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "Cell \u001b[1;32mIn[17], line 14\u001b[0m, in \u001b[0;36mtrain_qcnn\u001b[1;34m(train_states, opt, cl, error_prob)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# losses_val = []\u001b[39;00m\n\u001b[0;32m     13\u001b[0m w \u001b[38;5;241m=\u001b[39m weights_init\n\u001b[1;32m---> 14\u001b[0m state \u001b[38;5;241m=\u001b[39m \u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights_init\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_states\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_prob\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m it \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_iters):\n\u001b[0;32m     17\u001b[0m     \n\u001b[0;32m     18\u001b[0m     \u001b[38;5;66;03m# For self paced learning, we sort the datapoints at every iteration\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cl \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSPCL\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSPACL\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\erik.recio\\Documents\\GitHub\\venv\\Lib\\site-packages\\jaxopt\\_src\\optax_wrapper.py:108\u001b[0m, in \u001b[0;36mOptaxSolver.init_state\u001b[1;34m(self, init_params, *args, **kwargs)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Initialize the solver state.\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \n\u001b[0;32m     99\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;124;03m  state\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    106\u001b[0m opt_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39minit(init_params)\n\u001b[1;32m--> 108\u001b[0m value, aux \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m params_dtype \u001b[38;5;241m=\u001b[39m tree_util\u001b[38;5;241m.\u001b[39mtree_single_dtype(init_params)\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m OptaxState(iter_num\u001b[38;5;241m=\u001b[39mjnp\u001b[38;5;241m.\u001b[39masarray(\u001b[38;5;241m0\u001b[39m),\n\u001b[0;32m    113\u001b[0m                   value\u001b[38;5;241m=\u001b[39mjnp\u001b[38;5;241m.\u001b[39masarray(jnp\u001b[38;5;241m.\u001b[39minf, value\u001b[38;5;241m.\u001b[39mdtype),\n\u001b[0;32m    114\u001b[0m                   error\u001b[38;5;241m=\u001b[39mjnp\u001b[38;5;241m.\u001b[39masarray(jnp\u001b[38;5;241m.\u001b[39minf, dtype\u001b[38;5;241m=\u001b[39mparams_dtype),\n\u001b[0;32m    115\u001b[0m                   aux\u001b[38;5;241m=\u001b[39maux,\n\u001b[0;32m    116\u001b[0m                   internal_state\u001b[38;5;241m=\u001b[39mopt_state)\n",
      "File \u001b[1;32mc:\\Users\\erik.recio\\Documents\\GitHub\\venv\\Lib\\site-packages\\jaxopt\\_src\\base.py:71\u001b[0m, in \u001b[0;36m_add_aux_to_fun.<locals>.fun_with_aux\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfun_with_aux\u001b[39m(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m---> 71\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "    \u001b[1;31m[... skipping hidden 12 frame]\u001b[0m\n",
      "Cell \u001b[1;32mIn[9], line 14\u001b[0m, in \u001b[0;36mloss\u001b[1;34m(weights, ini_states, error_prob)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;129m@jax\u001b[39m\u001b[38;5;241m.\u001b[39mjit\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss\u001b[39m(weights, ini_states, error_prob):\n\u001b[1;32m---> 14\u001b[0m     costs \u001b[38;5;241m=\u001b[39m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43msingle_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mini_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_prob\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m costs\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(ini_states)\n",
      "    \u001b[1;31m[... skipping hidden 15 frame]\u001b[0m\n",
      "Cell \u001b[1;32mIn[9], line 4\u001b[0m, in \u001b[0;36msingle_loss\u001b[1;34m(weights, ini_state, error_prob)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;129m@jax\u001b[39m\u001b[38;5;241m.\u001b[39mjit\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msingle_loss\u001b[39m(weights, ini_state, error_prob):\n\u001b[1;32m----> 4\u001b[0m     out_state \u001b[38;5;241m=\u001b[39m \u001b[43mcircuit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mini_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_prob\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m loss_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfidelity\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m      7\u001b[0m         cost \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m qml\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mfidelity(out_state, ini_state)\n",
      "    \u001b[1;31m[... skipping hidden 12 frame]\u001b[0m\n",
      "Cell \u001b[1;32mIn[8], line 6\u001b[0m, in \u001b[0;36mcircuit\u001b[1;34m(weights, state_ini, error_prob)\u001b[0m\n\u001b[0;32m      4\u001b[0m     state_out \u001b[38;5;241m=\u001b[39m variational_circuit(weights, state_ini, error_prob)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m circuit_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShor\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m----> 6\u001b[0m     state_out \u001b[38;5;241m=\u001b[39m \u001b[43mshor_circuit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_ini\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_prob\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m state_out\n",
      "    \u001b[1;31m[... skipping hidden 12 frame]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\erik.recio\\Documents\\GitHub\\venv\\Lib\\site-packages\\pennylane\\qnode.py:1027\u001b[0m, in \u001b[0;36mQNode.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1022\u001b[0m         full_transform_program\u001b[38;5;241m.\u001b[39m_set_all_argnums(\n\u001b[0;32m   1023\u001b[0m             \u001b[38;5;28mself\u001b[39m, args, kwargs, argnums\n\u001b[0;32m   1024\u001b[0m         )  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;66;03m# pylint: disable=unexpected-keyword-arg\u001b[39;00m\n\u001b[1;32m-> 1027\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mqml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1028\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1029\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1030\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgradient_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1031\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1032\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform_program\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_transform_program\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1033\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1034\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgradient_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1035\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverride_shots\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverride_shots\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1036\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1037\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1039\u001b[0m res \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;66;03m# convert result to the interface in case the qfunc has no parameters\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\erik.recio\\Documents\\GitHub\\venv\\Lib\\site-packages\\pennylane\\interfaces\\execution.py:616\u001b[0m, in \u001b[0;36mexecute\u001b[1;34m(tapes, device, gradient_fn, interface, transform_program, config, grad_on_execution, gradient_kwargs, cache, cachesize, max_diff, override_shots, expand_fn, max_expansion, device_batch_transform)\u001b[0m\n\u001b[0;32m    614\u001b[0m \u001b[38;5;66;03m# Exiting early if we do not need to deal with an interface boundary\u001b[39;00m\n\u001b[0;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m no_interface_boundary_required:\n\u001b[1;32m--> 616\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43minner_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m post_processing(results)\n\u001b[0;32m    619\u001b[0m _grad_on_execution \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\erik.recio\\Documents\\GitHub\\venv\\Lib\\site-packages\\pennylane\\interfaces\\execution.py:249\u001b[0m, in \u001b[0;36m_make_inner_execute.<locals>.inner_execute\u001b[1;34m(tapes, **_)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m numpy_only:\n\u001b[0;32m    248\u001b[0m     tapes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(qml\u001b[38;5;241m.\u001b[39mtransforms\u001b[38;5;241m.\u001b[39mconvert_to_numpy_parameters(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tapes)\n\u001b[1;32m--> 249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcached_device_execution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtapes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\erik.recio\\Documents\\GitHub\\venv\\Lib\\site-packages\\pennylane\\interfaces\\execution.py:371\u001b[0m, in \u001b[0;36mcache_execute.<locals>.wrapper\u001b[1;34m(tapes, **kwargs)\u001b[0m\n\u001b[0;32m    366\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (res, []) \u001b[38;5;28;01mif\u001b[39;00m return_tuple \u001b[38;5;28;01melse\u001b[39;00m res\n\u001b[0;32m    368\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    369\u001b[0m     \u001b[38;5;66;03m# execute all unique tapes that do not exist in the cache\u001b[39;00m\n\u001b[0;32m    370\u001b[0m     \u001b[38;5;66;03m# convert to list as new device interface returns a tuple\u001b[39;00m\n\u001b[1;32m--> 371\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexecution_tapes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    373\u001b[0m final_res \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, tape \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tapes):\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2288.0_x64__qbz5n2kfra8p0\\Lib\\contextlib.py:81\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[1;32m---> 81\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\erik.recio\\Documents\\GitHub\\venv\\Lib\\site-packages\\pennylane\\_qubit_device.py:460\u001b[0m, in \u001b[0;36mQubitDevice.batch_execute\u001b[1;34m(self, circuits)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m circuit \u001b[38;5;129;01min\u001b[39;00m circuits:\n\u001b[0;32m    456\u001b[0m     \u001b[38;5;66;03m# we need to reset the device here, else it will\u001b[39;00m\n\u001b[0;32m    457\u001b[0m     \u001b[38;5;66;03m# not start the next computation in the zero state\u001b[39;00m\n\u001b[0;32m    458\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m--> 460\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcircuit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    461\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(res)\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtracker\u001b[38;5;241m.\u001b[39mactive:\n",
      "File \u001b[1;32mc:\\Users\\erik.recio\\Documents\\GitHub\\venv\\Lib\\site-packages\\pennylane\\devices\\default_mixed.py:685\u001b[0m, in \u001b[0;36mDefaultMixed.execute\u001b[1;34m(self, circuit, **kwargs)\u001b[0m\n\u001b[0;32m    683\u001b[0m         wires_list\u001b[38;5;241m.\u001b[39mappend(m\u001b[38;5;241m.\u001b[39mwires)\n\u001b[0;32m    684\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeasured_wires \u001b[38;5;241m=\u001b[39m qml\u001b[38;5;241m.\u001b[39mwires\u001b[38;5;241m.\u001b[39mWires\u001b[38;5;241m.\u001b[39mall_wires(wires_list)\n\u001b[1;32m--> 685\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcircuit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\erik.recio\\Documents\\GitHub\\venv\\Lib\\site-packages\\pennylane\\_qubit_device.py:279\u001b[0m, in \u001b[0;36mQubitDevice.execute\u001b[1;34m(self, circuit, **kwargs)\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_validity(circuit\u001b[38;5;241m.\u001b[39moperations, circuit\u001b[38;5;241m.\u001b[39mobservables)\n\u001b[0;32m    278\u001b[0m \u001b[38;5;66;03m# apply all circuit operations\u001b[39;00m\n\u001b[1;32m--> 279\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcircuit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moperations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrotations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_diagonalizing_gates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcircuit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;66;03m# generate computational basis samples\u001b[39;00m\n\u001b[0;32m    282\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshots \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m circuit\u001b[38;5;241m.\u001b[39mis_sampled:\n",
      "File \u001b[1;32mc:\\Users\\erik.recio\\Documents\\GitHub\\venv\\Lib\\site-packages\\pennylane\\devices\\default_mixed.py:699\u001b[0m, in \u001b[0;36mDefaultMixed.apply\u001b[1;34m(self, operations, rotations, **kwargs)\u001b[0m\n\u001b[0;32m    693\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m DeviceError(\n\u001b[0;32m    694\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOperation \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moperation\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m cannot be used after other Operations have already been applied \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    695\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshort_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m device.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    696\u001b[0m         )\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m operation \u001b[38;5;129;01min\u001b[39;00m operations:\n\u001b[1;32m--> 699\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_operation\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    701\u001b[0m \u001b[38;5;66;03m# store the pre-rotated state\u001b[39;00m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pre_rotated_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state\n",
      "File \u001b[1;32mc:\\Users\\erik.recio\\Documents\\GitHub\\venv\\Lib\\site-packages\\pennylane\\devices\\default_mixed.py:604\u001b[0m, in \u001b[0;36mDefaultMixed._apply_operation\u001b[1;34m(self, operation)\u001b[0m\n\u001b[0;32m    601\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(operation, QubitDensityMatrix):\n\u001b[1;32m--> 604\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_density_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwires\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    605\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(operation, Snapshot):\n",
      "File \u001b[1;32mc:\\Users\\erik.recio\\Documents\\GitHub\\venv\\Lib\\site-packages\\pennylane\\devices\\default_mixed.py:540\u001b[0m, in \u001b[0;36mDefaultMixed._apply_density_matrix\u001b[1;34m(self, state, device_wires)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dm_dim \u001b[38;5;241m!=\u001b[39m state\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDensity matrix must be of length (2**wires, 2**wires)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 540\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m qnp\u001b[38;5;241m.\u001b[39mallclose(\n\u001b[0;32m    541\u001b[0m     qnp\u001b[38;5;241m.\u001b[39mtrace(qnp\u001b[38;5;241m.\u001b[39mreshape(state, (state_dim, state_dim))), \u001b[38;5;241m1.0\u001b[39m, atol\u001b[38;5;241m=\u001b[39mtolerance\n\u001b[0;32m    542\u001b[0m ):\n\u001b[0;32m    543\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrace of density matrix is not equal one.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    545\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(device_wires) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_wires \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(device_wires\u001b[38;5;241m.\u001b[39mlabels) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m    546\u001b[0m     device_wires\u001b[38;5;241m.\u001b[39mlabels\n\u001b[0;32m    547\u001b[0m ):\n\u001b[0;32m    548\u001b[0m     \u001b[38;5;66;03m# Initialize the entire wires with the state\u001b[39;00m\n",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\erik.recio\\Documents\\GitHub\\venv\\Lib\\site-packages\\jax\\_src\\core.py:1510\u001b[0m, in \u001b[0;36mconcretization_function_error.<locals>.error\u001b[1;34m(self, arg)\u001b[0m\n\u001b[0;32m   1509\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21merror\u001b[39m(\u001b[38;5;28mself\u001b[39m, arg):\n\u001b[1;32m-> 1510\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m TracerBoolConversionError(arg)\n",
      "\u001b[1;31mTracerBoolConversionError\u001b[0m: Attempted boolean conversion of traced array with shape bool[]..\nThe error occurred while tracing the function shor_circuit at C:\\Users\\erik.recio\\AppData\\Local\\Temp\\ipykernel_21044\\4088058128.py:31 for jit. This concrete value was not available in Python because it depends on the value of the argument state_ini.\nSee https://jax.readthedocs.io/en/latest/errors.html#jax.errors.TracerBoolConversionError"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Miscellaneous"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
