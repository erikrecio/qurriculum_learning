{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sympy.utilities.iterables import multiset_permutations\n",
    "\n",
    "import jax.random\n",
    "import jax.numpy as jnp\n",
    "import jax.scipy.optimize\n",
    "import jaxopt\n",
    "import optax\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "import pennylane as qml\n",
    "from functools import partial\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "plt.ioff()\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pytz\n",
    "import ast\n",
    "from pypdf import PdfMerger\n",
    "\n",
    "import multiprocessing as mp\n",
    "import contextlib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# pip install jaxopt optax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running parameters\n",
    "num_iters = 500    # Number of training iterations\n",
    "num_runs = 10\n",
    "num_cpus = 10\n",
    "cl_types = [\"NCL\"]#, \"CL\", \"ACL\", \"SPCL\", \"SPACL\"]     # \"NCL\" - No curriculum, \"CL\" - Curriculum, \"ACL\" - Anti-curriculum, \"SPCL\" - Self paced curriculum, \"SPACL\" - Self paced anti-curriculum\n",
    "\n",
    "# Circuit parameters\n",
    "nqubits = 9\n",
    "error_prob = 0.1\n",
    "\n",
    "# Data hyper-parameters\n",
    "batch_size = 6    # batch training size\n",
    "train_size = 6    # Total states that will be used for training\n",
    "# val_size = 0      # Total states that will be used for validation\n",
    "cl_batch_ratios = [1/3, 1/3, 1/3]  # [0.3, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]\n",
    "cl_iter_ratios  = [1/4, 1/4, 1/2]  # [0.2, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2]\n",
    "\n",
    "# Optimization parameters\n",
    "optimizer = \"Adam\"  # \"Adam\", \"GradientDescent\", \"BFGS\"\n",
    "loss_type = \"fidelity\" # \"fidelity\"\n",
    "initialization = \"gaussian\" # \"gaussian\", \"uniform\"\n",
    "max_weight_init = 2*np.pi  # weight_init goes from 0 to this number. Max = 2*np.pi. Other options = 0.01\n",
    "stepsize = 0.01         # stepsize of the gradient descent.\n",
    "\n",
    "# Constant definitions\n",
    "cl_batches = []\n",
    "i_batch_size = 0\n",
    "for i in range(len(cl_iter_ratios)):\n",
    "    if i < len(cl_iter_ratios)-1:\n",
    "        i_batch_size += int(cl_batch_ratios[i]*train_size)\n",
    "        i_num_iters = int(cl_iter_ratios[i]*num_iters)\n",
    "    else:\n",
    "        i_batch_size = train_size\n",
    "        i_num_iters = num_iters - len(cl_batches)\n",
    "        \n",
    "    cl_batches += [i_batch_size]*i_num_iters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Generate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def X(i):\n",
    "    return qml.PauliX(i)\n",
    "\n",
    "def Y(i):\n",
    "    return qml.PauliY(i)\n",
    "\n",
    "def Z(i):\n",
    "    return qml.PauliZ(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset():\n",
    "    x_matrix = qml.matrix(X(0))\n",
    "    _, x_eigvecs = jnp.linalg.eigh(x_matrix)\n",
    "    \n",
    "    y_matrix = qml.matrix(Y(0))\n",
    "    _, y_eigvecs = jnp.linalg.eigh(y_matrix)\n",
    "\n",
    "    z_matrix = qml.matrix(Z(0))\n",
    "    _, z_eigvecs = jnp.linalg.eigh(z_matrix)\n",
    "    \n",
    "    eigvecs = x_eigvecs.tolist() + y_eigvecs.tolist() + z_eigvecs.tolist()\n",
    "    \n",
    "    ini_states = []\n",
    "    for e in eigvecs:\n",
    "        for _ in range(4):\n",
    "            e = np.tensordot(np.array([1,0]), e, axes=0).flatten()\n",
    "        for _ in range(4):\n",
    "            e = np.tensordot(e, np.array([1,0]), axes=0).flatten()\n",
    "        rho = np.tensordot(e, e, axes=0)\n",
    "        ini_states.append(rho)\n",
    "    \n",
    "    ini_states = np.array(ini_states)\n",
    "    np.random.shuffle(ini_states)\n",
    "    \n",
    "    return ini_states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Quantum Circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def general_unitary_2q(q1, q2, weights):\n",
    "    qml.U3(wires=q1, theta=weights[0], phi=weights[1], delta=weights[2])\n",
    "    qml.U3(wires=q1, theta=weights[3], phi=weights[4], delta=weights[5])\n",
    "    qml.CNOT(wires=[q2, q1])\n",
    "    qml.RZ(wires=q1, phi=weights[6])\n",
    "    qml.RY(wires=q2, phi=weights[7])\n",
    "    qml.CNOT(wires=[q1, q2])\n",
    "    qml.RY(wires=q2, phi=weights[8])\n",
    "    qml.CNOT(wires=[q2, q1])\n",
    "    qml.U3(wires=q1, theta=weights[9], phi=weights[10], delta=weights[11])\n",
    "    qml.U3(wires=q1, theta=weights[12], phi=weights[13], delta=weights[14])\n",
    "\n",
    "def general_unitary_3q(q1, q2, q3, weights):\n",
    "    general_unitary_2q(q1, q2, weights[0:15])\n",
    "    general_unitary_2q(q2, q3, weights[15:30])\n",
    "    general_unitary_2q(q3, q1, weights[30:45])\n",
    "\n",
    "def variational_unitary(weights):\n",
    "    # https://pennylane.ai/blog/2021/05/how-to-simulate-noise-with-pennylane/\n",
    "    w_u1 = weights[0:45]\n",
    "    w_u2 = weights[45:90]\n",
    "    \n",
    "    qml.adjoint(general_unitary_3q)(1, 4, 7, w_u2)\n",
    "    qml.adjoint(general_unitary_3q)(0, 1, 2, w_u1)\n",
    "    qml.adjoint(general_unitary_3q)(3, 4, 5, w_u1)\n",
    "    qml.adjoint(general_unitary_3q)(6, 7, 8, w_u1)\n",
    "    \n",
    "    for i in range(nqubits):\n",
    "        qml.BitFlip(error_prob, i)\n",
    "        # qml.PhaseFlip(error_prob, i)\n",
    "        # qml.AmplitudeDamping(error_prob, i)\n",
    "        # qml.PhaseDamping(error_prob, i)\n",
    "        # qml.DepolarizingChannel(error_prob, i)\n",
    "    \n",
    "    general_unitary_3q(6, 7, 8, w_u1)\n",
    "    general_unitary_3q(3, 4, 5, w_u1)\n",
    "    general_unitary_3q(0, 1, 2, w_u1)\n",
    "    general_unitary_3q(1, 4, 7, w_u2)\n",
    "    \n",
    "\n",
    "dev = qml.device(\"default.mixed\", wires=nqubits)\n",
    "@jax.jit\n",
    "@qml.qnode(dev, interface=\"jax\", diff_method=\"best\")\n",
    "def variational_circuit(weights, state_ini):\n",
    "    qml.QubitDensityMatrix(state_ini, wires=range(nqubits))\n",
    "    variational_unitary(weights)\n",
    "    return qml.state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def single_loss(weights, ini_state):\n",
    "    \n",
    "    out_state = variational_circuit(weights, ini_state)\n",
    "\n",
    "    if loss_type == \"fidelity\":\n",
    "        cost = 1 - qml.math.fidelity(out_state, ini_state)\n",
    "    \n",
    "    return cost\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def loss(weights, ini_states):\n",
    "    costs = jax.vmap(single_loss, in_axes=[None, 0])(weights, ini_states)\n",
    "    return costs.sum()/len(ini_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_multi_image(filename):\n",
    "    pp = PdfPages(filename)\n",
    "    fig_nums = plt.get_fignums()\n",
    "    figs = [plt.figure(n) for n in fig_nums]\n",
    "    for fig in figs:\n",
    "        fig.savefig(pp, bbox_inches='tight', format='pdf')\n",
    "    pp.close()\n",
    "\n",
    "\n",
    "def close_all_figures():\n",
    "    fig_nums = plt.get_fignums()\n",
    "    for n in fig_nums:\n",
    "        plt.figure(n)\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "def save_plots(time_now,\n",
    "               folder_name,\n",
    "               file_name,\n",
    "               plot_run,\n",
    "               losses_train\n",
    "            #    losses_val\n",
    "              ):\n",
    "\n",
    "\n",
    "    fig, axis = plt.subplots(1,1)\n",
    "    # fig.set_figheight(6.5)\n",
    "    # fig.set_figwidth(15)\n",
    "    fig.tight_layout()  # otherwise the right y-label is slightly clipped # rect=(1,1,5,1)\n",
    "\n",
    "    # ---------------------------------------------------------------------- #\n",
    "    # -------------------- Loss and accuracy figure ------------------------ #\n",
    "    # ---------------------------------------------------------------------- #\n",
    "\n",
    "    iterations = range(1, num_iters+1)\n",
    "\n",
    "    color2 = 'darkblue'\n",
    "    axis.set_ylabel('Loss', color=color2)  # we already handled the x-label with axis[0]\n",
    "    axis.plot(iterations, losses_train, label=\"Train Loss\", color=color2)\n",
    "    # axis.plot(iterations, losses_val, '-.', label=\"Val. Loss\", color=color2)\n",
    "    axis.tick_params(axis='y', labelcolor=color2)\n",
    "    axis.set_yscale(\"log\")\n",
    "    axis.set_ylim(bottom=0.0, top=1.0)\n",
    "\n",
    "    # plt.legend()\n",
    "    axis.set_title(f\"Training and Validation Loss - Run {plot_run} ({losses_train[num_iters-1]:.2E})\") #/{losses_val[num_iters-1]:.2E})\")\n",
    "    \n",
    "    # ---------------------------------------------------------------------- #\n",
    "    # --------------------------- Save plots ------------------------------- #\n",
    "    # ---------------------------------------------------------------------- #\n",
    "\n",
    "    plots_pdf_name = f\"{folder_name}/{time_now} - Plots - {file_name}.pdf\"\n",
    "    \n",
    "    \n",
    "    # If the file doesn't exist we save it. If it does, we merge it.\n",
    "    if not os.path.isfile(plots_pdf_name):\n",
    "        save_multi_image(plots_pdf_name)\n",
    "    \n",
    "    else:\n",
    "        save_multi_image(plots_pdf_name + \"2\")\n",
    "        # Merge the new plot with the rest and delete the last file\n",
    "        merger = PdfMerger()\n",
    "        merger.append(plots_pdf_name)\n",
    "        merger.append(plots_pdf_name + \"2\")\n",
    "        merger.write(plots_pdf_name)\n",
    "        merger.close()\n",
    "        os.remove(plots_pdf_name + \"2\")\n",
    "    \n",
    "    close_all_figures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_hyperparameters(time_now, folder_name, file_name):\n",
    "    \n",
    "    # --------------- Hyperparameters -----------------#\n",
    "    hyperparameters = {}\n",
    "    hyperparameters[\"num_iters\"] = [num_iters]\n",
    "    hyperparameters[\"num_runs\"] = [num_runs]\n",
    "    hyperparameters[\"cl_types\"] = [cl_types]\n",
    "    hyperparameters[\"nqubits\"] = [nqubits]\n",
    "    hyperparameters[\"error_prob\"] = [error_prob]\n",
    "    hyperparameters[\"batch_size\"] = [batch_size]\n",
    "    hyperparameters[\"train_size\"] = [train_size]\n",
    "    # hyperparameters[\"val_size\"] = [val_size]\n",
    "    hyperparameters[\"cl_batch_ratios\"] = [cl_batch_ratios]\n",
    "    hyperparameters[\"cl_iter_ratios\"] = [cl_iter_ratios]\n",
    "    hyperparameters[\"optimizer\"] = [optimizer]\n",
    "    hyperparameters[\"loss_type\"] = [loss_type]\n",
    "    hyperparameters[\"initialization\"] = [initialization]\n",
    "    hyperparameters[\"max_weight_init\"] = [max_weight_init]\n",
    "    hyperparameters[\"stepsize\"] = [stepsize]\n",
    "    hyperparameters[\"key\"] = [time_now]\n",
    "\n",
    "    hyperparameters = pd.DataFrame(hyperparameters)\n",
    "\n",
    "    hyperparameters_file_name = f\"{folder_name}/{time_now} - Hyperparameters{file_name}.csv\"\n",
    "    hyperparameters.to_csv(hyperparameters_file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(time_now,\n",
    "              folder_name,\n",
    "              run,\n",
    "              weights,\n",
    "              losses_train,\n",
    "            #   losses_val,\n",
    "              run_time,\n",
    "              cl\n",
    "              ):\n",
    "    \n",
    "    # -------------------- Total Data -------------------- #\n",
    "    data = {}\n",
    "    data[\"run\"] = run\n",
    "    data[\"run_time\"] = run_time\n",
    "    data[\"weights\"] = [weights]\n",
    "    data[\"losses_train\"] = [losses_train]\n",
    "    # data[\"losses_val\"] = [losses_val]\n",
    "    \n",
    "\n",
    "    data = pd.DataFrame(data)\n",
    "    \n",
    "    data_file_name = f\"{folder_name}/{time_now} - Data - {cl}.csv\"\n",
    "    data.to_csv(data_file_name, index=False, mode='a', header = not os.path.exists(data_file_name))\n",
    "    \n",
    "    \n",
    "    # ------------------- Plots ------------------- #\n",
    "    save_plots(time_now,\n",
    "               folder_name,\n",
    "               cl,\n",
    "               run,\n",
    "               losses_train\n",
    "            #    losses_val\n",
    "              )\n",
    "    \n",
    "    if cl == \"NCL\":\n",
    "        cl_str = \"NCL  \"\n",
    "    elif cl==\"CL\":\n",
    "        cl_str = \"CL   \"\n",
    "    elif cl==\"ACL\":\n",
    "        cl_str = \"ACL  \"\n",
    "    elif cl==\"SPCL\":\n",
    "        cl_str = \"SPCL \"\n",
    "    elif cl==\"SPACL\":\n",
    "        cl_str = \"SPACL\"\n",
    "        \n",
    "    print(\n",
    "        f\" {cl_str} |\"\n",
    "        f\" {run:3d} |\"\n",
    "        f\" {run_time:0.0f}\"\n",
    "    )\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_plots_average_run(time_now, folder_name):\n",
    "        \n",
    "        transparency = 0.1\n",
    "        \n",
    "        if cl_types == [\"NCL\", \"CL\", \"ACL\", \"SPCL\", \"SPACL\"]:\n",
    "                arr_file_names = [[\"NCL\",\"CL\",\"ACL\"], [\"SPCL\",\"SPACL\"]]\n",
    "        else:\n",
    "                arr_file_names = [cl_types]\n",
    "\n",
    "        for file_names in arr_file_names:\n",
    "\n",
    "                fig, axis = plt.subplots(1,len(file_names))\n",
    "                if len(file_names) == 1:\n",
    "                        axis = [axis]\n",
    "                        fig.tight_layout(rect=(0,0,0,0))\n",
    "                else:\n",
    "                        fig.set_figheight(6)\n",
    "                        fig.set_figwidth(7*len(file_names))\n",
    "                        fig.tight_layout(pad=4, w_pad=7)\n",
    "\n",
    "                i = 0\n",
    "                for file_name in file_names:\n",
    "\n",
    "                        data_file_name = f\"{folder_name}/{time_now} - Data - {file_name}.csv\"\n",
    "\n",
    "                        # Read the saved data #####################\n",
    "                        read_data = pd.read_csv(data_file_name,\n",
    "                                                usecols=[\"losses_train\"],\n",
    "                                                        #  \"losses_val\"],\n",
    "                                                converters={\"losses_train\":ast.literal_eval})\n",
    "                                                        #     \"losses_val\":ast.literal_eval})\n",
    "\n",
    "                        all_runs_losses_train = list(map(np.array, read_data[\"losses_train\"]))\n",
    "                        # all_runs_losses_val = list(map(np.array, read_data[\"losses_val\"]))\n",
    "\n",
    "                        # We take the averages\n",
    "                        losses_train = sum(all_runs_losses_train)/num_runs\n",
    "                        # losses_val = sum(all_runs_losses_val)/num_runs\n",
    "\n",
    "                        iterations = range(1, num_iters+1)\n",
    "\n",
    "                        color2 = 'darkblue'\n",
    "                        axis[i].set_ylabel('Loss', color=color2)\n",
    "\n",
    "                        axis[i].plot(iterations, losses_train, label=\"Train Loss\", color=color2)\n",
    "                        for loss_train in all_runs_losses_train:\n",
    "                                axis[i].plot(iterations, loss_train, alpha=transparency, color=color2)\n",
    "\n",
    "                        # axis[i].plot(iterations, losses_val, '-.', label=\"Val. Loss\", color=color2)\n",
    "                        # for loss_val in all_runs_losses_val:\n",
    "                        #         axis[i].plot(iterations, loss_val, '-.', alpha=transparency, color=color2)\n",
    "\n",
    "                        axis[i].tick_params(axis='y', labelcolor=color2)\n",
    "                        axis[i].set_yscale(\"log\")\n",
    "                        axis[i].set_ylim(bottom=0.0, top=1.0)\n",
    "\n",
    "                        # fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "                        # plt.legend()\n",
    "                        axis[i].set_title(f\"Training and Validation Loss - Average {file_name} ({losses_train[num_iters-1]:.2E})\") #/{losses_val[num_iters-1]:.2E})\")\n",
    "                        \n",
    "                        i += 1\n",
    "                        \n",
    "        plots_pdf_name = f\"{folder_name}/{time_now} - Average plots.pdf\"\n",
    "        save_multi_image(plots_pdf_name)\n",
    "        close_all_figures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_plots_last_loss_per_run(time_now, folder_name):\n",
    "\n",
    "    x_axis = list(range(1, num_runs+1)) + [\"Avg\"]\n",
    "\n",
    "    fig, axis = plt.subplots(1,1)\n",
    "    # fig.set_figheight(6)\n",
    "    # fig.set_figwidth(7)\n",
    "    # fig.tight_layout(pad=4, w_pad=7)\n",
    "\n",
    "    for cl in cl_types:\n",
    "        data_file_name = f\"{folder_name}/{time_now} - Data - {cl}.csv\"\n",
    "        read_data = pd.read_csv(data_file_name,\n",
    "                                usecols=[\"losses_train\"],\n",
    "                                converters={\"losses_train\":ast.literal_eval})\n",
    "\n",
    "        all_runs_losses_train = np.array(list(map(np.array, read_data[\"losses_train\"])))\n",
    "        \n",
    "        last_losses_train = all_runs_losses_train[:,num_iters-1]\n",
    "        \n",
    "        std_train = [0]*num_runs + [np.std(last_losses_train)]\n",
    "        \n",
    "        last_losses_train = list(last_losses_train) + [np.average(last_losses_train)]\n",
    "        \n",
    "        axis.set_ylabel('Loss')\n",
    "        axis.set_xlabel('Runs')\n",
    "        axis.set_xticks(range(len(x_axis)))\n",
    "        axis.set_xticklabels(x_axis)\n",
    "        axis.errorbar(range(len(x_axis)), last_losses_train, yerr=std_train, label=cl, fmt=\"o\", capsize=6)\n",
    "        axis.set_yscale(\"log\")\n",
    "        axis.set_title(f\"Last iteration loss per run - Training\")\n",
    "        axis.legend()\n",
    "\n",
    "    plots_pdf_name = f\"{folder_name}/{time_now} - Plots last loss per run.pdf\"\n",
    "    save_multi_image(plots_pdf_name)\n",
    "    close_all_figures()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def sort_states(w, ini_states, ascending):    \n",
    "    scores = jax.vmap(single_loss, in_axes=[None, 0])(jnp.array(w), jnp.array(ini_states))\n",
    "    \n",
    "    p = jnp.where(ascending, scores.argsort(), scores.argsort()[::-1])\n",
    "    \n",
    "    return ini_states[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_qcnn(train_states, opt, cl): #val_states,\n",
    "    \n",
    "    if initialization == \"uniform\":\n",
    "        weights_init = np.random.uniform(0, max_weight_init, 90)\n",
    "    elif initialization == \"gaussian\":\n",
    "        weights_init = np.random.normal(0, 1/np.sqrt(nqubits), 90)\n",
    "        \n",
    "    #Initiaize variables\n",
    "    weights = []\n",
    "    losses_train = []\n",
    "    # losses_val = []\n",
    "\n",
    "    w = weights_init\n",
    "    state = opt.init_state(weights_init, train_states[:2])\n",
    "    \n",
    "    for it in range(num_iters):\n",
    "        \n",
    "        # For self paced learning, we sort the datapoints at every iteration\n",
    "        if cl in [\"SPCL\", \"SPACL\"]:\n",
    "            ascending = True if cl == \"SPCL\" else False\n",
    "            train_states = sort_states(w, train_states, ascending)\n",
    "            \n",
    "        # Once they are sorted, we select the first datapoints into the batch lists\n",
    "        if cl in [\"CL\", \"ACL\", \"SPCL\", \"SPACL\"]:\n",
    "            train_states_batch = train_states[:cl_batches[it]]\n",
    "        \n",
    "        elif cl == \"NCL\":\n",
    "            batch_index = np.random.default_rng().choice(len(train_states), size=batch_size, replace=False)\n",
    "            train_states_batch = train_states[batch_index]\n",
    "\n",
    "            \n",
    "        # Update the weights by one optimizer step\n",
    "        with open(os.devnull, \"w\") as f, contextlib.redirect_stdout(f):\n",
    "            w, state = opt.update(w, state, train_states_batch)\n",
    "        \n",
    "        if optimizer == \"GradientDescent\":\n",
    "            l_train = loss(w, train_states_batch)\n",
    "        else:\n",
    "            l_train = state.value\n",
    "        \n",
    "        # l_val = loss(w, val_states)\n",
    "\n",
    "        # Compute difference between variational unitary and target unitary from hamiltonian evolution\n",
    "        \n",
    "        weights.append(w.tolist())\n",
    "        losses_train.append(float(l_train))\n",
    "        # losses_val.append(float(l_val))\n",
    "\n",
    "    return weights, losses_train #, losses_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    # with jax.profiler.trace(\"/tmp/jax-trace\", create_perfetto_link=True):\n",
    "\n",
    "    time_now = datetime.now(pytz.timezone('Europe/Andorra')).strftime(\"%Y-%m-%d %H-%M-%S\")\n",
    "\n",
    "    folder_name = f\"Results/{nqubits}q - {num_iters:} iters/\"\n",
    "    if not os.path.isdir(f'{folder_name}'):\n",
    "        os.makedirs(f'{folder_name}')\n",
    "\n",
    "    save_hyperparameters(time_now, folder_name, file_name=\"\")\n",
    "\n",
    "    # t = time.time()\n",
    "    # key = jax.random.PRNGKey(int((t-int(t))*10**10))  # We start with a random (depending on time) seed for the jax keys\n",
    "\n",
    "    # choose variational classifier\n",
    "    if optimizer == \"GradientDescent\":\n",
    "        opt = jaxopt.GradientDescent(loss, stepsize=stepsize, verbose=False, jit=True)\n",
    "    elif optimizer == \"Adam\":\n",
    "        opt = jaxopt.OptaxSolver(loss, optax.adam(stepsize), verbose=False, jit=True)\n",
    "    elif optimizer == \"BFGS\":\n",
    "        opt = jaxopt.BFGS(loss, verbose=False, jit=True)\n",
    "    \n",
    "    \n",
    "    for run in range (num_runs):\n",
    "        \n",
    "        # -------------------------------------------------------------- #\n",
    "        # ------------------- Generate ground states ------------------- #\n",
    "        # -------------------------------------------------------------- #\n",
    "        \n",
    "        print(\"Generating dataset...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        states = generate_dataset()\n",
    "        \n",
    "        train_states = states[:train_size]\n",
    "        # val_states = states[train_size:]\n",
    "        \n",
    "        run_time = time.time() - start_time\n",
    "\n",
    "        print(f\"Dataset generated - {run_time:.0f}s\")\n",
    "        print()\n",
    "        print(\"Max train / Last run\")\n",
    "        print(\"---------------------\")\n",
    "        print(\"  CL   | Run | Time  \")\n",
    "        print(\"---------------------\")\n",
    "        \n",
    "        \n",
    "        for cl in cl_types:\n",
    "            # ----------------------------------------------------------------------------------------------- #\n",
    "            # ------------------------ Sort training gs by their score if curriculum ------------------------ #\n",
    "            # ----------------------------------------------------------------------------------------------- #\n",
    "\n",
    "            if cl in [\"CL\", \"ACL\"]:\n",
    "                score_it = num_iters-1\n",
    "                ascending = True if cl == \"CL\" else False\n",
    "                train_states = sort_states(weights_ncl[score_it], train_states, ascending)\n",
    "\n",
    "            # ------------------------------------------------------------ #\n",
    "            # ------------------------ Train QCNN ------------------------ #\n",
    "            # ------------------------------------------------------------ #\n",
    "\n",
    "            start_time = time.time()\n",
    "\n",
    "            weights, \\\n",
    "            losses_train = train_qcnn(train_states,\n",
    "                                            opt=opt,\n",
    "                                            cl=cl\n",
    "                                            )\n",
    "\n",
    "            run_time = time.time() - start_time\n",
    "            \n",
    "            if cl == \"NCL\":\n",
    "                weights_ncl = weights\n",
    "\n",
    "            # --------------------------------------------------------- #\n",
    "            # ------------------- Save calculations ------------------- #\n",
    "            # --------------------------------------------------------- #\n",
    "            save_data(time_now,\n",
    "                      folder_name,\n",
    "                      run,\n",
    "                      weights,\n",
    "                      losses_train,\n",
    "                      run_time,\n",
    "                      cl=cl\n",
    "                      )\n",
    "\n",
    "        print(\"---------------------\")\n",
    "        print()\n",
    "    \n",
    "    save_plots_average_run(time_now, folder_name)\n",
    "    save_plots_last_loss_per_run(time_now, folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_parallel():\n",
    "\n",
    "    def run_parallel(run):\n",
    "        time_now = datetime.now(pytz.timezone('Europe/Andorra')).strftime(\"%Y-%m-%d %H-%M-%S\")\n",
    "\n",
    "        folder_name = f\"Results/{nqubits}q - {num_iters:} iters/\"\n",
    "        if not os.path.isdir(f'{folder_name}'):\n",
    "            os.makedirs(f'{folder_name}')\n",
    "\n",
    "        save_hyperparameters(time_now, folder_name, file_name=\"\")\n",
    "\n",
    "        # t = time.time()\n",
    "        # key = jax.random.PRNGKey(int((t-int(t))*10**10))  # We start with a random (depending on time) seed for the jax keys\n",
    "\n",
    "        # choose variational classifier\n",
    "        if optimizer == \"GradientDescent\":\n",
    "            opt = jaxopt.GradientDescent(loss, stepsize=stepsize, verbose=False, jit=True)\n",
    "        elif optimizer == \"Adam\":\n",
    "            opt = jaxopt.OptaxSolver(loss, optax.adam(stepsize), verbose=False, jit=True)\n",
    "        elif optimizer == \"BFGS\":\n",
    "            opt = jaxopt.BFGS(loss, verbose=False, jit=True)\n",
    "        \n",
    "        # -------------------------------------------------------------- #\n",
    "        # ------------------- Generate ground states ------------------- #\n",
    "        # -------------------------------------------------------------- #\n",
    "        \n",
    "        print(\"Generating dataset...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        states = generate_dataset()\n",
    "        \n",
    "        train_states = states[:train_size]\n",
    "        # val_states = states[train_size:]\n",
    "        \n",
    "        run_time = time.time() - start_time\n",
    "\n",
    "        print(f\"Dataset generated - {run_time:.0f}s\")\n",
    "        print()\n",
    "        print(\"Max train / Last run\")\n",
    "        print(\"---------------------\")\n",
    "        print(\"  CL   | Run | Time  \")\n",
    "        print(\"---------------------\")\n",
    "        \n",
    "        \n",
    "        for cl in cl_types:\n",
    "            # ----------------------------------------------------------------------------------------------- #\n",
    "            # ------------------------ Sort training gs by their score if curriculum ------------------------ #\n",
    "            # ----------------------------------------------------------------------------------------------- #\n",
    "\n",
    "            if cl in [\"CL\", \"ACL\"]:\n",
    "                score_it = num_iters-1\n",
    "                ascending = True if cl == \"CL\" else False\n",
    "                train_states = sort_states(weights_ncl[score_it], train_states, ascending)\n",
    "\n",
    "            # ------------------------------------------------------------ #\n",
    "            # ------------------------ Train QCNN ------------------------ #\n",
    "            # ------------------------------------------------------------ #\n",
    "\n",
    "            start_time = time.time()\n",
    "\n",
    "            weights, \\\n",
    "            losses_train = train_qcnn(train_states,\n",
    "                                            opt=opt,\n",
    "                                            cl=cl\n",
    "                                            )\n",
    "\n",
    "            run_time = time.time() - start_time\n",
    "            \n",
    "            if cl == \"NCL\":\n",
    "                weights_ncl = weights\n",
    "\n",
    "            # --------------------------------------------------------- #\n",
    "            # ------------------- Save calculations ------------------- #\n",
    "            # --------------------------------------------------------- #\n",
    "            save_data(time_now,\n",
    "                      folder_name,\n",
    "                      run,\n",
    "                      weights,\n",
    "                      losses_train,\n",
    "                      run_time,\n",
    "                      cl=cl\n",
    "                      )\n",
    "\n",
    "        print(\"---------------------\")\n",
    "        print()\n",
    "    \n",
    "    with mp.Pool(num_cpus) as pool:\n",
    "        gs_list = pool.starmap(run_parallel, list(range(num_runs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if num_cpus==0:\n",
    "    main()\n",
    "else:\n",
    "    main_parallel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Miscelaneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "time_now_arr = [\"2024-02-19 13-00-49\", \"2024-02-19 14-32-08\", \"2024-02-19 16-04-22\", \"2024-02-19 17-35-32\", \"2024-02-19 19-08-09\", \"2024-02-19 20-39-22\", \"2024-02-19 22-08-08\", \"2024-02-19 23-36-24\", \"2024-02-20 01-04-31\", \"2024-02-20 02-32-28\"]\n",
    "folder_name = f\"Results/{nqubits}q - {num_iters:} iters/\"\n",
    "file_name = \"NCL\"\n",
    "\n",
    "losses_train = []\n",
    "error_probs = []\n",
    "for time_now in time_now_arr:\n",
    "    data_file_name = f\"{folder_name}/{time_now} - Data - {file_name}.csv\"\n",
    "    read_data = pd.read_csv(data_file_name,\n",
    "                            usecols=[\"losses_train\"],\n",
    "                            converters={\"losses_train\":ast.literal_eval})\n",
    "    last_loss_train = read_data[\"losses_train\"][0][num_iters-1]\n",
    "    losses_train.append(last_loss_train)\n",
    "    \n",
    "    hyperparams_file_name = f\"{folder_name}/{time_now} - Hyperparameters.csv\"\n",
    "    read_hyperparams = pd.read_csv(hyperparams_file_name,\n",
    "                            usecols=[\"error_prob\"])\n",
    "    error_prob = read_hyperparams[\"error_prob\"][0]\n",
    "    error_probs.append(error_prob)\n",
    "    \n",
    "\n",
    "fig, axis = plt.subplots(1,1)\n",
    "# fig.set_figheight(6.5)\n",
    "# fig.set_figwidth(15)\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped # rect=(1,1,5,1)\n",
    "\n",
    "# ---------------------------------------------------------------------- #\n",
    "# -------------------- Loss and accuracy figure ------------------------ #\n",
    "# ---------------------------------------------------------------------- #\n",
    "\n",
    "runs = range(1, num_iters+1)\n",
    "\n",
    "color2 = 'darkblue'\n",
    "axis.set_xlabel('Error rate')\n",
    "axis.set_ylabel('Loss')\n",
    "axis.plot(error_probs, losses_train, label=\"Train Loss\", color=color2)\n",
    "axis.tick_params(axis='y', labelcolor=color2)\n",
    "axis.set_yscale(\"log\")\n",
    "axis.set_xscale(\"log\")\n",
    "# axis.set_ylim(bottom=0.0, top=1.0)\n",
    "\n",
    "# plt.legend()\n",
    "axis.set_title(f\"Training loss vs error rate\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
